{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(974, 8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv('full_dataset.csv')\n",
    "#df = shuffle(df, random_state=42)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>corpus</th>\n",
       "      <th>genre</th>\n",
       "      <th>period</th>\n",
       "      <th>region</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HUMA_P3_WMD_1777_HomburgRAW.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>HUMA</td>\n",
       "      <td>P3</td>\n",
       "      <td>WMD</td>\n",
       "      <td>Nachricht von den Alterthu&amp;#868;mern in dem Ge...</td>\n",
       "      <td>Homburg</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NEWS_P3_NoD_1786_wolfenbuettel1.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>P3</td>\n",
       "      <td>NoD</td>\n",
       "      <td>Zeitung\\r\\nfür\\r\\nStädte, Flecken und Dörfer,\\...</td>\n",
       "      <td>wolfenbuettel1</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NARR_P1_NoD_1658_MorgenlaendischRAW.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>NARR</td>\n",
       "      <td>P1</td>\n",
       "      <td>NoD</td>\n",
       "      <td>Das zwey vnd dreysigste Capitel.\\n      Des Pr...</td>\n",
       "      <td>Morgenlaendisch</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SCIE_P1_WMD_1680_EpidemicaRAW.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>SCIE</td>\n",
       "      <td>P1</td>\n",
       "      <td>WMD</td>\n",
       "      <td>Das XX. Capitel.\\n      Von den Schnecken.\\n  ...</td>\n",
       "      <td>Epidemica</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NEWS_P2_WMD_1701_hanau2.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>P2</td>\n",
       "      <td>WMD</td>\n",
       "      <td>Extraordinari Europæische Zeitung. 1701. Num. ...</td>\n",
       "      <td>hanau2</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename      corpus genre period region  \\\n",
       "0          HUMA_P3_WMD_1777_HomburgRAW.txt  manchester  HUMA     P3    WMD   \n",
       "1      NEWS_P3_NoD_1786_wolfenbuettel1.txt  manchester  NEWS     P3    NoD   \n",
       "2  NARR_P1_NoD_1658_MorgenlaendischRAW.txt  manchester  NARR     P1    NoD   \n",
       "3        SCIE_P1_WMD_1680_EpidemicaRAW.txt  manchester  SCIE     P1    WMD   \n",
       "4              NEWS_P2_WMD_1701_hanau2.txt  manchester  NEWS     P2    WMD   \n",
       "\n",
       "                                                text            title  year  \n",
       "0  Nachricht von den Alterthu&#868;mern in dem Ge...          Homburg  1777  \n",
       "1  Zeitung\\r\\nfür\\r\\nStädte, Flecken und Dörfer,\\...   wolfenbuettel1  1786  \n",
       "2  Das zwey vnd dreysigste Capitel.\\n      Des Pr...  Morgenlaendisch  1658  \n",
       "3  Das XX. Capitel.\\n      Von den Schnecken.\\n  ...        Epidemica  1680  \n",
       "4  Extraordinari Europæische Zeitung. 1701. Num. ...           hanau2  1701  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#kompletter Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teilung des Dataframes in die einzelnen Teilcorpora und Perioden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Teilung in Manchester und Innsbruck Dataframe, sowie in die einzelnen Perioden\n",
    "#Der einfachheit halber wird hier mit dem Dataframe.loc Attribut gearbeitet, weil es vergleichbar mit einem SQL-Statement ist ist\n",
    "#Hierfür jeweils eine eigene Zelle, damit man via Shape nochmal die Größe prüfen kann\n",
    "#Für die Tests können die einzelnen Dataframes wie gewünscht concateniert werden\n",
    "\n",
    "\n",
    "\n",
    "df_man = df.loc[df['corpus'] == 'manchester']\n",
    "df_man.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inn = df.loc[df['corpus'] == 'innsbruck']\n",
    "df_inn.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P1\n",
    "df_P1 = df.loc[df['period'] == 'P1']\n",
    "df_P1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P2\n",
    "df_P2 = df.loc[df['period'] == 'P2']\n",
    "df_P2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P3\n",
    "df_P3 = df.loc[df['period'] == 'P3']\n",
    "df_P3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P4\n",
    "df_P4 = df.loc[df['period'] == 'P4']\n",
    "df_P4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P5\n",
    "df_P5 = df.loc[df['period'] == 'P5']\n",
    "df_P5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P6\n",
    "df_P6 = df.loc[df['period'] == 'P6']\n",
    "df_P6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konkatenieren der einzelnen Teile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat34 = pd.concat((df_P3, df_P4))\n",
    "df_concat34.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat12 = pd.concat((df_P1, df_P2))\n",
    "df_concat12.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features P1 ist der Trainingskorpus, er heißt im folgenden _train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "tf = TfidfVectorizer(stop_words=get_stop_words('de'), max_features=20000)\n",
    "\n",
    "X_train = tf.fit_transform(df_P1.text)\n",
    "X_P2 = tf.transform(df_P2.text)\n",
    "X_P3 = tf.transform(df_P3.text)\n",
    "X_P4 = tf.transform(df_P4.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "\n",
    "y_train = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P1 auf die restlichen einzelnen Perioden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.25      0.07      0.11        15\n",
      "        LEGA       0.00      0.00      0.00        15\n",
      "        NARR       0.00      0.00      0.00        15\n",
      "        NEWS       0.21      1.00      0.35        23\n",
      "        SCIE       0.00      0.00      0.00        15\n",
      "        SERM       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.21       113\n",
      "   macro avg       0.07      0.15      0.06       113\n",
      "weighted avg       0.08      0.21      0.08       113\n",
      "\n",
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.00      0.00      0.00        15\n",
      "        LEGA       0.00      0.00      0.00        15\n",
      "        NARR       0.00      0.00      0.00        15\n",
      "        NEWS       0.17      1.00      0.29        18\n",
      "        SCIE       0.00      0.00      0.00        15\n",
      "        SERM       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.17       108\n",
      "   macro avg       0.02      0.14      0.04       108\n",
      "weighted avg       0.03      0.17      0.05       108\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        22\n",
      "        HUMA       0.00      0.00      0.00        24\n",
      "        LEGA       0.00      0.00      0.00        25\n",
      "        NARR       0.00      0.00      0.00        26\n",
      "        NEWS       0.44      1.00      0.61       108\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.44       247\n",
      "   macro avg       0.06      0.14      0.09       247\n",
      "weighted avg       0.19      0.44      0.27       247\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       0.00      0.00      0.00        20\n",
      "        NARR       0.00      0.00      0.00        22\n",
      "        NEWS       0.40      1.00      0.58        84\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.40       208\n",
      "   macro avg       0.06      0.14      0.08       208\n",
      "weighted avg       0.16      0.40      0.23       208\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       0.00      0.00      0.00        22\n",
      "        NARR       0.00      0.00      0.00        19\n",
      "        NEWS       0.29      1.00      0.45        53\n",
      "        SCIE       0.00      0.00      0.00        27\n",
      "        SERM       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.29       182\n",
      "   macro avg       0.04      0.14      0.06       182\n",
      "weighted avg       0.08      0.29      0.13       182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "naive_bayes = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred_P2 = naive_bayes.predict(X_P2)\n",
    "y_pred_P3 = naive_bayes.predict(X_P3)\n",
    "y_pred_P4 = naive_bayes.predict(X_P4)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS'] \n",
      "\n",
      " ['NEWS' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SCIE' 'LEGA' 'HUMA' 'NEWS' 'HUMA'\n",
      " 'LEGA' 'NEWS' 'SERM' 'SCIE' 'NEWS' 'LEGA' 'SERM' 'SCIE' 'LEGA' 'HUMA'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NARR' 'HUMA' 'SERM' 'NARR'\n",
      " 'NEWS' 'LEGA' 'NEWS' 'SERM' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NARR' 'DRAM' 'SERM' 'NEWS' 'HUMA' 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'SCIE'\n",
      " 'NEWS' 'DRAM' 'HUMA' 'HUMA' 'DRAM' 'NEWS' 'HUMA' 'SCIE' 'SCIE' 'SERM'\n",
      " 'SERM' 'SERM' 'DRAM' 'DRAM' 'NEWS' 'LEGA' 'SCIE' 'LEGA' 'HUMA' 'DRAM'\n",
      " 'SERM' 'NARR' 'DRAM' 'NEWS' 'SCIE' 'NEWS' 'SCIE' 'SERM' 'LEGA' 'LEGA'\n",
      " 'DRAM' 'NARR' 'NEWS' 'SCIE' 'NARR' 'LEGA' 'HUMA' 'SCIE' 'NEWS' 'NARR'\n",
      " 'HUMA' 'LEGA' 'SERM' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'LEGA' 'SCIE' 'NEWS'\n",
      " 'HUMA' 'DRAM' 'SERM' 'NEWS' 'SERM' 'SCIE' 'SERM' 'HUMA' 'NEWS' 'SERM'\n",
      " 'NEWS' 'NARR' 'SERM' 'DRAM' 'NEWS' 'SCIE' 'HUMA' 'NEWS' 'NARR' 'SERM'\n",
      " 'DRAM' 'NARR' 'NEWS' 'NEWS' 'HUMA' 'LEGA' 'NARR' 'NARR' 'SCIE' 'SCIE'\n",
      " 'LEGA' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'DRAM' 'HUMA'\n",
      " 'NARR' 'NEWS' 'SCIE' 'DRAM' 'DRAM' 'NEWS' 'LEGA' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'SERM' 'SCIE' 'NARR' 'NARR' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'HUMA']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_P6,'\\n\\n', y_P6) #Vergleich der vorhergesagten mit den tatsächlichen Label durch NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P1 und P2 concateniert auf die restlichen Perioden und den neuen Korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.27      0.42        15\n",
      "        HUMA       0.44      0.80      0.57        15\n",
      "        LEGA       1.00      0.53      0.70        15\n",
      "        NARR       0.47      1.00      0.64        15\n",
      "        NEWS       1.00      1.00      1.00        18\n",
      "        SCIE       1.00      0.33      0.50        15\n",
      "        SERM       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.82      0.68      0.66       108\n",
      "weighted avg       0.83      0.69      0.67       108\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.41      0.58        22\n",
      "        HUMA       0.00      0.00      0.00        24\n",
      "        LEGA       0.00      0.00      0.00        25\n",
      "        NARR       0.57      0.15      0.24        26\n",
      "        NEWS       0.51      0.97      0.67       108\n",
      "        SCIE       0.80      0.20      0.32        20\n",
      "        SERM       0.71      0.68      0.70        22\n",
      "\n",
      "    accuracy                           0.55       247\n",
      "   macro avg       0.51      0.35      0.36       247\n",
      "weighted avg       0.50      0.55      0.46       247\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.17      0.29        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       0.00      0.00      0.00        20\n",
      "        NARR       1.00      0.09      0.17        22\n",
      "        NEWS       0.44      1.00      0.61        84\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.48       208\n",
      "   macro avg       0.48      0.25      0.24       208\n",
      "weighted avg       0.47      0.48      0.36       208\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       0.00      0.00      0.00        22\n",
      "        NARR       1.00      0.05      0.10        19\n",
      "        NEWS       0.31      1.00      0.47        53\n",
      "        SCIE       1.00      0.04      0.07        27\n",
      "        SERM       0.86      0.29      0.43        21\n",
      "\n",
      "    accuracy                           0.34       182\n",
      "   macro avg       0.45      0.20      0.15       182\n",
      "weighted avg       0.44      0.34      0.21       182\n",
      "\n",
      "Inn               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.20      0.34        59\n",
      "        HUMA       0.00      0.00      0.00        67\n",
      "        LEGA       0.00      0.00      0.00        67\n",
      "        NARR       0.70      0.10      0.18        67\n",
      "        NEWS       0.43      0.99      0.59       245\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.83      0.07      0.14        67\n",
      "        SERM       0.80      0.49      0.61        65\n",
      "\n",
      "    accuracy                           0.47       638\n",
      "   macro avg       0.47      0.23      0.23       638\n",
      "weighted avg       0.50      0.47      0.36       638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train12 = tf.fit_transform(df_concat12.text)\n",
    "X_P3 = tf.transform(df_P3.text)\n",
    "X_P4 = tf.transform(df_P4.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "X_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train12 = df_concat12.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "y_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train12, y_train12)\n",
    "\n",
    "y_pred_P3 = naive_bayes.predict(X_P3)\n",
    "y_pred_P4 = naive_bayes.predict(X_P4)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "y_pred_inn = naive_bayes.predict(X_inn)\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))\n",
    "print('Inn', classification_report(y_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_inn, y_pred_inn)print(y_pred_P6,'\\n\\n', y_P6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P3 und P4 concateniert auf die restlichen Perioden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.20      0.07      0.10        15\n",
      "        LEGA       0.91      0.67      0.77        15\n",
      "        NARR       0.38      0.87      0.53        15\n",
      "        NEWS       1.00      1.00      1.00        25\n",
      "        SCIE       0.00      0.00      0.00        15\n",
      "        SERM       0.35      0.93      0.51        15\n",
      "\n",
      "    accuracy                           0.55       115\n",
      "   macro avg       0.41      0.50      0.42       115\n",
      "weighted avg       0.46      0.55      0.47       115\n",
      "\n",
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.33      0.13      0.19        15\n",
      "        LEGA       0.91      0.67      0.77        15\n",
      "        NARR       0.31      0.87      0.46        15\n",
      "        NEWS       1.00      1.00      1.00        23\n",
      "        SCIE       0.00      0.00      0.00        15\n",
      "        SERM       0.48      1.00      0.65        15\n",
      "\n",
      "    accuracy                           0.56       113\n",
      "   macro avg       0.43      0.52      0.44       113\n",
      "weighted avg       0.47      0.56      0.48       113\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       0.00      0.00      0.00        20\n",
      "        NARR       0.00      0.00      0.00        22\n",
      "        NEWS       0.41      1.00      0.58        84\n",
      "        SCIE       1.00      0.05      0.10        20\n",
      "        SERM       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.42       208\n",
      "   macro avg       0.34      0.17      0.13       208\n",
      "weighted avg       0.37      0.42      0.27       208\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       0.00      0.00      0.00        22\n",
      "        NARR       0.00      0.00      0.00        19\n",
      "        NEWS       0.29      1.00      0.45        53\n",
      "        SCIE       0.00      0.00      0.00        27\n",
      "        SERM       1.00      0.10      0.17        21\n",
      "\n",
      "    accuracy                           0.30       182\n",
      "   macro avg       0.18      0.16      0.09       182\n",
      "weighted avg       0.20      0.30      0.15       182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train34 = tf.fit_transform(df_concat34.text)\n",
    "X_P1 = tf.transform(df_P1.text)\n",
    "X_P2 = tf.transform(df_P2.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "\n",
    "y_train34 = df_concat34.genre.to_numpy()\n",
    "y_P1 = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train34, y_train34)\n",
    "\n",
    "y_pred_P1 = naive_bayes.predict(X_P1)\n",
    "y_pred_P2 = naive_bayes.predict(X_P2)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "print('P1', classification_report(y_P1, y_pred_P1))\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes alter auf neuer Korpus - Manchester Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.19      0.31        59\n",
      "        HUMA       0.62      0.07      0.13        67\n",
      "        LEGA       0.75      0.04      0.08        67\n",
      "        NARR       0.65      0.16      0.26        67\n",
      "        NEWS       0.43      0.97      0.60       245\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       1.00      0.10      0.19        67\n",
      "        SERM       0.87      0.51      0.64        65\n",
      "\n",
      "    accuracy                           0.48       638\n",
      "   macro avg       0.67      0.26      0.28       638\n",
      "weighted avg       0.66      0.48      0.39       638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_man = tf.fit_transform(df_man.text)\n",
    "X_test_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train_man = df_man.genre.to_numpy()\n",
    "y_test_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train_man, y_train_man)\n",
    "\n",
    "y_pred_inn = naive_bayes.predict(X_test_inn)\n",
    "print(classification_report(y_test_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes neuer auf alter Korpus - Innsbruck Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        45\n",
      "        HUMA       0.00      0.00      0.00        45\n",
      "        LEGA       0.00      0.00      0.00        45\n",
      "        NARR       0.00      0.00      0.00        45\n",
      "        NEWS       0.21      1.00      0.35        66\n",
      "        SCIE       0.00      0.00      0.00        45\n",
      "        SERM       0.93      0.56      0.69        45\n",
      "\n",
      "    accuracy                           0.27       336\n",
      "   macro avg       0.16      0.22      0.15       336\n",
      "weighted avg       0.17      0.27      0.16       336\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_inn = tf.fit_transform(df_inn.text)\n",
    "X_test_man = tf.transform(df_man.text)\n",
    "\n",
    "y_train_inn = df_inn.genre.to_numpy()\n",
    "y_test_man = df_man.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train_inn, y_train_inn)\n",
    "\n",
    "y_pred_man = naive_bayes.predict(X_test_man)\n",
    "print(classification_report(y_test_man, y_pred_man))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

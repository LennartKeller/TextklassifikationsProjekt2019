{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(974, 8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv('full_dataset.csv')\n",
    "#df = shuffle(df, random_state=42)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>corpus</th>\n",
       "      <th>genre</th>\n",
       "      <th>period</th>\n",
       "      <th>region</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HUMA_P3_WMD_1777_HomburgRAW.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>HUMA</td>\n",
       "      <td>P3</td>\n",
       "      <td>WMD</td>\n",
       "      <td>Nachricht von den Alterthu&amp;#868;mern in dem Ge...</td>\n",
       "      <td>Homburg</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NEWS_P3_NoD_1786_wolfenbuettel1.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>P3</td>\n",
       "      <td>NoD</td>\n",
       "      <td>Zeitung\\r\\nfür\\r\\nStädte, Flecken und Dörfer,\\...</td>\n",
       "      <td>wolfenbuettel1</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NARR_P1_NoD_1658_MorgenlaendischRAW.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>NARR</td>\n",
       "      <td>P1</td>\n",
       "      <td>NoD</td>\n",
       "      <td>Das zwey vnd dreysigste Capitel.\\n      Des Pr...</td>\n",
       "      <td>Morgenlaendisch</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SCIE_P1_WMD_1680_EpidemicaRAW.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>SCIE</td>\n",
       "      <td>P1</td>\n",
       "      <td>WMD</td>\n",
       "      <td>Das XX. Capitel.\\n      Von den Schnecken.\\n  ...</td>\n",
       "      <td>Epidemica</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NEWS_P2_WMD_1701_hanau2.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>P2</td>\n",
       "      <td>WMD</td>\n",
       "      <td>Extraordinari Europæische Zeitung. 1701. Num. ...</td>\n",
       "      <td>hanau2</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename      corpus genre period region  \\\n",
       "0          HUMA_P3_WMD_1777_HomburgRAW.txt  manchester  HUMA     P3    WMD   \n",
       "1      NEWS_P3_NoD_1786_wolfenbuettel1.txt  manchester  NEWS     P3    NoD   \n",
       "2  NARR_P1_NoD_1658_MorgenlaendischRAW.txt  manchester  NARR     P1    NoD   \n",
       "3        SCIE_P1_WMD_1680_EpidemicaRAW.txt  manchester  SCIE     P1    WMD   \n",
       "4              NEWS_P2_WMD_1701_hanau2.txt  manchester  NEWS     P2    WMD   \n",
       "\n",
       "                                                text            title  year  \n",
       "0  Nachricht von den Alterthu&#868;mern in dem Ge...          Homburg  1777  \n",
       "1  Zeitung\\r\\nfür\\r\\nStädte, Flecken und Dörfer,\\...   wolfenbuettel1  1786  \n",
       "2  Das zwey vnd dreysigste Capitel.\\n      Des Pr...  Morgenlaendisch  1658  \n",
       "3  Das XX. Capitel.\\n      Von den Schnecken.\\n  ...        Epidemica  1680  \n",
       "4  Extraordinari Europæische Zeitung. 1701. Num. ...           hanau2  1701  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#kompletter Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Achtung!!! Hier können die NEWS aus dem Datensatz herausgenommen werden - Einfach mit \\# kommentieren oder entkommentieren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              filename      corpus genre  \\\n",
      "0                      HUMA_P3_WMD_1777_HomburgRAW.txt  manchester  HUMA   \n",
      "2              NARR_P1_NoD_1658_MorgenlaendischRAW.txt  manchester  NARR   \n",
      "3                    SCIE_P1_WMD_1680_EpidemicaRAW.txt  manchester  SCIE   \n",
      "5                      SCIE_P2_WMD_1714_KleinodRAW.txt  manchester  SCIE   \n",
      "6                 SERM_P2_WOD_1730_SeelenLiechtRAW.txt  manchester  SERM   \n",
      "..                                                 ...         ...   ...   \n",
      "967  HUMA_P4_WMD_1812_Ueber die National-Ehre_RAW .txt   innsbruck  HUMA   \n",
      "969             NARR_P4_OOD_1842_Meister GrÑth_RAW.txt   innsbruck  NARR   \n",
      "970               DRAM_P4_OMD_1814_Schutzgeist_RAW.txt   innsbruck  DRAM   \n",
      "972           SCIE_P4_OOD_1811_Krankheitslehre_RAW.txt   innsbruck  SCIE   \n",
      "973  HUMA_P4_OOD_1808_Stadt Wienerisch-Neustadt_RAW...   innsbruck  HUMA   \n",
      "\n",
      "    period region                                               text  \\\n",
      "0       P3    WMD  Nachricht von den Alterthu&#868;mern in dem Ge...   \n",
      "2       P1    NoD  Das zwey vnd dreysigste Capitel.\\n      Des Pr...   \n",
      "3       P1    WMD  Das XX. Capitel.\\n      Von den Schnecken.\\n  ...   \n",
      "5       P2    WMD  Das Dritte Capitul/\\n      Von dem gru&#868;ne...   \n",
      "6       P2    WOD  An dem anderten Sonntag\\n      Nach der Ersche...   \n",
      "..     ...    ...                                                ...   \n",
      "967     P4    WMD  Erster Abschnitt.\\r\\nEs ist noch nicht so lang...   \n",
      "969     P4    OOD        Es war ein lieblicher Abend des Spätsomm...   \n",
      "970     P4    OMD  \\t\\t\\r\\n\\t\\tDas Vorspiel. \\r\\n(Die Straße nach...   \n",
      "972     P4    OOD  Einleitung \\r\\naus der\\r\\nNaturgeschichte der ...   \n",
      "973     P4    OOD  §. 3. \\r\\n\\r\\nZustand der Stadt Neustadt, zur ...   \n",
      "\n",
      "                         title  year  \n",
      "0                      Homburg  1777  \n",
      "2              Morgenlaendisch  1658  \n",
      "3                    Epidemica  1680  \n",
      "5                      Kleinod  1714  \n",
      "6                 SeelenLiecht  1730  \n",
      "..                         ...   ...  \n",
      "967    Ueber die National-Ehre  1812  \n",
      "969              Meister GrÑth  1842  \n",
      "970                Schutzgeist  1814  \n",
      "972            Krankheitslehre  1811  \n",
      "973  Stadt Wienerisch-Neustadt  1808  \n",
      "\n",
      "[663 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df[df.genre != 'NEWS']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teilung des Dataframes in die einzelnen Teilcorpora und Perioden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Teilung in Manchester und Innsbruck Dataframe, sowie in die einzelnen Perioden\n",
    "#Der einfachheit halber wird hier mit dem Dataframe.loc Attribut gearbeitet, weil es vergleichbar mit einem SQL-Statement ist ist\n",
    "#Hierfür jeweils eine eigene Zelle, damit man via Shape nochmal die Größe prüfen kann\n",
    "#Für die Tests können die einzelnen Dataframes wie gewünscht concateniert werden\n",
    "\n",
    "\n",
    "\n",
    "df_man = df.loc[df['corpus'] == 'manchester']\n",
    "df_man.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inn = df.loc[df['corpus'] == 'innsbruck']\n",
    "df_inn.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P1\n",
    "df_P1 = df.loc[df['period'] == 'P1']\n",
    "df_P1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P2\n",
    "df_P2 = df.loc[df['period'] == 'P2']\n",
    "df_P2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P3\n",
    "df_P3 = df.loc[df['period'] == 'P3']\n",
    "df_P3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P4\n",
    "df_P4 = df.loc[df['period'] == 'P4']\n",
    "df_P4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P5\n",
    "df_P5 = df.loc[df['period'] == 'P5']\n",
    "df_P5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P6\n",
    "df_P6 = df.loc[df['period'] == 'P6']\n",
    "df_P6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konkatenieren der einzelnen Teile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat34 = pd.concat((df_P3, df_P4))\n",
    "df_concat34.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat12 = pd.concat((df_P1, df_P2))\n",
    "df_concat12.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features P1 ist der Trainingskorpus, er heißt im folgenden _train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "tf = TfidfVectorizer(stop_words=get_stop_words('de'), max_features=20000)\n",
    "\n",
    "#Wie beim Lennart steht das X für die Texte und Y für die Label\n",
    "\n",
    "X_train = tf.fit_transform(df_P1.text)\n",
    "X_P2 = tf.transform(df_P2.text)\n",
    "X_P3 = tf.transform(df_P3.text)\n",
    "X_P4 = tf.transform(df_P4.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "\n",
    "y_train = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P1 auf die restlichen einzelnen Perioden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.33      0.50        15\n",
      "        HUMA       0.29      0.60      0.39        15\n",
      "        LEGA       1.00      0.33      0.50        15\n",
      "        NARR       0.57      0.87      0.68        15\n",
      "        SCIE       0.80      0.53      0.64        15\n",
      "        SERM       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.59        90\n",
      "   macro avg       0.74      0.59      0.59        90\n",
      "weighted avg       0.74      0.59      0.59        90\n",
      "\n",
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.13      0.24        15\n",
      "        HUMA       0.35      0.80      0.49        15\n",
      "        LEGA       1.00      0.27      0.42        15\n",
      "        NARR       0.45      0.93      0.61        15\n",
      "        SCIE       0.62      0.33      0.43        15\n",
      "        SERM       0.82      0.60      0.69        15\n",
      "\n",
      "    accuracy                           0.51        90\n",
      "   macro avg       0.71      0.51      0.48        90\n",
      "weighted avg       0.71      0.51      0.48        90\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.91      0.95      0.93        22\n",
      "        HUMA       0.50      0.46      0.48        24\n",
      "        LEGA       0.92      0.44      0.59        25\n",
      "        NARR       0.74      0.65      0.69        26\n",
      "        SCIE       0.93      0.65      0.76        20\n",
      "        SERM       0.44      0.91      0.60        22\n",
      "\n",
      "    accuracy                           0.67       139\n",
      "   macro avg       0.74      0.68      0.68       139\n",
      "weighted avg       0.74      0.67      0.67       139\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.94      0.83      0.88        18\n",
      "        HUMA       0.62      0.36      0.46        22\n",
      "        LEGA       1.00      0.50      0.67        20\n",
      "        NARR       0.60      0.68      0.64        22\n",
      "        SCIE       0.75      0.75      0.75        20\n",
      "        SERM       0.55      1.00      0.71        22\n",
      "\n",
      "    accuracy                           0.69       124\n",
      "   macro avg       0.74      0.69      0.68       124\n",
      "weighted avg       0.73      0.69      0.68       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.70      0.84      0.76        19\n",
      "        HUMA       0.56      0.24      0.33        21\n",
      "        LEGA       1.00      0.36      0.53        22\n",
      "        NARR       0.50      0.68      0.58        19\n",
      "        SCIE       0.83      0.37      0.51        27\n",
      "        SERM       0.41      1.00      0.58        21\n",
      "\n",
      "    accuracy                           0.57       129\n",
      "   macro avg       0.67      0.58      0.55       129\n",
      "weighted avg       0.68      0.57      0.54       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "naive_bayes = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred_P2 = naive_bayes.predict(X_P2)\n",
    "y_pred_P3 = naive_bayes.predict(X_P3)\n",
    "y_pred_P4 = naive_bayes.predict(X_P4)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SERM' 'DRAM' 'SCIE' 'SERM' 'HUMA' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'DRAM' 'LEGA' 'NARR' 'SERM' 'SCIE' 'DRAM' 'SERM' 'SERM' 'DRAM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'NARR' 'DRAM' 'SERM' 'NARR' 'NARR' 'HUMA'\n",
      " 'SERM' 'NARR' 'NARR' 'HUMA' 'SERM' 'DRAM' 'NARR' 'DRAM' 'SERM' 'HUMA'\n",
      " 'SERM' 'SCIE' 'SERM' 'DRAM' 'SCIE' 'DRAM' 'SERM' 'SERM' 'DRAM' 'NARR'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'DRAM' 'NARR' 'LEGA' 'HUMA' 'SERM'\n",
      " 'NARR' 'DRAM' 'SERM' 'NARR' 'DRAM' 'SERM' 'SCIE' 'SERM' 'SERM' 'LEGA'\n",
      " 'DRAM' 'DRAM' 'HUMA' 'NARR' 'LEGA' 'HUMA' 'NARR' 'NARR' 'NARR' 'SCIE'\n",
      " 'SERM' 'SCIE' 'NARR' 'SERM' 'SERM' 'SERM' 'HUMA' 'DRAM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'DRAM' 'SERM' 'DRAM' 'SCIE' 'SERM' 'NARR'\n",
      " 'SERM' 'DRAM' 'NARR' 'SERM' 'LEGA' 'NARR' 'NARR' 'SCIE' 'HUMA' 'LEGA'\n",
      " 'NARR' 'SERM' 'SCIE' 'SERM' 'DRAM' 'NARR' 'NARR' 'NARR' 'DRAM' 'DRAM'\n",
      " 'LEGA' 'LEGA' 'SERM' 'SERM' 'NARR' 'DRAM' 'NARR' 'SERM' 'SERM'] \n",
      "\n",
      " ['HUMA' 'DRAM' 'SCIE' 'LEGA' 'HUMA' 'HUMA' 'LEGA' 'SERM' 'SCIE' 'LEGA'\n",
      " 'SERM' 'SCIE' 'LEGA' 'HUMA' 'DRAM' 'HUMA' 'NARR' 'HUMA' 'SERM' 'NARR'\n",
      " 'LEGA' 'SERM' 'SERM' 'LEGA' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'HUMA'\n",
      " 'SERM' 'NARR' 'NARR' 'SCIE' 'LEGA' 'NARR' 'NARR' 'DRAM' 'SERM' 'HUMA'\n",
      " 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'SCIE' 'DRAM' 'HUMA' 'HUMA' 'DRAM' 'HUMA'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'DRAM' 'DRAM' 'LEGA' 'SCIE' 'LEGA'\n",
      " 'HUMA' 'DRAM' 'SERM' 'NARR' 'DRAM' 'SCIE' 'SCIE' 'SERM' 'LEGA' 'LEGA'\n",
      " 'DRAM' 'NARR' 'SCIE' 'NARR' 'LEGA' 'HUMA' 'SCIE' 'NARR' 'HUMA' 'LEGA'\n",
      " 'SERM' 'SCIE' 'HUMA' 'SERM' 'LEGA' 'SCIE' 'HUMA' 'DRAM' 'SERM' 'SERM'\n",
      " 'SCIE' 'SERM' 'HUMA' 'SERM' 'NARR' 'SERM' 'DRAM' 'SCIE' 'HUMA' 'NARR'\n",
      " 'SERM' 'DRAM' 'NARR' 'HUMA' 'LEGA' 'NARR' 'NARR' 'SCIE' 'SCIE' 'LEGA'\n",
      " 'NARR' 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'HUMA' 'NARR' 'SCIE' 'DRAM' 'DRAM'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'SERM' 'SCIE' 'NARR' 'NARR' 'LEGA' 'HUMA']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_P6,'\\n\\n', y_P6) #Vergleich der vorhergesagten mit den tatsächlichen Label durch NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P1 und P2 concateniert auf die restlichen Perioden und den neuen Korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.27      0.42        15\n",
      "        HUMA       0.48      0.87      0.62        15\n",
      "        LEGA       1.00      0.53      0.70        15\n",
      "        NARR       0.48      1.00      0.65        15\n",
      "        SCIE       0.83      0.33      0.48        15\n",
      "        SERM       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.63        90\n",
      "   macro avg       0.78      0.63      0.62        90\n",
      "weighted avg       0.78      0.63      0.62        90\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.95      0.91      0.93        22\n",
      "        HUMA       0.57      0.33      0.42        24\n",
      "        LEGA       1.00      0.72      0.84        25\n",
      "        NARR       0.74      0.77      0.75        26\n",
      "        SCIE       0.90      0.90      0.90        20\n",
      "        SERM       0.56      1.00      0.72        22\n",
      "\n",
      "    accuracy                           0.76       139\n",
      "   macro avg       0.79      0.77      0.76       139\n",
      "weighted avg       0.79      0.76      0.76       139\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.94      0.89      0.91        18\n",
      "        HUMA       0.67      0.27      0.39        22\n",
      "        LEGA       1.00      0.75      0.86        20\n",
      "        NARR       0.67      0.73      0.70        22\n",
      "        SCIE       0.80      1.00      0.89        20\n",
      "        SERM       0.65      1.00      0.79        22\n",
      "\n",
      "    accuracy                           0.77       124\n",
      "   macro avg       0.79      0.77      0.75       124\n",
      "weighted avg       0.78      0.77      0.75       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.77      0.89      0.83        19\n",
      "        HUMA       0.62      0.48      0.54        21\n",
      "        LEGA       1.00      0.50      0.67        22\n",
      "        NARR       0.71      0.79      0.75        19\n",
      "        SCIE       0.88      0.56      0.68        27\n",
      "        SERM       0.50      1.00      0.67        21\n",
      "\n",
      "    accuracy                           0.69       129\n",
      "   macro avg       0.75      0.70      0.69       129\n",
      "weighted avg       0.76      0.69      0.69       129\n",
      "\n",
      "Inn               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.88      0.90      0.89        59\n",
      "        HUMA       0.62      0.36      0.45        67\n",
      "        LEGA       1.00      0.66      0.79        67\n",
      "        NARR       0.71      0.76      0.73        67\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.85      0.79      0.82        67\n",
      "        SERM       0.56      1.00      0.72        65\n",
      "\n",
      "    accuracy                           0.74       393\n",
      "   macro avg       0.66      0.64      0.63       393\n",
      "weighted avg       0.77      0.74      0.73       393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train12 = tf.fit_transform(df_concat12.text)\n",
    "X_P3 = tf.transform(df_P3.text)\n",
    "X_P4 = tf.transform(df_P4.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "X_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train12 = df_concat12.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "y_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train12, y_train12)\n",
    "\n",
    "y_pred_P3 = naive_bayes.predict(X_P3)\n",
    "y_pred_P4 = naive_bayes.predict(X_P4)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "y_pred_inn = naive_bayes.predict(X_inn)\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))\n",
    "print('Inn', classification_report(y_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SERM' 'DRAM' 'SCIE' 'SERM' 'HUMA' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'DRAM' 'LEGA' 'NARR' 'DRAM' 'SCIE' 'DRAM' 'SERM' 'SERM' 'DRAM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SCIE' 'DRAM' 'SERM' 'HUMA' 'NARR' 'HUMA'\n",
      " 'SERM' 'NARR' 'NARR' 'SCIE' 'LEGA' 'DRAM' 'NARR' 'DRAM' 'SERM' 'HUMA'\n",
      " 'SERM' 'SCIE' 'LEGA' 'DRAM' 'SCIE' 'DRAM' 'HUMA' 'HUMA' 'DRAM' 'NARR'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'DRAM' 'NARR' 'LEGA' 'SCIE' 'SERM'\n",
      " 'HUMA' 'DRAM' 'SERM' 'NARR' 'DRAM' 'SERM' 'SCIE' 'SERM' 'HUMA' 'LEGA'\n",
      " 'DRAM' 'NARR' 'SCIE' 'NARR' 'LEGA' 'SERM' 'NARR' 'NARR' 'HUMA' 'SCIE'\n",
      " 'SERM' 'HUMA' 'NARR' 'SERM' 'SERM' 'HUMA' 'HUMA' 'DRAM' 'SERM' 'SERM'\n",
      " 'SCIE' 'SERM' 'HUMA' 'SERM' 'DRAM' 'SERM' 'DRAM' 'SCIE' 'SERM' 'NARR'\n",
      " 'SERM' 'DRAM' 'NARR' 'SERM' 'LEGA' 'NARR' 'NARR' 'SCIE' 'HUMA' 'LEGA'\n",
      " 'NARR' 'SERM' 'SCIE' 'SERM' 'DRAM' 'HUMA' 'NARR' 'SCIE' 'DRAM' 'DRAM'\n",
      " 'LEGA' 'LEGA' 'SERM' 'SERM' 'HUMA' 'NARR' 'NARR' 'LEGA' 'SERM' 'DRAM'\n",
      " 'SERM' 'NARR' 'NARR' 'LEGA' 'SCIE' 'NARR' 'NARR' 'SERM' 'LEGA' 'HUMA'\n",
      " 'NARR' 'SERM' 'DRAM' 'HUMA' 'SERM' 'SERM' 'DRAM' 'SERM' 'SCIE' 'NARR'\n",
      " 'HUMA' 'SCIE' 'SERM' 'HUMA' 'DRAM' 'SCIE' 'SCIE' 'SERM' 'SCIE' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'LEGA' 'LEGA' 'DRAM' 'NARR' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'NARR' 'HUMA' 'LEGA' 'NARR' 'NARR' 'LEGA' 'SCIE' 'SERM'\n",
      " 'DRAM' 'SERM' 'LEGA' 'NARR' 'DRAM' 'NARR' 'SERM' 'HUMA' 'NARR' 'SERM'\n",
      " 'SCIE' 'SCIE' 'LEGA' 'HUMA' 'LEGA' 'NARR' 'NARR' 'SCIE' 'SERM' 'SERM'\n",
      " 'SCIE' 'SERM' 'NARR' 'NARR' 'SCIE' 'SERM' 'SCIE' 'SERM' 'LEGA' 'SCIE'\n",
      " 'NARR' 'SCIE' 'SCIE' 'SERM' 'LEGA' 'DRAM' 'SCIE' 'HUMA' 'SERM' 'NARR'\n",
      " 'NARR' 'SERM' 'SERM' 'SERM' 'SERM' 'NARR' 'NARR' 'DRAM' 'SERM' 'HUMA'\n",
      " 'NARR' 'LEGA' 'LEGA' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SERM' 'SCIE' 'LEGA'\n",
      " 'SERM' 'SERM' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'NARR' 'SERM' 'DRAM' 'SCIE' 'SERM' 'LEGA' 'SERM' 'HUMA' 'SERM'\n",
      " 'SERM' 'HUMA' 'DRAM' 'SCIE' 'HUMA' 'NARR' 'HUMA' 'SERM' 'SERM' 'SERM'\n",
      " 'SCIE' 'LEGA' 'SERM' 'SERM' 'SERM' 'SERM' 'LEGA' 'SERM' 'LEGA' 'SERM'\n",
      " 'NARR' 'DRAM' 'LEGA' 'DRAM' 'HUMA' 'NARR' 'LEGA' 'SERM' 'DRAM' 'SCIE'\n",
      " 'DRAM' 'LEGA' 'NARR' 'NARR' 'DRAM' 'SCIE' 'SCIE' 'LEGA' 'NARR' 'SERM'\n",
      " 'NARR' 'SERM' 'SERM' 'NARR' 'NARR' 'SCIE' 'HUMA' 'SERM' 'HUMA' 'NARR'\n",
      " 'SCIE' 'NARR' 'LEGA' 'SERM' 'NARR' 'SERM' 'SERM' 'LEGA' 'DRAM' 'DRAM'\n",
      " 'LEGA' 'LEGA' 'SCIE' 'LEGA' 'SERM' 'SCIE' 'SCIE' 'DRAM' 'SERM' 'NARR'\n",
      " 'SERM' 'DRAM' 'DRAM' 'SERM' 'NARR' 'SERM' 'DRAM' 'SERM' 'SERM' 'LEGA'\n",
      " 'NARR' 'LEGA' 'NARR' 'SERM' 'SERM' 'LEGA' 'DRAM' 'DRAM' 'HUMA' 'SCIE'\n",
      " 'SCIE' 'NARR' 'DRAM' 'SCIE' 'DRAM' 'SCIE' 'SCIE' 'HUMA' 'SERM' 'NARR'\n",
      " 'HUMA' 'NARR' 'DRAM' 'NARR' 'SERM' 'SCIE' 'NARR' 'SCIE' 'DRAM' 'NARR'\n",
      " 'DRAM' 'SERM' 'LEGA' 'SERM' 'SERM' 'SERM' 'SCIE' 'SCIE' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'NARR' 'NARR' 'HUMA' 'SERM' 'HUMA' 'NARR' 'DRAM' 'NARR' 'SERM'\n",
      " 'SERM' 'SERM' 'NARR'] \n",
      "\n",
      " ['HUMA' 'DRAM' 'SCIE' 'LEGA' 'HUMA' 'HUMA' 'LEGA' 'SERM' 'SCIE' 'LEGA'\n",
      " 'SERM' 'SCIE' 'LEGA' 'HUMA' 'DRAM' 'HUMA' 'NARR' 'HUMA' 'SERM' 'NARR'\n",
      " 'LEGA' 'SERM' 'SERM' 'LEGA' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'HUMA'\n",
      " 'SERM' 'NARR' 'NARR' 'SCIE' 'LEGA' 'NARR' 'NARR' 'DRAM' 'SERM' 'HUMA'\n",
      " 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'SCIE' 'DRAM' 'HUMA' 'HUMA' 'DRAM' 'HUMA'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'DRAM' 'DRAM' 'LEGA' 'SCIE' 'LEGA'\n",
      " 'HUMA' 'DRAM' 'SERM' 'NARR' 'DRAM' 'SCIE' 'SCIE' 'SERM' 'LEGA' 'LEGA'\n",
      " 'DRAM' 'NARR' 'SCIE' 'NARR' 'LEGA' 'HUMA' 'SCIE' 'NARR' 'HUMA' 'LEGA'\n",
      " 'SERM' 'SCIE' 'HUMA' 'SERM' 'LEGA' 'SCIE' 'HUMA' 'DRAM' 'SERM' 'SERM'\n",
      " 'SCIE' 'SERM' 'HUMA' 'SERM' 'NARR' 'SERM' 'DRAM' 'SCIE' 'HUMA' 'NARR'\n",
      " 'SERM' 'DRAM' 'NARR' 'HUMA' 'LEGA' 'NARR' 'NARR' 'SCIE' 'SCIE' 'LEGA'\n",
      " 'NARR' 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'HUMA' 'NARR' 'SCIE' 'DRAM' 'DRAM'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'SERM' 'SCIE' 'NARR' 'NARR' 'LEGA' 'HUMA' 'DRAM'\n",
      " 'SERM' 'HUMA' 'NARR' 'LEGA' 'SCIE' 'HUMA' 'DRAM' 'SERM' 'LEGA' 'HUMA'\n",
      " 'NARR' 'SERM' 'DRAM' 'LEGA' 'SERM' 'HUMA' 'DRAM' 'SERM' 'HUMA' 'NARR'\n",
      " 'HUMA' 'SCIE' 'SERM' 'HUMA' 'DRAM' 'SCIE' 'HUMA' 'SERM' 'HUMA' 'SERM'\n",
      " 'NARR' 'HUMA' 'SERM' 'HUMA' 'NARR' 'LEGA' 'LEGA' 'DRAM' 'NARR' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'HUMA' 'HUMA' 'LEGA' 'NARR' 'NARR' 'LEGA' 'SCIE' 'SERM'\n",
      " 'DRAM' 'SERM' 'LEGA' 'NARR' 'DRAM' 'NARR' 'SERM' 'HUMA' 'HUMA' 'SERM'\n",
      " 'HUMA' 'SCIE' 'LEGA' 'LEGA' 'LEGA' 'HUMA' 'NARR' 'SCIE' 'LEGA' 'SERM'\n",
      " 'HUMA' 'SERM' 'NARR' 'NARR' 'SCIE' 'SERM' 'SCIE' 'NARR' 'LEGA' 'SCIE'\n",
      " 'NARR' 'SCIE' 'SCIE' 'HUMA' 'LEGA' 'DRAM' 'SCIE' 'HUMA' 'SERM' 'DRAM'\n",
      " 'HUMA' 'SERM' 'NARR' 'LEGA' 'SERM' 'NARR' 'NARR' 'DRAM' 'HUMA' 'LEGA'\n",
      " 'NARR' 'LEGA' 'LEGA' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SERM' 'SCIE' 'LEGA'\n",
      " 'NARR' 'SERM' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'LEGA' 'NARR' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'NARR' 'SERM' 'DRAM' 'SCIE' 'SERM' 'LEGA' 'HUMA' 'LEGA' 'SERM'\n",
      " 'SERM' 'LEGA' 'DRAM' 'SCIE' 'SCIE' 'NARR' 'HUMA' 'SERM' 'SERM' 'HUMA'\n",
      " 'SCIE' 'LEGA' 'NARR' 'SERM' 'NARR' 'DRAM' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'NARR' 'DRAM' 'LEGA' 'DRAM' 'LEGA' 'NARR' 'LEGA' 'SERM' 'DRAM' 'SCIE'\n",
      " 'DRAM' 'LEGA' 'NARR' 'NARR' 'DRAM' 'HUMA' 'SCIE' 'LEGA' 'NARR' 'SERM'\n",
      " 'HUMA' 'NEWS-P4' 'SERM' 'NARR' 'NARR' 'SCIE' 'LEGA' 'SERM' 'HUMA' 'NARR'\n",
      " 'SCIE' 'NARR' 'LEGA' 'HUMA' 'HUMA' 'HUMA' 'SERM' 'LEGA' 'DRAM' 'DRAM'\n",
      " 'LEGA' 'LEGA' 'SCIE' 'LEGA' 'HUMA' 'SCIE' 'SCIE' 'NARR' 'NARR' 'HUMA'\n",
      " 'SERM' 'DRAM' 'DRAM' 'NARR' 'NARR' 'SERM' 'DRAM' 'HUMA' 'SERM' 'LEGA'\n",
      " 'NARR' 'LEGA' 'NARR' 'HUMA' 'SERM' 'LEGA' 'DRAM' 'DRAM' 'LEGA' 'HUMA'\n",
      " 'SCIE' 'NARR' 'DRAM' 'SCIE' 'DRAM' 'SCIE' 'SCIE' 'HUMA' 'SERM' 'HUMA'\n",
      " 'HUMA' 'NARR' 'DRAM' 'NARR' 'SERM' 'SCIE' 'NARR' 'SCIE' 'DRAM' 'HUMA'\n",
      " 'DRAM' 'SERM' 'LEGA' 'SERM' 'SERM' 'SERM' 'SCIE' 'SCIE' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'NARR' 'NARR' 'HUMA' 'SERM' 'HUMA' 'NARR' 'DRAM' 'HUMA' 'NARR'\n",
      " 'DRAM' 'SCIE' 'HUMA']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_inn,'\\n\\n', y_inn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P3 und P4 concateniert auf die restlichen Perioden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.20      0.07      0.10        15\n",
      "        LEGA       0.92      0.73      0.81        15\n",
      "        NARR       0.45      0.87      0.59        15\n",
      "        SCIE       0.00      0.00      0.00        15\n",
      "        SERM       0.32      0.93      0.47        15\n",
      "\n",
      "    accuracy                           0.43        90\n",
      "   macro avg       0.31      0.43      0.33        90\n",
      "weighted avg       0.31      0.43      0.33        90\n",
      "\n",
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.62      0.33      0.43        15\n",
      "        LEGA       0.91      0.67      0.77        15\n",
      "        NARR       0.36      0.87      0.51        15\n",
      "        SCIE       0.00      0.00      0.00        15\n",
      "        SERM       0.43      1.00      0.60        15\n",
      "\n",
      "    accuracy                           0.48        90\n",
      "   macro avg       0.39      0.48      0.39        90\n",
      "weighted avg       0.39      0.48      0.39        90\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.22      0.36        18\n",
      "        HUMA       1.00      0.68      0.81        22\n",
      "        LEGA       1.00      1.00      1.00        20\n",
      "        NARR       0.54      1.00      0.70        22\n",
      "        SCIE       0.90      0.95      0.93        20\n",
      "        SERM       0.96      1.00      0.98        22\n",
      "\n",
      "    accuracy                           0.82       124\n",
      "   macro avg       0.90      0.81      0.80       124\n",
      "weighted avg       0.89      0.82      0.80       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.11      0.19        19\n",
      "        HUMA       0.78      0.67      0.72        21\n",
      "        LEGA       0.72      0.95      0.82        22\n",
      "        NARR       0.46      1.00      0.63        19\n",
      "        SCIE       1.00      0.63      0.77        27\n",
      "        SERM       0.86      0.90      0.88        21\n",
      "\n",
      "    accuracy                           0.71       129\n",
      "   macro avg       0.80      0.71      0.67       129\n",
      "weighted avg       0.82      0.71      0.68       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train34 = tf.fit_transform(df_concat34.text)\n",
    "X_P1 = tf.transform(df_P1.text)\n",
    "X_P2 = tf.transform(df_P2.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "\n",
    "y_train34 = df_concat34.genre.to_numpy()\n",
    "y_P1 = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train34, y_train34)\n",
    "\n",
    "y_pred_P1 = naive_bayes.predict(X_P1)\n",
    "y_pred_P2 = naive_bayes.predict(X_P2)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "print('P1', classification_report(y_P1, y_pred_P1))\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes alter auf neuer Korpus - Manchester Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.98      0.85      0.91        59\n",
      "        HUMA       0.79      0.63      0.70        67\n",
      "        LEGA       0.98      0.88      0.93        67\n",
      "        NARR       0.73      0.91      0.81        67\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.89      0.84      0.86        67\n",
      "        SERM       0.77      0.98      0.86        65\n",
      "\n",
      "    accuracy                           0.84       393\n",
      "   macro avg       0.74      0.73      0.73       393\n",
      "weighted avg       0.85      0.84      0.84       393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_man = tf.fit_transform(df_man.text)\n",
    "X_test_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train_man = df_man.genre.to_numpy()\n",
    "y_test_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train_man, y_train_man)\n",
    "\n",
    "y_pred_inn = naive_bayes.predict(X_test_inn)\n",
    "print(classification_report(y_test_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SERM' 'DRAM' 'SCIE' 'LEGA' 'HUMA' 'HUMA' 'LEGA' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SCIE' 'LEGA' 'NARR' 'DRAM' 'SCIE' 'NARR' 'SERM' 'SERM' 'NARR'\n",
      " 'LEGA' 'SERM' 'SERM' 'LEGA' 'SCIE' 'DRAM' 'SERM' 'SCIE' 'SCIE' 'HUMA'\n",
      " 'SERM' 'NARR' 'NARR' 'SCIE' 'LEGA' 'DRAM' 'NARR' 'DRAM' 'SERM' 'HUMA'\n",
      " 'NARR' 'SCIE' 'LEGA' 'DRAM' 'SCIE' 'DRAM' 'HUMA' 'HUMA' 'DRAM' 'HUMA'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'NARR' 'NARR' 'LEGA' 'SCIE' 'LEGA'\n",
      " 'HUMA' 'DRAM' 'SERM' 'NARR' 'DRAM' 'SERM' 'SCIE' 'SERM' 'LEGA' 'LEGA'\n",
      " 'DRAM' 'NARR' 'SCIE' 'NARR' 'LEGA' 'HUMA' 'SCIE' 'NARR' 'HUMA' 'SCIE'\n",
      " 'SERM' 'SCIE' 'HUMA' 'SERM' 'LEGA' 'SCIE' 'HUMA' 'DRAM' 'SERM' 'NARR'\n",
      " 'NARR' 'SERM' 'HUMA' 'SERM' 'NARR' 'SERM' 'DRAM' 'SCIE' 'NARR' 'NARR'\n",
      " 'SERM' 'DRAM' 'NARR' 'HUMA' 'LEGA' 'NARR' 'NARR' 'SCIE' 'HUMA' 'LEGA'\n",
      " 'NARR' 'SERM' 'HUMA' 'SERM' 'DRAM' 'HUMA' 'NARR' 'SCIE' 'DRAM' 'DRAM'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'SERM' 'SCIE' 'NARR' 'NARR' 'LEGA' 'HUMA' 'DRAM'\n",
      " 'SERM' 'NARR' 'NARR' 'LEGA' 'SCIE' 'NARR' 'NARR' 'SERM' 'LEGA' 'HUMA'\n",
      " 'NARR' 'SERM' 'DRAM' 'LEGA' 'SERM' 'HUMA' 'DRAM' 'SERM' 'SCIE' 'NARR'\n",
      " 'HUMA' 'SCIE' 'SERM' 'HUMA' 'DRAM' 'SCIE' 'HUMA' 'SERM' 'SCIE' 'SERM'\n",
      " 'NARR' 'HUMA' 'SERM' 'HUMA' 'NARR' 'LEGA' 'LEGA' 'DRAM' 'NARR' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'NARR' 'HUMA' 'LEGA' 'NARR' 'NARR' 'LEGA' 'SCIE' 'SERM'\n",
      " 'DRAM' 'SERM' 'LEGA' 'NARR' 'DRAM' 'NARR' 'SERM' 'HUMA' 'HUMA' 'SERM'\n",
      " 'SCIE' 'SCIE' 'LEGA' 'LEGA' 'LEGA' 'HUMA' 'NARR' 'SCIE' 'LEGA' 'SERM'\n",
      " 'SCIE' 'SERM' 'NARR' 'NARR' 'SCIE' 'SERM' 'HUMA' 'NARR' 'LEGA' 'HUMA'\n",
      " 'NARR' 'HUMA' 'SCIE' 'HUMA' 'LEGA' 'DRAM' 'SCIE' 'HUMA' 'SERM' 'DRAM'\n",
      " 'NARR' 'SERM' 'SERM' 'LEGA' 'SERM' 'NARR' 'NARR' 'DRAM' 'HUMA' 'HUMA'\n",
      " 'NARR' 'LEGA' 'LEGA' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SERM' 'SCIE' 'LEGA'\n",
      " 'SERM' 'SERM' 'DRAM' 'SERM' 'SCIE' 'HUMA' 'LEGA' 'NARR' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'NARR' 'SERM' 'NARR' 'SCIE' 'SERM' 'LEGA' 'SERM' 'LEGA' 'SERM'\n",
      " 'SERM' 'HUMA' 'NARR' 'SCIE' 'SCIE' 'NARR' 'HUMA' 'SERM' 'SERM' 'SERM'\n",
      " 'SCIE' 'LEGA' 'SERM' 'SERM' 'NARR' 'SERM' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'NARR' 'DRAM' 'LEGA' 'DRAM' 'HUMA' 'NARR' 'LEGA' 'SERM' 'DRAM' 'SCIE'\n",
      " 'DRAM' 'LEGA' 'NARR' 'NARR' 'DRAM' 'HUMA' 'SCIE' 'LEGA' 'NARR' 'SERM'\n",
      " 'HUMA' 'LEGA' 'SERM' 'NARR' 'NARR' 'SCIE' 'HUMA' 'SERM' 'HUMA' 'NARR'\n",
      " 'SCIE' 'NARR' 'LEGA' 'SERM' 'NARR' 'HUMA' 'SERM' 'LEGA' 'DRAM' 'DRAM'\n",
      " 'LEGA' 'LEGA' 'SCIE' 'LEGA' 'NARR' 'SCIE' 'SCIE' 'NARR' 'NARR' 'NARR'\n",
      " 'SERM' 'DRAM' 'DRAM' 'SERM' 'NARR' 'SERM' 'NARR' 'SERM' 'SERM' 'LEGA'\n",
      " 'NARR' 'LEGA' 'NARR' 'HUMA' 'SERM' 'LEGA' 'DRAM' 'DRAM' 'HUMA' 'SCIE'\n",
      " 'SCIE' 'NARR' 'DRAM' 'SCIE' 'DRAM' 'SCIE' 'SCIE' 'HUMA' 'SERM' 'NARR'\n",
      " 'HUMA' 'NARR' 'DRAM' 'NARR' 'SERM' 'SCIE' 'NARR' 'SCIE' 'DRAM' 'NARR'\n",
      " 'DRAM' 'SERM' 'LEGA' 'SERM' 'SERM' 'SERM' 'SCIE' 'SCIE' 'NARR' 'HUMA'\n",
      " 'LEGA' 'NARR' 'NARR' 'HUMA' 'SERM' 'HUMA' 'NARR' 'DRAM' 'HUMA' 'SERM'\n",
      " 'DRAM' 'SCIE' 'NARR'] \n",
      "\n",
      " ['HUMA' 'DRAM' 'SCIE' 'LEGA' 'HUMA' 'HUMA' 'LEGA' 'SERM' 'SCIE' 'LEGA'\n",
      " 'SERM' 'SCIE' 'LEGA' 'HUMA' 'DRAM' 'HUMA' 'NARR' 'HUMA' 'SERM' 'NARR'\n",
      " 'LEGA' 'SERM' 'SERM' 'LEGA' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'HUMA'\n",
      " 'SERM' 'NARR' 'NARR' 'SCIE' 'LEGA' 'NARR' 'NARR' 'DRAM' 'SERM' 'HUMA'\n",
      " 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'SCIE' 'DRAM' 'HUMA' 'HUMA' 'DRAM' 'HUMA'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'DRAM' 'DRAM' 'LEGA' 'SCIE' 'LEGA'\n",
      " 'HUMA' 'DRAM' 'SERM' 'NARR' 'DRAM' 'SCIE' 'SCIE' 'SERM' 'LEGA' 'LEGA'\n",
      " 'DRAM' 'NARR' 'SCIE' 'NARR' 'LEGA' 'HUMA' 'SCIE' 'NARR' 'HUMA' 'LEGA'\n",
      " 'SERM' 'SCIE' 'HUMA' 'SERM' 'LEGA' 'SCIE' 'HUMA' 'DRAM' 'SERM' 'SERM'\n",
      " 'SCIE' 'SERM' 'HUMA' 'SERM' 'NARR' 'SERM' 'DRAM' 'SCIE' 'HUMA' 'NARR'\n",
      " 'SERM' 'DRAM' 'NARR' 'HUMA' 'LEGA' 'NARR' 'NARR' 'SCIE' 'SCIE' 'LEGA'\n",
      " 'NARR' 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'HUMA' 'NARR' 'SCIE' 'DRAM' 'DRAM'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'SERM' 'SCIE' 'NARR' 'NARR' 'LEGA' 'HUMA' 'DRAM'\n",
      " 'SERM' 'HUMA' 'NARR' 'LEGA' 'SCIE' 'HUMA' 'DRAM' 'SERM' 'LEGA' 'HUMA'\n",
      " 'NARR' 'SERM' 'DRAM' 'LEGA' 'SERM' 'HUMA' 'DRAM' 'SERM' 'HUMA' 'NARR'\n",
      " 'HUMA' 'SCIE' 'SERM' 'HUMA' 'DRAM' 'SCIE' 'HUMA' 'SERM' 'HUMA' 'SERM'\n",
      " 'NARR' 'HUMA' 'SERM' 'HUMA' 'NARR' 'LEGA' 'LEGA' 'DRAM' 'NARR' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'HUMA' 'HUMA' 'LEGA' 'NARR' 'NARR' 'LEGA' 'SCIE' 'SERM'\n",
      " 'DRAM' 'SERM' 'LEGA' 'NARR' 'DRAM' 'NARR' 'SERM' 'HUMA' 'HUMA' 'SERM'\n",
      " 'HUMA' 'SCIE' 'LEGA' 'LEGA' 'LEGA' 'HUMA' 'NARR' 'SCIE' 'LEGA' 'SERM'\n",
      " 'HUMA' 'SERM' 'NARR' 'NARR' 'SCIE' 'SERM' 'SCIE' 'NARR' 'LEGA' 'SCIE'\n",
      " 'NARR' 'SCIE' 'SCIE' 'HUMA' 'LEGA' 'DRAM' 'SCIE' 'HUMA' 'SERM' 'DRAM'\n",
      " 'HUMA' 'SERM' 'NARR' 'LEGA' 'SERM' 'NARR' 'NARR' 'DRAM' 'HUMA' 'LEGA'\n",
      " 'NARR' 'LEGA' 'LEGA' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SERM' 'SCIE' 'LEGA'\n",
      " 'NARR' 'SERM' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'LEGA' 'NARR' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'NARR' 'SERM' 'DRAM' 'SCIE' 'SERM' 'LEGA' 'HUMA' 'LEGA' 'SERM'\n",
      " 'SERM' 'LEGA' 'DRAM' 'SCIE' 'SCIE' 'NARR' 'HUMA' 'SERM' 'SERM' 'HUMA'\n",
      " 'SCIE' 'LEGA' 'NARR' 'SERM' 'NARR' 'DRAM' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'NARR' 'DRAM' 'LEGA' 'DRAM' 'LEGA' 'NARR' 'LEGA' 'SERM' 'DRAM' 'SCIE'\n",
      " 'DRAM' 'LEGA' 'NARR' 'NARR' 'DRAM' 'HUMA' 'SCIE' 'LEGA' 'NARR' 'SERM'\n",
      " 'HUMA' 'NEWS-P4' 'SERM' 'NARR' 'NARR' 'SCIE' 'LEGA' 'SERM' 'HUMA' 'NARR'\n",
      " 'SCIE' 'NARR' 'LEGA' 'HUMA' 'HUMA' 'HUMA' 'SERM' 'LEGA' 'DRAM' 'DRAM'\n",
      " 'LEGA' 'LEGA' 'SCIE' 'LEGA' 'HUMA' 'SCIE' 'SCIE' 'NARR' 'NARR' 'HUMA'\n",
      " 'SERM' 'DRAM' 'DRAM' 'NARR' 'NARR' 'SERM' 'DRAM' 'HUMA' 'SERM' 'LEGA'\n",
      " 'NARR' 'LEGA' 'NARR' 'HUMA' 'SERM' 'LEGA' 'DRAM' 'DRAM' 'LEGA' 'HUMA'\n",
      " 'SCIE' 'NARR' 'DRAM' 'SCIE' 'DRAM' 'SCIE' 'SCIE' 'HUMA' 'SERM' 'HUMA'\n",
      " 'HUMA' 'NARR' 'DRAM' 'NARR' 'SERM' 'SCIE' 'NARR' 'SCIE' 'DRAM' 'HUMA'\n",
      " 'DRAM' 'SERM' 'LEGA' 'SERM' 'SERM' 'SERM' 'SCIE' 'SCIE' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'NARR' 'NARR' 'HUMA' 'SERM' 'HUMA' 'NARR' 'DRAM' 'HUMA' 'NARR'\n",
      " 'DRAM' 'SCIE' 'HUMA']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_inn,'\\n\\n', y_test_inn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes neuer auf alter Korpus - Innsbruck Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.02      0.04        45\n",
      "        HUMA       0.67      0.13      0.22        45\n",
      "        LEGA       1.00      0.22      0.36        45\n",
      "        NARR       0.42      0.76      0.54        45\n",
      "        SCIE       1.00      0.20      0.33        45\n",
      "        SERM       0.28      1.00      0.44        45\n",
      "\n",
      "    accuracy                           0.39       270\n",
      "   macro avg       0.73      0.39      0.32       270\n",
      "weighted avg       0.73      0.39      0.32       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_inn = tf.fit_transform(df_inn.text)\n",
    "X_test_man = tf.transform(df_man.text)\n",
    "\n",
    "y_train_inn = df_inn.genre.to_numpy()\n",
    "y_test_man = df_man.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train_inn, y_train_inn)\n",
    "\n",
    "y_pred_man = naive_bayes.predict(X_test_man)\n",
    "print(classification_report(y_test_man, y_pred_man))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SERM' 'NARR' 'NARR' 'SERM' 'SERM' 'SERM' 'SERM' 'LEGA' 'SERM' 'SERM'\n",
      " 'NARR' 'NARR' 'SERM' 'SERM' 'NARR' 'HUMA' 'SERM' 'NARR' 'LEGA' 'SERM'\n",
      " 'SERM' 'NARR' 'SERM' 'SERM' 'NARR' 'SERM' 'SERM' 'NARR' 'SERM' 'SCIE'\n",
      " 'NARR' 'SERM' 'NARR' 'SERM' 'SERM' 'SERM' 'DRAM' 'NARR' 'SERM' 'SERM'\n",
      " 'SERM' 'NARR' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'LEGA' 'SERM' 'SERM'\n",
      " 'NARR' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'NARR' 'NARR' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'LEGA' 'NARR' 'SERM' 'NARR' 'SERM' 'NARR' 'SERM'\n",
      " 'SERM' 'NARR' 'NARR' 'SERM' 'NARR' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'NARR' 'SERM' 'NARR' 'SERM' 'SERM' 'NARR' 'HUMA' 'SERM'\n",
      " 'SERM' 'NARR' 'NARR' 'SERM' 'SERM' 'SCIE' 'SERM' 'NARR' 'SERM' 'NARR'\n",
      " 'SERM' 'SERM' 'NARR' 'SERM' 'SERM' 'NARR' 'NARR' 'NARR' 'HUMA' 'SERM'\n",
      " 'SCIE' 'SERM' 'SERM' 'LEGA' 'NARR' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'NARR' 'SERM' 'SERM' 'SERM' 'NARR' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'NARR' 'SCIE' 'NARR' 'SERM' 'NARR' 'NARR' 'SCIE'\n",
      " 'NARR' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'NARR' 'SERM' 'SERM' 'LEGA' 'SERM' 'SERM' 'SCIE' 'SERM' 'SERM' 'SERM'\n",
      " 'NARR' 'NARR' 'NARR' 'SERM' 'SERM' 'NARR' 'SERM' 'NARR' 'SERM' 'HUMA'\n",
      " 'NARR' 'HUMA' 'SERM' 'SERM' 'LEGA' 'SERM' 'SERM' 'SCIE' 'SERM' 'NARR'\n",
      " 'NARR' 'NARR' 'SERM' 'SERM' 'NARR' 'SERM' 'SERM' 'SERM' 'SERM' 'LEGA'\n",
      " 'SERM' 'SERM' 'NARR' 'SERM' 'SERM' 'SERM' 'NARR' 'HUMA' 'SERM' 'SERM'\n",
      " 'SERM' 'NARR' 'NARR' 'SERM' 'SERM' 'NARR' 'SERM' 'NARR' 'NARR' 'SERM'\n",
      " 'LEGA' 'NARR' 'SERM' 'SERM' 'NARR' 'LEGA' 'SERM' 'SERM' 'SERM' 'SCIE'\n",
      " 'NARR' 'SERM' 'HUMA' 'SERM' 'SERM' 'NARR' 'SERM' 'SERM' 'NARR' 'SERM'\n",
      " 'HUMA' 'NARR' 'NARR' 'SERM' 'SERM' 'SERM' 'NARR' 'SERM' 'NARR' 'SERM'\n",
      " 'SERM' 'NARR' 'SERM' 'SERM' 'NARR' 'NARR' 'SERM' 'SERM' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'HUMA' 'SERM' 'NARR' 'NARR' 'SERM' 'NARR' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'NARR' 'SERM' 'NARR' 'SERM' 'SERM' 'SERM'] \n",
      "\n",
      " ['HUMA' 'NARR' 'SCIE' 'SCIE' 'SERM' 'SERM' 'SCIE' 'LEGA' 'SERM' 'HUMA'\n",
      " 'NARR' 'NARR' 'NARR' 'DRAM' 'NARR' 'HUMA' 'SERM' 'NARR' 'LEGA' 'SERM'\n",
      " 'SERM' 'LEGA' 'DRAM' 'SCIE' 'DRAM' 'SCIE' 'HUMA' 'NARR' 'NARR' 'SCIE'\n",
      " 'NARR' 'DRAM' 'DRAM' 'HUMA' 'SCIE' 'LEGA' 'DRAM' 'HUMA' 'SERM' 'SCIE'\n",
      " 'DRAM' 'NARR' 'LEGA' 'SCIE' 'SERM' 'LEGA' 'SERM' 'LEGA' 'LEGA' 'SERM'\n",
      " 'NARR' 'LEGA' 'SERM' 'SCIE' 'DRAM' 'HUMA' 'SERM' 'NARR' 'NARR' 'DRAM'\n",
      " 'SERM' 'NARR' 'SCIE' 'LEGA' 'NARR' 'SERM' 'NARR' 'LEGA' 'NARR' 'LEGA'\n",
      " 'HUMA' 'DRAM' 'DRAM' 'NARR' 'NARR' 'SCIE' 'SERM' 'DRAM' 'NARR' 'DRAM'\n",
      " 'SERM' 'LEGA' 'NARR' 'HUMA' 'NARR' 'SERM' 'SCIE' 'LEGA' 'HUMA' 'SERM'\n",
      " 'DRAM' 'HUMA' 'HUMA' 'SCIE' 'SERM' 'SCIE' 'SCIE' 'NARR' 'SERM' 'HUMA'\n",
      " 'LEGA' 'DRAM' 'DRAM' 'LEGA' 'SCIE' 'HUMA' 'NARR' 'HUMA' 'NARR' 'HUMA'\n",
      " 'SCIE' 'LEGA' 'SCIE' 'LEGA' 'HUMA' 'LEGA' 'HUMA' 'SERM' 'SCIE' 'SERM'\n",
      " 'DRAM' 'LEGA' 'DRAM' 'HUMA' 'SCIE' 'LEGA' 'NARR' 'SERM' 'SERM' 'DRAM'\n",
      " 'HUMA' 'NARR' 'SERM' 'HUMA' 'SCIE' 'NARR' 'SERM' 'HUMA' 'DRAM' 'SCIE'\n",
      " 'SCIE' 'SERM' 'SERM' 'LEGA' 'LEGA' 'HUMA' 'SCIE' 'DRAM' 'DRAM' 'LEGA'\n",
      " 'SCIE' 'SERM' 'DRAM' 'LEGA' 'SCIE' 'DRAM' 'SCIE' 'LEGA' 'SCIE' 'SERM'\n",
      " 'SCIE' 'NARR' 'HUMA' 'HUMA' 'LEGA' 'NARR' 'NARR' 'DRAM' 'LEGA' 'HUMA'\n",
      " 'NARR' 'HUMA' 'LEGA' 'NARR' 'LEGA' 'LEGA' 'SCIE' 'SCIE' 'SCIE' 'NARR'\n",
      " 'SCIE' 'DRAM' 'HUMA' 'HUMA' 'HUMA' 'NARR' 'DRAM' 'SERM' 'LEGA' 'LEGA'\n",
      " 'SERM' 'SERM' 'SCIE' 'LEGA' 'SERM' 'NARR' 'NARR' 'LEGA' 'DRAM' 'SERM'\n",
      " 'DRAM' 'SCIE' 'NARR' 'DRAM' 'HUMA' 'DRAM' 'HUMA' 'SCIE' 'DRAM' 'SCIE'\n",
      " 'LEGA' 'HUMA' 'LEGA' 'SERM' 'HUMA' 'LEGA' 'SCIE' 'LEGA' 'DRAM' 'SCIE'\n",
      " 'DRAM' 'LEGA' 'HUMA' 'SERM' 'SERM' 'NARR' 'SERM' 'DRAM' 'NARR' 'SCIE'\n",
      " 'SCIE' 'NARR' 'DRAM' 'SERM' 'HUMA' 'SERM' 'SCIE' 'SERM' 'LEGA' 'SERM'\n",
      " 'LEGA' 'LEGA' 'HUMA' 'HUMA' 'NARR' 'NARR' 'SERM' 'SCIE' 'DRAM' 'DRAM'\n",
      " 'HUMA' 'DRAM' 'HUMA' 'DRAM' 'NARR' 'NARR' 'HUMA' 'DRAM' 'HUMA' 'SERM'\n",
      " 'HUMA' 'SCIE' 'DRAM' 'HUMA' 'DRAM' 'LEGA' 'HUMA' 'LEGA' 'DRAM' 'DRAM']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_man,'\\n\\n', y_test_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression P1 auf den rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.fit_transform(df_P1.text)\n",
    "X_P2 = tf.transform(df_P2.text)\n",
    "X_P3 = tf.transform(df_P3.text)\n",
    "X_P4 = tf.transform(df_P4.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "\n",
    "y_train = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.53      0.70        15\n",
      "        HUMA       0.28      0.53      0.36        15\n",
      "        LEGA       0.89      0.53      0.67        15\n",
      "        NARR       0.64      0.93      0.76        15\n",
      "        SCIE       0.58      0.47      0.52        15\n",
      "        SERM       0.90      0.60      0.72        15\n",
      "\n",
      "    accuracy                           0.60        90\n",
      "   macro avg       0.71      0.60      0.62        90\n",
      "weighted avg       0.71      0.60      0.62        90\n",
      "\n",
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.64      0.47      0.54        15\n",
      "        HUMA       0.29      0.93      0.44        15\n",
      "        LEGA       1.00      0.33      0.50        15\n",
      "        NARR       0.59      0.67      0.62        15\n",
      "        SCIE       0.71      0.33      0.45        15\n",
      "        SERM       1.00      0.07      0.12        15\n",
      "\n",
      "    accuracy                           0.47        90\n",
      "   macro avg       0.70      0.47      0.45        90\n",
      "weighted avg       0.70      0.47      0.45        90\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.17      1.00      0.29        22\n",
      "        HUMA       0.00      0.00      0.00        24\n",
      "        LEGA       1.00      0.08      0.15        25\n",
      "        NARR       0.00      0.00      0.00        26\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       0.80      0.18      0.30        22\n",
      "\n",
      "    accuracy                           0.20       139\n",
      "   macro avg       0.33      0.21      0.12       139\n",
      "weighted avg       0.33      0.20      0.12       139\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.15      1.00      0.27        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       1.00      0.10      0.18        20\n",
      "        NARR       0.00      0.00      0.00        22\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       1.00      0.23      0.37        22\n",
      "\n",
      "    accuracy                           0.20       124\n",
      "   macro avg       0.36      0.22      0.14       124\n",
      "weighted avg       0.36      0.20      0.13       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.15      1.00      0.27        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       1.00      0.05      0.09        22\n",
      "        NARR       0.00      0.00      0.00        19\n",
      "        SCIE       0.00      0.00      0.00        27\n",
      "        SERM       0.80      0.19      0.31        21\n",
      "\n",
      "    accuracy                           0.19       129\n",
      "   macro avg       0.33      0.21      0.11       129\n",
      "weighted avg       0.32      0.19      0.10       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred_P2 = log_reg.predict(X_P2)\n",
    "y_pred_P3 = log_reg.predict(X_P3)\n",
    "y_pred_P4 = log_reg.predict(X_P4)\n",
    "y_pred_P5 = log_reg.predict(X_P5)\n",
    "y_pred_P6 = log_reg.predict(X_P6)\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression P1 und P2 konkateniert auf den Rest angewandt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.67      0.53      0.59        15\n",
      "        HUMA       0.42      0.93      0.58        15\n",
      "        LEGA       1.00      0.53      0.70        15\n",
      "        NARR       0.59      0.87      0.70        15\n",
      "        SCIE       0.86      0.40      0.55        15\n",
      "        SERM       1.00      0.53      0.70        15\n",
      "\n",
      "    accuracy                           0.63        90\n",
      "   macro avg       0.76      0.63      0.64        90\n",
      "weighted avg       0.76      0.63      0.64        90\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.16      1.00      0.28        22\n",
      "        HUMA       0.00      0.00      0.00        24\n",
      "        LEGA       1.00      0.04      0.08        25\n",
      "        NARR       0.00      0.00      0.00        26\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.19       139\n",
      "   macro avg       0.36      0.20      0.10       139\n",
      "weighted avg       0.36      0.19      0.10       139\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.15      1.00      0.26        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       0.00      0.00      0.00        20\n",
      "        NARR       0.00      0.00      0.00        22\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.16       124\n",
      "   macro avg       0.19      0.18      0.07       124\n",
      "weighted avg       0.20      0.16      0.07       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.15      1.00      0.26        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       0.00      0.00      0.00        22\n",
      "        NARR       0.00      0.00      0.00        19\n",
      "        SCIE       0.00      0.00      0.00        27\n",
      "        SERM       1.00      0.05      0.09        21\n",
      "\n",
      "    accuracy                           0.16       129\n",
      "   macro avg       0.19      0.17      0.06       129\n",
      "weighted avg       0.18      0.16      0.05       129\n",
      "\n",
      "Inn               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.15      1.00      0.27        59\n",
      "        HUMA       0.00      0.00      0.00        67\n",
      "        LEGA       1.00      0.01      0.03        67\n",
      "        NARR       0.00      0.00      0.00        67\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.00      0.00      0.00        67\n",
      "        SERM       1.00      0.09      0.17        65\n",
      "\n",
      "    accuracy                           0.17       393\n",
      "   macro avg       0.31      0.16      0.07       393\n",
      "weighted avg       0.36      0.17      0.07       393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train12 = tf.fit_transform(df_concat12.text)\n",
    "X_P3 = tf.transform(df_P3.text)\n",
    "X_P4 = tf.transform(df_P4.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "X_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train12 = df_concat12.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "y_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train12, y_train12)\n",
    "\n",
    "y_pred_P3 = log_reg.predict(X_P3)\n",
    "y_pred_P4 = log_reg.predict(X_P4)\n",
    "y_pred_P5 = log_reg.predict(X_P5)\n",
    "y_pred_P6 = log_reg.predict(X_P6)\n",
    "y_pred_inn = log_reg.predict(X_inn)\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))\n",
    "print('Inn', classification_report(y_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression P3 und P4 angewandt auf den Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.45      0.33      0.38        15\n",
      "        LEGA       0.86      0.80      0.83        15\n",
      "        NARR       0.44      0.73      0.55        15\n",
      "        SCIE       0.82      0.60      0.69        15\n",
      "        SERM       0.48      0.93      0.64        15\n",
      "\n",
      "    accuracy                           0.57        90\n",
      "   macro avg       0.51      0.57      0.52        90\n",
      "weighted avg       0.51      0.57      0.52        90\n",
      "\n",
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.38      0.40      0.39        15\n",
      "        LEGA       0.87      0.87      0.87        15\n",
      "        NARR       0.52      0.87      0.65        15\n",
      "        SCIE       0.73      0.53      0.62        15\n",
      "        SERM       0.65      1.00      0.79        15\n",
      "\n",
      "    accuracy                           0.61        90\n",
      "   macro avg       0.52      0.61      0.55        90\n",
      "weighted avg       0.52      0.61      0.55        90\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.90      1.00      0.95        18\n",
      "        HUMA       1.00      0.73      0.84        22\n",
      "        LEGA       0.95      1.00      0.98        20\n",
      "        NARR       1.00      1.00      1.00        22\n",
      "        SCIE       0.83      1.00      0.91        20\n",
      "        SERM       1.00      0.95      0.98        22\n",
      "\n",
      "    accuracy                           0.94       124\n",
      "   macro avg       0.95      0.95      0.94       124\n",
      "weighted avg       0.95      0.94      0.94       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.93      0.68      0.79        19\n",
      "        HUMA       0.87      0.62      0.72        21\n",
      "        LEGA       0.68      0.95      0.79        22\n",
      "        NARR       0.63      1.00      0.78        19\n",
      "        SCIE       1.00      0.70      0.83        27\n",
      "        SERM       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.80       129\n",
      "   macro avg       0.83      0.80      0.80       129\n",
      "weighted avg       0.84      0.80      0.80       129\n",
      "\n",
      "Inn, (!!Vorsicht!! ist in P4 identisch mit trainingsdaten)               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.95      0.90      0.92        59\n",
      "        HUMA       0.96      0.79      0.87        67\n",
      "        LEGA       0.85      0.99      0.91        67\n",
      "        NARR       0.86      1.00      0.92        67\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.94      0.88      0.91        67\n",
      "        SERM       0.97      0.94      0.95        65\n",
      "\n",
      "    accuracy                           0.91       393\n",
      "   macro avg       0.79      0.78      0.78       393\n",
      "weighted avg       0.92      0.91      0.91       393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train34 = tf.fit_transform(df_concat34.text)\n",
    "X_P1 = tf.transform(df_P1.text)\n",
    "X_P2 = tf.transform(df_P2.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "X_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train34 = df_concat34.genre.to_numpy()\n",
    "y_P1 = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "y_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train34, y_train34)\n",
    "\n",
    "y_pred_P1 = log_reg.predict(X_P1)\n",
    "y_pred_P2 = log_reg.predict(X_P2)\n",
    "y_pred_P5 = log_reg.predict(X_P5)\n",
    "y_pred_P6 = log_reg.predict(X_P6)\n",
    "y_pred_inn = log_reg.predict(X_inn)\n",
    "print('P1', classification_report(y_P1, y_pred_P1))\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))\n",
    "print('Inn, (!!Vorsicht!! ist in P4 identisch mit trainingsdaten)', classification_report(y_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression alter auf neuer - Manchester TRainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.15      1.00      0.26        59\n",
      "        HUMA       0.00      0.00      0.00        67\n",
      "        LEGA       0.00      0.00      0.00        67\n",
      "        NARR       0.00      0.00      0.00        67\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.00      0.00      0.00        67\n",
      "        SERM       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.15       393\n",
      "   macro avg       0.02      0.14      0.04       393\n",
      "weighted avg       0.02      0.15      0.04       393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_man = tf.fit_transform(df_man.text)\n",
    "X_test_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train_man = df_man.genre.to_numpy()\n",
    "y_test_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train_man, y_train_man)\n",
    "\n",
    "y_pred_inn = log_reg.predict(X_test_inn)\n",
    "print(classification_report(y_test_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression neuer auf alter Korpus - Innsbruck Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.79      0.84      0.82        45\n",
      "        HUMA       0.70      0.31      0.43        45\n",
      "        LEGA       0.95      0.84      0.89        45\n",
      "        NARR       0.58      0.91      0.71        45\n",
      "        SCIE       0.88      0.67      0.76        45\n",
      "        SERM       0.70      0.89      0.78        45\n",
      "\n",
      "    accuracy                           0.74       270\n",
      "   macro avg       0.77      0.74      0.73       270\n",
      "weighted avg       0.77      0.74      0.73       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_inn = tf.fit_transform(df_inn.text)\n",
    "X_test_man = tf.transform(df_man.text)\n",
    "\n",
    "y_train_inn = df_inn.genre.to_numpy()\n",
    "y_test_man = df_man.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train_inn, y_train_inn)\n",
    "\n",
    "y_pred_man = log_reg.predict(X_test_man)\n",
    "print(classification_report(y_test_man, y_pred_man))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

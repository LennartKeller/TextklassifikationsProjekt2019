{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(974, 8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv('full_dataset.csv')\n",
    "#df = shuffle(df, random_state=42)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>corpus</th>\n",
       "      <th>genre</th>\n",
       "      <th>period</th>\n",
       "      <th>region</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HUMA_P3_WMD_1777_HomburgRAW.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>HUMA</td>\n",
       "      <td>P3</td>\n",
       "      <td>WMD</td>\n",
       "      <td>Nachricht von den Alterthu&amp;#868;mern in dem Ge...</td>\n",
       "      <td>Homburg</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NEWS_P3_NoD_1786_wolfenbuettel1.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>P3</td>\n",
       "      <td>NoD</td>\n",
       "      <td>Zeitung\\r\\nfür\\r\\nStädte, Flecken und Dörfer,\\...</td>\n",
       "      <td>wolfenbuettel1</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NARR_P1_NoD_1658_MorgenlaendischRAW.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>NARR</td>\n",
       "      <td>P1</td>\n",
       "      <td>NoD</td>\n",
       "      <td>Das zwey vnd dreysigste Capitel.\\n      Des Pr...</td>\n",
       "      <td>Morgenlaendisch</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SCIE_P1_WMD_1680_EpidemicaRAW.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>SCIE</td>\n",
       "      <td>P1</td>\n",
       "      <td>WMD</td>\n",
       "      <td>Das XX. Capitel.\\n      Von den Schnecken.\\n  ...</td>\n",
       "      <td>Epidemica</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NEWS_P2_WMD_1701_hanau2.txt</td>\n",
       "      <td>manchester</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>P2</td>\n",
       "      <td>WMD</td>\n",
       "      <td>Extraordinari Europæische Zeitung. 1701. Num. ...</td>\n",
       "      <td>hanau2</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename      corpus genre period region  \\\n",
       "0          HUMA_P3_WMD_1777_HomburgRAW.txt  manchester  HUMA     P3    WMD   \n",
       "1      NEWS_P3_NoD_1786_wolfenbuettel1.txt  manchester  NEWS     P3    NoD   \n",
       "2  NARR_P1_NoD_1658_MorgenlaendischRAW.txt  manchester  NARR     P1    NoD   \n",
       "3        SCIE_P1_WMD_1680_EpidemicaRAW.txt  manchester  SCIE     P1    WMD   \n",
       "4              NEWS_P2_WMD_1701_hanau2.txt  manchester  NEWS     P2    WMD   \n",
       "\n",
       "                                                text            title  year  \n",
       "0  Nachricht von den Alterthu&#868;mern in dem Ge...          Homburg  1777  \n",
       "1  Zeitung\\r\\nfür\\r\\nStädte, Flecken und Dörfer,\\...   wolfenbuettel1  1786  \n",
       "2  Das zwey vnd dreysigste Capitel.\\n      Des Pr...  Morgenlaendisch  1658  \n",
       "3  Das XX. Capitel.\\n      Von den Schnecken.\\n  ...        Epidemica  1680  \n",
       "4  Extraordinari Europæische Zeitung. 1701. Num. ...           hanau2  1701  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#kompletter Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Achtung!!! Hier können die NEWS aus dem Datensatz herausgenommen werden - Einfach mit \\# kommentieren oder entkommentieren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df.genre != 'NEWS']\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teilung des Dataframes in die einzelnen Teilcorpora und Perioden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Teilung in Manchester und Innsbruck Dataframe, sowie in die einzelnen Perioden\n",
    "#Der einfachheit halber wird hier mit dem Dataframe.loc Attribut gearbeitet, weil es vergleichbar mit einem SQL-Statement ist ist\n",
    "#Hierfür jeweils eine eigene Zelle, damit man via Shape nochmal die Größe prüfen kann\n",
    "#Für die Tests können die einzelnen Dataframes wie gewünscht concateniert werden\n",
    "\n",
    "\n",
    "\n",
    "df_man = df.loc[df['corpus'] == 'manchester']\n",
    "df_man.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inn = df.loc[df['corpus'] == 'innsbruck']\n",
    "df_inn.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P1\n",
    "df_P1 = df.loc[df['period'] == 'P1']\n",
    "df_P1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P2\n",
    "df_P2 = df.loc[df['period'] == 'P2']\n",
    "df_P2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P3\n",
    "df_P3 = df.loc[df['period'] == 'P3']\n",
    "df_P3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P4\n",
    "df_P4 = df.loc[df['period'] == 'P4']\n",
    "df_P4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P5\n",
    "df_P5 = df.loc[df['period'] == 'P5']\n",
    "df_P5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P6\n",
    "df_P6 = df.loc[df['period'] == 'P6']\n",
    "df_P6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konkatenieren der einzelnen Teile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat34 = pd.concat((df_P3, df_P4))\n",
    "df_concat34.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat12 = pd.concat((df_P1, df_P2))\n",
    "df_concat12.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features P1 ist der Trainingskorpus, er heißt im folgenden _train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "tf = TfidfVectorizer(stop_words=get_stop_words('de'), max_features=20000)\n",
    "\n",
    "#Wie beim Lennart steht das X für die Texte und Y für die Label\n",
    "\n",
    "X_train = tf.fit_transform(df_P1.text)\n",
    "X_P2 = tf.transform(df_P2.text)\n",
    "X_P3 = tf.transform(df_P3.text)\n",
    "X_P4 = tf.transform(df_P4.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "\n",
    "y_train = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P1 auf die restlichen einzelnen Perioden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.33      0.50        15\n",
      "        HUMA       0.28      0.53      0.36        15\n",
      "        LEGA       1.00      0.33      0.50        15\n",
      "        NARR       0.54      0.93      0.68        15\n",
      "        NEWS       1.00      1.00      1.00        23\n",
      "        SCIE       0.78      0.47      0.58        15\n",
      "        SERM       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.66       113\n",
      "   macro avg       0.77      0.64      0.64       113\n",
      "weighted avg       0.79      0.66      0.66       113\n",
      "\n",
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.13      0.24        15\n",
      "        HUMA       0.35      0.80      0.49        15\n",
      "        LEGA       1.00      0.27      0.42        15\n",
      "        NARR       0.47      0.93      0.62        15\n",
      "        NEWS       0.95      1.00      0.97        18\n",
      "        SCIE       0.62      0.33      0.43        15\n",
      "        SERM       0.82      0.60      0.69        15\n",
      "\n",
      "    accuracy                           0.59       108\n",
      "   macro avg       0.74      0.58      0.55       108\n",
      "weighted avg       0.75      0.59      0.56       108\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.23      0.37        22\n",
      "        HUMA       0.00      0.00      0.00        24\n",
      "        LEGA       0.00      0.00      0.00        25\n",
      "        NARR       0.00      0.00      0.00        26\n",
      "        NEWS       0.48      1.00      0.65       108\n",
      "        SCIE       1.00      0.05      0.10        20\n",
      "        SERM       0.62      0.45      0.53        22\n",
      "\n",
      "    accuracy                           0.50       247\n",
      "   macro avg       0.44      0.25      0.23       247\n",
      "weighted avg       0.44      0.50      0.37       247\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       0.00      0.00      0.00        20\n",
      "        NARR       1.00      0.09      0.17        22\n",
      "        NEWS       0.42      1.00      0.59        84\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.45       208\n",
      "   macro avg       0.35      0.20      0.18       208\n",
      "weighted avg       0.38      0.45      0.31       208\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       0.00      0.00      0.00        22\n",
      "        NARR       0.00      0.00      0.00        19\n",
      "        NEWS       0.30      1.00      0.46        53\n",
      "        SCIE       0.00      0.00      0.00        27\n",
      "        SERM       1.00      0.14      0.25        21\n",
      "\n",
      "    accuracy                           0.31       182\n",
      "   macro avg       0.19      0.16      0.10       182\n",
      "weighted avg       0.20      0.31      0.16       182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "naive_bayes = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred_P2 = naive_bayes.predict(X_P2)\n",
    "y_pred_P3 = naive_bayes.predict(X_P3)\n",
    "y_pred_P4 = naive_bayes.predict(X_P4)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS'] \n",
      "\n",
      " ['NEWS' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SCIE' 'LEGA' 'HUMA' 'NEWS' 'HUMA'\n",
      " 'LEGA' 'NEWS' 'SERM' 'SCIE' 'NEWS' 'LEGA' 'SERM' 'SCIE' 'LEGA' 'HUMA'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NARR' 'HUMA' 'SERM' 'NARR'\n",
      " 'NEWS' 'LEGA' 'NEWS' 'SERM' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NARR' 'DRAM' 'SERM' 'NEWS' 'HUMA' 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'SCIE'\n",
      " 'NEWS' 'DRAM' 'HUMA' 'HUMA' 'DRAM' 'NEWS' 'HUMA' 'SCIE' 'SCIE' 'SERM'\n",
      " 'SERM' 'SERM' 'DRAM' 'DRAM' 'NEWS' 'LEGA' 'SCIE' 'LEGA' 'HUMA' 'DRAM'\n",
      " 'SERM' 'NARR' 'DRAM' 'NEWS' 'SCIE' 'NEWS' 'SCIE' 'SERM' 'LEGA' 'LEGA'\n",
      " 'DRAM' 'NARR' 'NEWS' 'SCIE' 'NARR' 'LEGA' 'HUMA' 'SCIE' 'NEWS' 'NARR'\n",
      " 'HUMA' 'LEGA' 'SERM' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'LEGA' 'SCIE' 'NEWS'\n",
      " 'HUMA' 'DRAM' 'SERM' 'NEWS' 'SERM' 'SCIE' 'SERM' 'HUMA' 'NEWS' 'SERM'\n",
      " 'NEWS' 'NARR' 'SERM' 'DRAM' 'NEWS' 'SCIE' 'HUMA' 'NEWS' 'NARR' 'SERM'\n",
      " 'DRAM' 'NARR' 'NEWS' 'NEWS' 'HUMA' 'LEGA' 'NARR' 'NARR' 'SCIE' 'SCIE'\n",
      " 'LEGA' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'DRAM' 'HUMA'\n",
      " 'NARR' 'NEWS' 'SCIE' 'DRAM' 'DRAM' 'NEWS' 'LEGA' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'SERM' 'SCIE' 'NARR' 'NARR' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'HUMA']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_P6,'\\n\\n', y_P6) #Vergleich der vorhergesagten mit den tatsächlichen Label durch NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P1 und P2 concateniert auf die restlichen Perioden und den neuen Korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.27      0.42        15\n",
      "        HUMA       0.44      0.80      0.57        15\n",
      "        LEGA       1.00      0.53      0.70        15\n",
      "        NARR       0.47      1.00      0.64        15\n",
      "        NEWS       1.00      1.00      1.00        18\n",
      "        SCIE       1.00      0.33      0.50        15\n",
      "        SERM       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.82      0.68      0.66       108\n",
      "weighted avg       0.83      0.69      0.67       108\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.41      0.58        22\n",
      "        HUMA       0.00      0.00      0.00        24\n",
      "        LEGA       0.00      0.00      0.00        25\n",
      "        NARR       0.57      0.15      0.24        26\n",
      "        NEWS       0.51      0.97      0.67       108\n",
      "        SCIE       0.80      0.20      0.32        20\n",
      "        SERM       0.71      0.68      0.70        22\n",
      "\n",
      "    accuracy                           0.55       247\n",
      "   macro avg       0.51      0.35      0.36       247\n",
      "weighted avg       0.50      0.55      0.46       247\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.17      0.29        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       0.00      0.00      0.00        20\n",
      "        NARR       1.00      0.09      0.17        22\n",
      "        NEWS       0.44      1.00      0.61        84\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.48       208\n",
      "   macro avg       0.48      0.25      0.24       208\n",
      "weighted avg       0.47      0.48      0.36       208\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       0.00      0.00      0.00        22\n",
      "        NARR       1.00      0.05      0.10        19\n",
      "        NEWS       0.31      1.00      0.47        53\n",
      "        SCIE       1.00      0.04      0.07        27\n",
      "        SERM       0.86      0.29      0.43        21\n",
      "\n",
      "    accuracy                           0.34       182\n",
      "   macro avg       0.45      0.20      0.15       182\n",
      "weighted avg       0.44      0.34      0.21       182\n",
      "\n",
      "Inn               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.20      0.34        59\n",
      "        HUMA       0.00      0.00      0.00        67\n",
      "        LEGA       0.00      0.00      0.00        67\n",
      "        NARR       0.70      0.10      0.18        67\n",
      "        NEWS       0.43      0.99      0.59       245\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.83      0.07      0.14        67\n",
      "        SERM       0.80      0.49      0.61        65\n",
      "\n",
      "    accuracy                           0.47       638\n",
      "   macro avg       0.47      0.23      0.23       638\n",
      "weighted avg       0.50      0.47      0.36       638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train12 = tf.fit_transform(df_concat12.text)\n",
    "X_P3 = tf.transform(df_P3.text)\n",
    "X_P4 = tf.transform(df_P4.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "X_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train12 = df_concat12.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "y_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train12, y_train12)\n",
    "\n",
    "y_pred_P3 = naive_bayes.predict(X_P3)\n",
    "y_pred_P4 = naive_bayes.predict(X_P4)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "y_pred_inn = naive_bayes.predict(X_inn)\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))\n",
    "print('Inn', classification_report(y_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NEWS' 'SERM'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'SERM' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'DRAM' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'SERM' 'NEWS' 'NEWS' 'DRAM' 'SCIE' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'NEWS'\n",
      " 'SERM' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'DRAM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'DRAM'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'DRAM' 'DRAM' 'SERM' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'DRAM' 'SERM'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM'\n",
      " 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SCIE'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'DRAM' 'SERM' 'NEWS' 'NEWS' 'SERM' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS'] \n",
      "\n",
      " ['NEWS' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SCIE' 'LEGA' 'HUMA' 'NEWS' 'HUMA'\n",
      " 'LEGA' 'NEWS' 'SERM' 'SCIE' 'NEWS' 'LEGA' 'SERM' 'SCIE' 'LEGA' 'HUMA'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NARR' 'HUMA' 'SERM' 'NARR'\n",
      " 'NEWS' 'LEGA' 'NEWS' 'SERM' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NARR' 'DRAM' 'SERM' 'NEWS' 'HUMA' 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'SCIE'\n",
      " 'NEWS' 'DRAM' 'HUMA' 'HUMA' 'DRAM' 'NEWS' 'HUMA' 'SCIE' 'SCIE' 'SERM'\n",
      " 'SERM' 'SERM' 'DRAM' 'DRAM' 'NEWS' 'LEGA' 'SCIE' 'LEGA' 'HUMA' 'DRAM'\n",
      " 'SERM' 'NARR' 'DRAM' 'NEWS' 'SCIE' 'NEWS' 'SCIE' 'SERM' 'LEGA' 'LEGA'\n",
      " 'DRAM' 'NARR' 'NEWS' 'SCIE' 'NARR' 'LEGA' 'HUMA' 'SCIE' 'NEWS' 'NARR'\n",
      " 'HUMA' 'LEGA' 'SERM' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'LEGA' 'SCIE' 'NEWS'\n",
      " 'HUMA' 'DRAM' 'SERM' 'NEWS' 'SERM' 'SCIE' 'SERM' 'HUMA' 'NEWS' 'SERM'\n",
      " 'NEWS' 'NARR' 'SERM' 'DRAM' 'NEWS' 'SCIE' 'HUMA' 'NEWS' 'NARR' 'SERM'\n",
      " 'DRAM' 'NARR' 'NEWS' 'NEWS' 'HUMA' 'LEGA' 'NARR' 'NARR' 'SCIE' 'SCIE'\n",
      " 'LEGA' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'DRAM' 'HUMA'\n",
      " 'NARR' 'NEWS' 'SCIE' 'DRAM' 'DRAM' 'NEWS' 'LEGA' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'SERM' 'SCIE' 'NARR' 'NARR' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'HUMA' 'DRAM' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'HUMA' 'NEWS' 'NARR'\n",
      " 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NEWS' 'HUMA' 'DRAM'\n",
      " 'NEWS' 'NEWS' 'SERM' 'LEGA' 'HUMA' 'NARR' 'NEWS' 'SERM' 'DRAM' 'NEWS'\n",
      " 'LEGA' 'SERM' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SERM' 'NEWS' 'HUMA' 'NARR'\n",
      " 'NEWS' 'HUMA' 'SCIE' 'SERM' 'NEWS' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SCIE'\n",
      " 'HUMA' 'NEWS' 'SERM' 'HUMA' 'SERM' 'NARR' 'NEWS' 'HUMA' 'SERM' 'NEWS'\n",
      " 'NEWS' 'HUMA' 'NARR' 'NEWS' 'NEWS' 'LEGA' 'LEGA' 'DRAM' 'NEWS' 'NARR'\n",
      " 'NEWS' 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'NEWS' 'HUMA' 'LEGA' 'NARR' 'NARR'\n",
      " 'LEGA' 'NEWS' 'SCIE' 'SERM' 'DRAM' 'NEWS' 'SERM' 'LEGA' 'NARR' 'NEWS'\n",
      " 'DRAM' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'HUMA' 'NEWS' 'HUMA'\n",
      " 'NEWS' 'SERM' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'SCIE' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'HUMA' 'NARR' 'SCIE' 'LEGA' 'NEWS' 'SERM' 'HUMA' 'NEWS' 'NEWS' 'SERM'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'SERM'\n",
      " 'NEWS' 'NEWS' 'SCIE' 'NARR' 'LEGA' 'SCIE' 'NEWS' 'NARR' 'NEWS' 'NEWS'\n",
      " 'SCIE' 'SCIE' 'HUMA' 'LEGA' 'DRAM' 'SCIE' 'NEWS' 'NEWS' 'HUMA' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'SERM' 'DRAM' 'HUMA' 'SERM' 'NARR' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NARR' 'NEWS' 'NARR' 'DRAM' 'HUMA' 'LEGA' 'NARR'\n",
      " 'NEWS' 'LEGA' 'LEGA' 'SCIE' 'DRAM' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'SCIE'\n",
      " 'SERM' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'DRAM' 'SCIE' 'SCIE' 'NEWS' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NARR' 'NEWS' 'SCIE' 'SCIE' 'NEWS' 'SCIE' 'NARR' 'NEWS' 'SERM' 'NEWS'\n",
      " 'DRAM' 'NEWS' 'SCIE' 'NEWS' 'SERM' 'LEGA' 'HUMA' 'NEWS' 'NEWS' 'LEGA'\n",
      " 'NEWS' 'SERM' 'SERM' 'NEWS' 'LEGA' 'DRAM' 'SCIE' 'SCIE' 'NARR' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'HUMA' 'SERM' 'SERM' 'HUMA' 'NEWS' 'SCIE' 'LEGA' 'NEWS'\n",
      " 'NARR' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NARR' 'DRAM' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'LEGA' 'NEWS' 'LEGA' 'LEGA' 'NARR' 'NEWS' 'NEWS' 'DRAM' 'LEGA'\n",
      " 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'NARR' 'LEGA' 'SERM' 'DRAM'\n",
      " 'NEWS' 'NEWS' 'SCIE' 'DRAM' 'LEGA' 'NARR' 'NEWS' 'NARR' 'DRAM' 'NEWS'\n",
      " 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'SERM' 'HUMA'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS-P4' 'SERM' 'NARR' 'NARR' 'SCIE'\n",
      " 'LEGA' 'SERM' 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'NARR'\n",
      " 'LEGA' 'NEWS' 'NEWS' 'NEWS' 'HUMA' 'HUMA' 'HUMA' 'SERM' 'LEGA' 'DRAM'\n",
      " 'DRAM' 'LEGA' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'LEGA' 'HUMA' 'SCIE' 'SCIE' 'NARR' 'NEWS' 'NARR' 'HUMA'\n",
      " 'SERM' 'DRAM' 'DRAM' 'NARR' 'NEWS' 'NARR' 'SERM' 'NEWS' 'DRAM' 'HUMA'\n",
      " 'NEWS' 'SERM' 'LEGA' 'NEWS' 'NARR' 'NEWS' 'LEGA' 'NEWS' 'NARR' 'HUMA'\n",
      " 'SERM' 'LEGA' 'NEWS' 'DRAM' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'HUMA'\n",
      " 'NEWS' 'SCIE' 'NARR' 'NEWS' 'DRAM' 'NEWS' 'SCIE' 'DRAM' 'SCIE' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'HUMA'\n",
      " 'HUMA' 'NEWS' 'NARR' 'NEWS' 'DRAM' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'SCIE' 'NARR' 'SCIE' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'HUMA'\n",
      " 'DRAM' 'SERM' 'NEWS' 'LEGA' 'SERM' 'SERM' 'SERM' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'SCIE' 'SCIE' 'NEWS' 'HUMA' 'NEWS' 'HUMA' 'LEGA' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'HUMA' 'NARR' 'NEWS' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'HUMA' 'NEWS' 'NARR' 'DRAM' 'NEWS' 'SCIE' 'HUMA']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_inn,'\\n\\n', y_inn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P3 und P4 concateniert auf die restlichen Perioden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.20      0.07      0.10        15\n",
      "        LEGA       0.91      0.67      0.77        15\n",
      "        NARR       0.38      0.87      0.53        15\n",
      "        NEWS       1.00      1.00      1.00        25\n",
      "        SCIE       0.00      0.00      0.00        15\n",
      "        SERM       0.35      0.93      0.51        15\n",
      "\n",
      "    accuracy                           0.55       115\n",
      "   macro avg       0.41      0.50      0.42       115\n",
      "weighted avg       0.46      0.55      0.47       115\n",
      "\n",
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.33      0.13      0.19        15\n",
      "        LEGA       0.91      0.67      0.77        15\n",
      "        NARR       0.31      0.87      0.46        15\n",
      "        NEWS       1.00      1.00      1.00        23\n",
      "        SCIE       0.00      0.00      0.00        15\n",
      "        SERM       0.48      1.00      0.65        15\n",
      "\n",
      "    accuracy                           0.56       113\n",
      "   macro avg       0.43      0.52      0.44       113\n",
      "weighted avg       0.47      0.56      0.48       113\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       0.00      0.00      0.00        20\n",
      "        NARR       0.00      0.00      0.00        22\n",
      "        NEWS       0.41      1.00      0.58        84\n",
      "        SCIE       1.00      0.05      0.10        20\n",
      "        SERM       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.42       208\n",
      "   macro avg       0.34      0.17      0.13       208\n",
      "weighted avg       0.37      0.42      0.27       208\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       0.00      0.00      0.00        22\n",
      "        NARR       0.00      0.00      0.00        19\n",
      "        NEWS       0.29      1.00      0.45        53\n",
      "        SCIE       0.00      0.00      0.00        27\n",
      "        SERM       1.00      0.10      0.17        21\n",
      "\n",
      "    accuracy                           0.30       182\n",
      "   macro avg       0.18      0.16      0.09       182\n",
      "weighted avg       0.20      0.30      0.15       182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train34 = tf.fit_transform(df_concat34.text)\n",
    "X_P1 = tf.transform(df_P1.text)\n",
    "X_P2 = tf.transform(df_P2.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "\n",
    "y_train34 = df_concat34.genre.to_numpy()\n",
    "y_P1 = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train34, y_train34)\n",
    "\n",
    "y_pred_P1 = naive_bayes.predict(X_P1)\n",
    "y_pred_P2 = naive_bayes.predict(X_P2)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "print('P1', classification_report(y_P1, y_pred_P1))\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes alter auf neuer Korpus - Manchester Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.19      0.31        59\n",
      "        HUMA       0.62      0.07      0.13        67\n",
      "        LEGA       0.75      0.04      0.08        67\n",
      "        NARR       0.65      0.16      0.26        67\n",
      "        NEWS       0.43      0.97      0.60       245\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       1.00      0.10      0.19        67\n",
      "        SERM       0.87      0.51      0.64        65\n",
      "\n",
      "    accuracy                           0.48       638\n",
      "   macro avg       0.67      0.26      0.28       638\n",
      "weighted avg       0.66      0.48      0.39       638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_man = tf.fit_transform(df_man.text)\n",
    "X_test_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train_man = df_man.genre.to_numpy()\n",
    "y_test_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train_man, y_train_man)\n",
    "\n",
    "y_pred_inn = naive_bayes.predict(X_test_inn)\n",
    "print(classification_report(y_test_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'SERM' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'DRAM' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'LEGA' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'SERM' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'NEWS' 'HUMA'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'LEGA' 'SCIE' 'NEWS' 'NEWS'\n",
      " 'SERM' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'DRAM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS'\n",
      " 'HUMA' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'DRAM'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NEWS' 'DRAM' 'DRAM' 'SERM' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NARR' 'SERM'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'HUMA'\n",
      " 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'HUMA' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'HUMA' 'NARR' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'DRAM' 'SERM' 'NEWS' 'NEWS' 'SERM' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'SERM' 'NARR' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'HUMA' 'NARR' 'NEWS' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'DRAM' 'NEWS' 'SCIE' 'NEWS'] \n",
      "\n",
      " ['NEWS' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SCIE' 'LEGA' 'HUMA' 'NEWS' 'HUMA'\n",
      " 'LEGA' 'NEWS' 'SERM' 'SCIE' 'NEWS' 'LEGA' 'SERM' 'SCIE' 'LEGA' 'HUMA'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NARR' 'HUMA' 'SERM' 'NARR'\n",
      " 'NEWS' 'LEGA' 'NEWS' 'SERM' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NARR' 'DRAM' 'SERM' 'NEWS' 'HUMA' 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'SCIE'\n",
      " 'NEWS' 'DRAM' 'HUMA' 'HUMA' 'DRAM' 'NEWS' 'HUMA' 'SCIE' 'SCIE' 'SERM'\n",
      " 'SERM' 'SERM' 'DRAM' 'DRAM' 'NEWS' 'LEGA' 'SCIE' 'LEGA' 'HUMA' 'DRAM'\n",
      " 'SERM' 'NARR' 'DRAM' 'NEWS' 'SCIE' 'NEWS' 'SCIE' 'SERM' 'LEGA' 'LEGA'\n",
      " 'DRAM' 'NARR' 'NEWS' 'SCIE' 'NARR' 'LEGA' 'HUMA' 'SCIE' 'NEWS' 'NARR'\n",
      " 'HUMA' 'LEGA' 'SERM' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'LEGA' 'SCIE' 'NEWS'\n",
      " 'HUMA' 'DRAM' 'SERM' 'NEWS' 'SERM' 'SCIE' 'SERM' 'HUMA' 'NEWS' 'SERM'\n",
      " 'NEWS' 'NARR' 'SERM' 'DRAM' 'NEWS' 'SCIE' 'HUMA' 'NEWS' 'NARR' 'SERM'\n",
      " 'DRAM' 'NARR' 'NEWS' 'NEWS' 'HUMA' 'LEGA' 'NARR' 'NARR' 'SCIE' 'SCIE'\n",
      " 'LEGA' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'DRAM' 'HUMA'\n",
      " 'NARR' 'NEWS' 'SCIE' 'DRAM' 'DRAM' 'NEWS' 'LEGA' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'SERM' 'SCIE' 'NARR' 'NARR' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'HUMA' 'DRAM' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'HUMA' 'NEWS' 'NARR'\n",
      " 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NEWS' 'HUMA' 'DRAM'\n",
      " 'NEWS' 'NEWS' 'SERM' 'LEGA' 'HUMA' 'NARR' 'NEWS' 'SERM' 'DRAM' 'NEWS'\n",
      " 'LEGA' 'SERM' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SERM' 'NEWS' 'HUMA' 'NARR'\n",
      " 'NEWS' 'HUMA' 'SCIE' 'SERM' 'NEWS' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SCIE'\n",
      " 'HUMA' 'NEWS' 'SERM' 'HUMA' 'SERM' 'NARR' 'NEWS' 'HUMA' 'SERM' 'NEWS'\n",
      " 'NEWS' 'HUMA' 'NARR' 'NEWS' 'NEWS' 'LEGA' 'LEGA' 'DRAM' 'NEWS' 'NARR'\n",
      " 'NEWS' 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'NEWS' 'HUMA' 'LEGA' 'NARR' 'NARR'\n",
      " 'LEGA' 'NEWS' 'SCIE' 'SERM' 'DRAM' 'NEWS' 'SERM' 'LEGA' 'NARR' 'NEWS'\n",
      " 'DRAM' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'HUMA' 'NEWS' 'HUMA'\n",
      " 'NEWS' 'SERM' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'SCIE' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'HUMA' 'NARR' 'SCIE' 'LEGA' 'NEWS' 'SERM' 'HUMA' 'NEWS' 'NEWS' 'SERM'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'SERM'\n",
      " 'NEWS' 'NEWS' 'SCIE' 'NARR' 'LEGA' 'SCIE' 'NEWS' 'NARR' 'NEWS' 'NEWS'\n",
      " 'SCIE' 'SCIE' 'HUMA' 'LEGA' 'DRAM' 'SCIE' 'NEWS' 'NEWS' 'HUMA' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'SERM' 'DRAM' 'HUMA' 'SERM' 'NARR' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NARR' 'NEWS' 'NARR' 'DRAM' 'HUMA' 'LEGA' 'NARR'\n",
      " 'NEWS' 'LEGA' 'LEGA' 'SCIE' 'DRAM' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'SCIE'\n",
      " 'SERM' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'DRAM' 'SCIE' 'SCIE' 'NEWS' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NARR' 'NEWS' 'SCIE' 'SCIE' 'NEWS' 'SCIE' 'NARR' 'NEWS' 'SERM' 'NEWS'\n",
      " 'DRAM' 'NEWS' 'SCIE' 'NEWS' 'SERM' 'LEGA' 'HUMA' 'NEWS' 'NEWS' 'LEGA'\n",
      " 'NEWS' 'SERM' 'SERM' 'NEWS' 'LEGA' 'DRAM' 'SCIE' 'SCIE' 'NARR' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'HUMA' 'SERM' 'SERM' 'HUMA' 'NEWS' 'SCIE' 'LEGA' 'NEWS'\n",
      " 'NARR' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NARR' 'DRAM' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'LEGA' 'NEWS' 'LEGA' 'LEGA' 'NARR' 'NEWS' 'NEWS' 'DRAM' 'LEGA'\n",
      " 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'NARR' 'LEGA' 'SERM' 'DRAM'\n",
      " 'NEWS' 'NEWS' 'SCIE' 'DRAM' 'LEGA' 'NARR' 'NEWS' 'NARR' 'DRAM' 'NEWS'\n",
      " 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'SERM' 'HUMA'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS-P4' 'SERM' 'NARR' 'NARR' 'SCIE'\n",
      " 'LEGA' 'SERM' 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'NARR'\n",
      " 'LEGA' 'NEWS' 'NEWS' 'NEWS' 'HUMA' 'HUMA' 'HUMA' 'SERM' 'LEGA' 'DRAM'\n",
      " 'DRAM' 'LEGA' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'LEGA' 'HUMA' 'SCIE' 'SCIE' 'NARR' 'NEWS' 'NARR' 'HUMA'\n",
      " 'SERM' 'DRAM' 'DRAM' 'NARR' 'NEWS' 'NARR' 'SERM' 'NEWS' 'DRAM' 'HUMA'\n",
      " 'NEWS' 'SERM' 'LEGA' 'NEWS' 'NARR' 'NEWS' 'LEGA' 'NEWS' 'NARR' 'HUMA'\n",
      " 'SERM' 'LEGA' 'NEWS' 'DRAM' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'HUMA'\n",
      " 'NEWS' 'SCIE' 'NARR' 'NEWS' 'DRAM' 'NEWS' 'SCIE' 'DRAM' 'SCIE' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'HUMA'\n",
      " 'HUMA' 'NEWS' 'NARR' 'NEWS' 'DRAM' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'SCIE' 'NARR' 'SCIE' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'HUMA'\n",
      " 'DRAM' 'SERM' 'NEWS' 'LEGA' 'SERM' 'SERM' 'SERM' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'SCIE' 'SCIE' 'NEWS' 'HUMA' 'NEWS' 'HUMA' 'LEGA' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'HUMA' 'NARR' 'NEWS' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'HUMA' 'NEWS' 'NARR' 'DRAM' 'NEWS' 'SCIE' 'HUMA']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_inn,'\\n\\n', y_test_inn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes neuer auf alter Korpus - Innsbruck Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        45\n",
      "        HUMA       0.00      0.00      0.00        45\n",
      "        LEGA       0.00      0.00      0.00        45\n",
      "        NARR       0.00      0.00      0.00        45\n",
      "        NEWS       0.21      1.00      0.35        66\n",
      "        SCIE       0.00      0.00      0.00        45\n",
      "        SERM       0.93      0.56      0.69        45\n",
      "\n",
      "    accuracy                           0.27       336\n",
      "   macro avg       0.16      0.22      0.15       336\n",
      "weighted avg       0.17      0.27      0.16       336\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_inn = tf.fit_transform(df_inn.text)\n",
    "X_test_man = tf.transform(df_man.text)\n",
    "\n",
    "y_train_inn = df_inn.genre.to_numpy()\n",
    "y_test_man = df_man.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train_inn, y_train_inn)\n",
    "\n",
    "y_pred_man = naive_bayes.predict(X_test_man)\n",
    "print(classification_report(y_test_man, y_pred_man))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'SERM' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'DRAM' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'LEGA' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'SERM' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'NEWS' 'HUMA'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'LEGA' 'SCIE' 'NEWS' 'NEWS'\n",
      " 'SERM' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'DRAM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS'\n",
      " 'HUMA' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'DRAM'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NEWS' 'DRAM' 'DRAM' 'SERM' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'NARR' 'SERM'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'HUMA'\n",
      " 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'HUMA' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'HUMA' 'NARR' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NARR'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'DRAM' 'SERM' 'NEWS' 'NEWS' 'SERM' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'SERM' 'NARR' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'HUMA' 'NARR' 'NEWS' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'DRAM' 'NEWS' 'SCIE' 'NEWS'] \n",
      "\n",
      " ['NEWS' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SCIE' 'LEGA' 'HUMA' 'NEWS' 'HUMA'\n",
      " 'LEGA' 'NEWS' 'SERM' 'SCIE' 'NEWS' 'LEGA' 'SERM' 'SCIE' 'LEGA' 'HUMA'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NARR' 'HUMA' 'SERM' 'NARR'\n",
      " 'NEWS' 'LEGA' 'NEWS' 'SERM' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'DRAM' 'DRAM' 'SCIE' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NARR' 'DRAM' 'SERM' 'NEWS' 'HUMA' 'SCIE' 'SCIE' 'LEGA' 'DRAM' 'SCIE'\n",
      " 'NEWS' 'DRAM' 'HUMA' 'HUMA' 'DRAM' 'NEWS' 'HUMA' 'SCIE' 'SCIE' 'SERM'\n",
      " 'SERM' 'SERM' 'DRAM' 'DRAM' 'NEWS' 'LEGA' 'SCIE' 'LEGA' 'HUMA' 'DRAM'\n",
      " 'SERM' 'NARR' 'DRAM' 'NEWS' 'SCIE' 'NEWS' 'SCIE' 'SERM' 'LEGA' 'LEGA'\n",
      " 'DRAM' 'NARR' 'NEWS' 'SCIE' 'NARR' 'LEGA' 'HUMA' 'SCIE' 'NEWS' 'NARR'\n",
      " 'HUMA' 'LEGA' 'SERM' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'LEGA' 'SCIE' 'NEWS'\n",
      " 'HUMA' 'DRAM' 'SERM' 'NEWS' 'SERM' 'SCIE' 'SERM' 'HUMA' 'NEWS' 'SERM'\n",
      " 'NEWS' 'NARR' 'SERM' 'DRAM' 'NEWS' 'SCIE' 'HUMA' 'NEWS' 'NARR' 'SERM'\n",
      " 'DRAM' 'NARR' 'NEWS' 'NEWS' 'HUMA' 'LEGA' 'NARR' 'NARR' 'SCIE' 'SCIE'\n",
      " 'LEGA' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'DRAM' 'HUMA'\n",
      " 'NARR' 'NEWS' 'SCIE' 'DRAM' 'DRAM' 'NEWS' 'LEGA' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'SERM' 'SCIE' 'NARR' 'NARR' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'HUMA' 'DRAM' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'HUMA' 'NEWS' 'NARR'\n",
      " 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'SCIE' 'NEWS' 'NEWS' 'NEWS' 'HUMA' 'DRAM'\n",
      " 'NEWS' 'NEWS' 'SERM' 'LEGA' 'HUMA' 'NARR' 'NEWS' 'SERM' 'DRAM' 'NEWS'\n",
      " 'LEGA' 'SERM' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SERM' 'NEWS' 'HUMA' 'NARR'\n",
      " 'NEWS' 'HUMA' 'SCIE' 'SERM' 'NEWS' 'NEWS' 'HUMA' 'DRAM' 'NEWS' 'SCIE'\n",
      " 'HUMA' 'NEWS' 'SERM' 'HUMA' 'SERM' 'NARR' 'NEWS' 'HUMA' 'SERM' 'NEWS'\n",
      " 'NEWS' 'HUMA' 'NARR' 'NEWS' 'NEWS' 'LEGA' 'LEGA' 'DRAM' 'NEWS' 'NARR'\n",
      " 'NEWS' 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'NEWS' 'HUMA' 'LEGA' 'NARR' 'NARR'\n",
      " 'LEGA' 'NEWS' 'SCIE' 'SERM' 'DRAM' 'NEWS' 'SERM' 'LEGA' 'NARR' 'NEWS'\n",
      " 'DRAM' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'SERM' 'NEWS' 'HUMA' 'NEWS' 'HUMA'\n",
      " 'NEWS' 'SERM' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'SCIE' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'HUMA' 'NARR' 'SCIE' 'LEGA' 'NEWS' 'SERM' 'HUMA' 'NEWS' 'NEWS' 'SERM'\n",
      " 'NARR' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'SCIE' 'NEWS' 'SERM'\n",
      " 'NEWS' 'NEWS' 'SCIE' 'NARR' 'LEGA' 'SCIE' 'NEWS' 'NARR' 'NEWS' 'NEWS'\n",
      " 'SCIE' 'SCIE' 'HUMA' 'LEGA' 'DRAM' 'SCIE' 'NEWS' 'NEWS' 'HUMA' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'SERM' 'DRAM' 'HUMA' 'SERM' 'NARR' 'LEGA' 'NEWS'\n",
      " 'NEWS' 'SERM' 'NEWS' 'NARR' 'NEWS' 'NARR' 'DRAM' 'HUMA' 'LEGA' 'NARR'\n",
      " 'NEWS' 'LEGA' 'LEGA' 'SCIE' 'DRAM' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'SCIE'\n",
      " 'SERM' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'NEWS' 'NEWS' 'SERM' 'NEWS'\n",
      " 'NEWS' 'DRAM' 'NEWS' 'DRAM' 'SCIE' 'SCIE' 'NEWS' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NARR' 'NEWS' 'SCIE' 'SCIE' 'NEWS' 'SCIE' 'NARR' 'NEWS' 'SERM' 'NEWS'\n",
      " 'DRAM' 'NEWS' 'SCIE' 'NEWS' 'SERM' 'LEGA' 'HUMA' 'NEWS' 'NEWS' 'LEGA'\n",
      " 'NEWS' 'SERM' 'SERM' 'NEWS' 'LEGA' 'DRAM' 'SCIE' 'SCIE' 'NARR' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'HUMA' 'SERM' 'SERM' 'HUMA' 'NEWS' 'SCIE' 'LEGA' 'NEWS'\n",
      " 'NARR' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NARR' 'DRAM' 'LEGA' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'LEGA' 'NEWS' 'LEGA' 'LEGA' 'NARR' 'NEWS' 'NEWS' 'DRAM' 'LEGA'\n",
      " 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'NARR' 'LEGA' 'SERM' 'DRAM'\n",
      " 'NEWS' 'NEWS' 'SCIE' 'DRAM' 'LEGA' 'NARR' 'NEWS' 'NARR' 'DRAM' 'NEWS'\n",
      " 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'SCIE' 'LEGA' 'NEWS' 'NARR' 'SERM' 'HUMA'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'NEWS-P4' 'SERM' 'NARR' 'NARR' 'SCIE'\n",
      " 'LEGA' 'SERM' 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'NARR' 'SCIE' 'NEWS' 'NARR'\n",
      " 'LEGA' 'NEWS' 'NEWS' 'NEWS' 'HUMA' 'HUMA' 'HUMA' 'SERM' 'LEGA' 'DRAM'\n",
      " 'DRAM' 'LEGA' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'LEGA' 'HUMA' 'SCIE' 'SCIE' 'NARR' 'NEWS' 'NARR' 'HUMA'\n",
      " 'SERM' 'DRAM' 'DRAM' 'NARR' 'NEWS' 'NARR' 'SERM' 'NEWS' 'DRAM' 'HUMA'\n",
      " 'NEWS' 'SERM' 'LEGA' 'NEWS' 'NARR' 'NEWS' 'LEGA' 'NEWS' 'NARR' 'HUMA'\n",
      " 'SERM' 'LEGA' 'NEWS' 'DRAM' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'LEGA' 'HUMA'\n",
      " 'NEWS' 'SCIE' 'NARR' 'NEWS' 'DRAM' 'NEWS' 'SCIE' 'DRAM' 'SCIE' 'NEWS'\n",
      " 'NEWS' 'SCIE' 'HUMA' 'NEWS' 'SERM' 'NEWS' 'NEWS' 'NEWS' 'NEWS' 'HUMA'\n",
      " 'HUMA' 'NEWS' 'NARR' 'NEWS' 'DRAM' 'NARR' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'SCIE' 'NARR' 'SCIE' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'HUMA'\n",
      " 'DRAM' 'SERM' 'NEWS' 'LEGA' 'SERM' 'SERM' 'SERM' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'SCIE' 'SCIE' 'NEWS' 'HUMA' 'NEWS' 'HUMA' 'LEGA' 'NEWS' 'NARR' 'NEWS'\n",
      " 'NEWS' 'NEWS' 'NEWS' 'NARR' 'NEWS' 'HUMA' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'SERM' 'HUMA' 'NARR' 'NEWS' 'DRAM' 'NEWS' 'NEWS' 'NEWS' 'NEWS'\n",
      " 'NEWS' 'HUMA' 'NEWS' 'NARR' 'DRAM' 'NEWS' 'SCIE' 'HUMA']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_inn,'\\n\\n', y_inn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression P1 auf den rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.fit_transform(df_P1.text)\n",
    "X_P2 = tf.transform(df_P2.text)\n",
    "X_P3 = tf.transform(df_P3.text)\n",
    "X_P4 = tf.transform(df_P4.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "\n",
    "y_train = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.33      0.50        15\n",
      "        HUMA       0.26      0.73      0.39        15\n",
      "        LEGA       1.00      0.33      0.50        15\n",
      "        NARR       0.61      0.93      0.74        15\n",
      "        NEWS       0.92      1.00      0.96        23\n",
      "        SCIE       0.83      0.33      0.48        15\n",
      "        SERM       1.00      0.47      0.64        15\n",
      "\n",
      "    accuracy                           0.62       113\n",
      "   macro avg       0.80      0.59      0.60       113\n",
      "weighted avg       0.81      0.62      0.62       113\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.20      0.33        15\n",
      "        HUMA       0.28      1.00      0.44        15\n",
      "        LEGA       1.00      0.27      0.42        15\n",
      "        NARR       0.56      0.67      0.61        15\n",
      "        NEWS       0.72      1.00      0.84        18\n",
      "        SCIE       0.75      0.20      0.32        15\n",
      "        SERM       1.00      0.07      0.12        15\n",
      "\n",
      "    accuracy                           0.50       108\n",
      "   macro avg       0.76      0.49      0.44       108\n",
      "weighted avg       0.76      0.50      0.45       108\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        22\n",
      "        HUMA       0.00      0.00      0.00        24\n",
      "        LEGA       0.00      0.00      0.00        25\n",
      "        NARR       0.00      0.00      0.00        26\n",
      "        NEWS       0.44      1.00      0.61       108\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.44       247\n",
      "   macro avg       0.06      0.14      0.09       247\n",
      "weighted avg       0.19      0.44      0.27       247\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       0.00      0.00      0.00        20\n",
      "        NARR       0.00      0.00      0.00        22\n",
      "        NEWS       0.40      1.00      0.58        84\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.40       208\n",
      "   macro avg       0.06      0.14      0.08       208\n",
      "weighted avg       0.16      0.40      0.23       208\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       0.00      0.00      0.00        22\n",
      "        NARR       0.00      0.00      0.00        19\n",
      "        NEWS       0.29      1.00      0.45        53\n",
      "        SCIE       0.00      0.00      0.00        27\n",
      "        SERM       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.29       182\n",
      "   macro avg       0.04      0.14      0.06       182\n",
      "weighted avg       0.08      0.29      0.13       182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred_P2 = log_reg.predict(X_P2)\n",
    "y_pred_P3 = log_reg.predict(X_P3)\n",
    "y_pred_P4 = log_reg.predict(X_P4)\n",
    "y_pred_P5 = log_reg.predict(X_P5)\n",
    "y_pred_P6 = log_reg.predict(X_P6)\n",
    "print(classification_report(y_P2, y_pred_P2))\n",
    "print(classification_report(y_P3, y_pred_P3))\n",
    "print(classification_report(y_P4, y_pred_P4))\n",
    "print(classification_report(y_P5, y_pred_P5))\n",
    "print(classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression P1 und P2 konkateniert auf den Rest angewandt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.27      0.42        15\n",
      "        HUMA       0.40      0.93      0.56        15\n",
      "        LEGA       1.00      0.47      0.64        15\n",
      "        NARR       0.58      0.93      0.72        15\n",
      "        NEWS       0.72      1.00      0.84        18\n",
      "        SCIE       1.00      0.33      0.50        15\n",
      "        SERM       1.00      0.53      0.70        15\n",
      "\n",
      "    accuracy                           0.65       108\n",
      "   macro avg       0.81      0.64      0.62       108\n",
      "weighted avg       0.81      0.65      0.63       108\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        22\n",
      "        HUMA       0.00      0.00      0.00        24\n",
      "        LEGA       0.00      0.00      0.00        25\n",
      "        NARR       0.00      0.00      0.00        26\n",
      "        NEWS       0.44      1.00      0.61       108\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.44       247\n",
      "   macro avg       0.06      0.14      0.09       247\n",
      "weighted avg       0.19      0.44      0.27       247\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       0.00      0.00      0.00        20\n",
      "        NARR       0.00      0.00      0.00        22\n",
      "        NEWS       0.40      1.00      0.58        84\n",
      "        SCIE       0.00      0.00      0.00        20\n",
      "        SERM       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.40       208\n",
      "   macro avg       0.06      0.14      0.08       208\n",
      "weighted avg       0.16      0.40      0.23       208\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       0.00      0.00      0.00        22\n",
      "        NARR       0.00      0.00      0.00        19\n",
      "        NEWS       0.29      1.00      0.45        53\n",
      "        SCIE       0.00      0.00      0.00        27\n",
      "        SERM       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.29       182\n",
      "   macro avg       0.04      0.14      0.06       182\n",
      "weighted avg       0.08      0.29      0.13       182\n",
      "\n",
      "Inn               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        59\n",
      "        HUMA       0.00      0.00      0.00        67\n",
      "        LEGA       0.00      0.00      0.00        67\n",
      "        NARR       0.00      0.00      0.00        67\n",
      "        NEWS       0.38      1.00      0.55       245\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.00      0.00      0.00        67\n",
      "        SERM       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.38       638\n",
      "   macro avg       0.05      0.12      0.07       638\n",
      "weighted avg       0.15      0.38      0.21       638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train12 = tf.fit_transform(df_concat12.text)\n",
    "X_P3 = tf.transform(df_P3.text)\n",
    "X_P4 = tf.transform(df_P4.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "X_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train12 = df_concat12.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "y_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train12, y_train12)\n",
    "\n",
    "y_pred_P3 = log_reg.predict(X_P3)\n",
    "y_pred_P4 = log_reg.predict(X_P4)\n",
    "y_pred_P5 = log_reg.predict(X_P5)\n",
    "y_pred_P6 = log_reg.predict(X_P6)\n",
    "y_pred_inn = log_reg.predict(X_inn)\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))\n",
    "print('Inn', classification_report(y_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression P3 und P4 angewandt auf den Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.38      0.33      0.36        15\n",
      "        LEGA       0.86      0.80      0.83        15\n",
      "        NARR       0.42      0.67      0.51        15\n",
      "        NEWS       1.00      1.00      1.00        25\n",
      "        SCIE       0.75      0.60      0.67        15\n",
      "        SERM       0.52      0.93      0.67        15\n",
      "\n",
      "    accuracy                           0.65       115\n",
      "   macro avg       0.56      0.62      0.58       115\n",
      "weighted avg       0.60      0.65      0.61       115\n",
      "\n",
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.39      0.47      0.42        15\n",
      "        LEGA       0.87      0.87      0.87        15\n",
      "        NARR       0.50      0.87      0.63        15\n",
      "        NEWS       1.00      1.00      1.00        23\n",
      "        SCIE       0.70      0.47      0.56        15\n",
      "        SERM       0.71      1.00      0.83        15\n",
      "\n",
      "    accuracy                           0.69       113\n",
      "   macro avg       0.60      0.67      0.62       113\n",
      "weighted avg       0.62      0.69      0.64       113\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        18\n",
      "        HUMA       0.00      0.00      0.00        22\n",
      "        LEGA       0.00      0.00      0.00        20\n",
      "        NARR       1.00      0.09      0.17        22\n",
      "        NEWS       0.42      1.00      0.60        84\n",
      "        SCIE       1.00      0.05      0.10        20\n",
      "        SERM       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.45       208\n",
      "   macro avg       0.49      0.21      0.19       208\n",
      "weighted avg       0.48      0.45      0.32       208\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        19\n",
      "        HUMA       0.00      0.00      0.00        21\n",
      "        LEGA       0.00      0.00      0.00        22\n",
      "        NARR       0.00      0.00      0.00        19\n",
      "        NEWS       0.30      1.00      0.47        53\n",
      "        SCIE       0.00      0.00      0.00        27\n",
      "        SERM       0.86      0.29      0.43        21\n",
      "\n",
      "    accuracy                           0.32       182\n",
      "   macro avg       0.17      0.18      0.13       182\n",
      "weighted avg       0.19      0.32      0.19       182\n",
      "\n",
      "Inn, (!!Vorsicht!! ist in P4 identisch mit trainingsdaten)               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.10      0.18        59\n",
      "        HUMA       1.00      0.10      0.19        67\n",
      "        LEGA       1.00      0.01      0.03        67\n",
      "        NARR       0.94      0.24      0.38        67\n",
      "        NEWS       0.44      1.00      0.61       245\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       1.00      0.13      0.24        67\n",
      "        SERM       0.97      0.52      0.68        65\n",
      "\n",
      "    accuracy                           0.50       638\n",
      "   macro avg       0.79      0.26      0.29       638\n",
      "weighted avg       0.77      0.50      0.41       638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train34 = tf.fit_transform(df_concat34.text)\n",
    "X_P1 = tf.transform(df_P1.text)\n",
    "X_P2 = tf.transform(df_P2.text)\n",
    "X_P5 = tf.transform(df_P5.text)\n",
    "X_P6 = tf.transform(df_P6.text)\n",
    "X_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train34 = df_concat34.genre.to_numpy()\n",
    "y_P1 = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "y_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train34, y_train34)\n",
    "\n",
    "y_pred_P1 = log_reg.predict(X_P1)\n",
    "y_pred_P2 = log_reg.predict(X_P2)\n",
    "y_pred_P5 = log_reg.predict(X_P5)\n",
    "y_pred_P6 = log_reg.predict(X_P6)\n",
    "y_pred_inn = log_reg.predict(X_inn)\n",
    "print('P1', classification_report(y_P1, y_pred_P1))\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))\n",
    "print('Inn, (!!Vorsicht!! ist in P4 identisch mit trainingsdaten)', classification_report(y_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression alter auf neuer - Manchester TRainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        59\n",
      "        HUMA       0.00      0.00      0.00        67\n",
      "        LEGA       0.00      0.00      0.00        67\n",
      "        NARR       0.00      0.00      0.00        67\n",
      "        NEWS       0.38      1.00      0.55       245\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.00      0.00      0.00        67\n",
      "        SERM       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.38       638\n",
      "   macro avg       0.05      0.12      0.07       638\n",
      "weighted avg       0.15      0.38      0.21       638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_man = tf.fit_transform(df_man.text)\n",
    "X_test_inn = tf.transform(df_inn.text)\n",
    "\n",
    "y_train_man = df_man.genre.to_numpy()\n",
    "y_test_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train_man, y_train_man)\n",
    "\n",
    "y_pred_inn = log_reg.predict(X_test_inn)\n",
    "print(classification_report(y_test_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression neuer auf alter Korpus - Innsbruck Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.20      0.33        45\n",
      "        HUMA       1.00      0.07      0.12        45\n",
      "        LEGA       0.00      0.00      0.00        45\n",
      "        NARR       0.76      0.36      0.48        45\n",
      "        NEWS       0.26      1.00      0.41        66\n",
      "        SCIE       1.00      0.02      0.04        45\n",
      "        SERM       0.84      0.82      0.83        45\n",
      "\n",
      "    accuracy                           0.39       336\n",
      "   macro avg       0.69      0.35      0.32       336\n",
      "weighted avg       0.67      0.39      0.32       336\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_inn = tf.fit_transform(df_inn.text)\n",
    "X_test_man = tf.transform(df_man.text)\n",
    "\n",
    "y_train_inn = df_inn.genre.to_numpy()\n",
    "y_test_man = df_man.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train_inn, y_train_inn)\n",
    "\n",
    "y_pred_man = log_reg.predict(X_test_man)\n",
    "print(classification_report(y_test_man, y_pred_man))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

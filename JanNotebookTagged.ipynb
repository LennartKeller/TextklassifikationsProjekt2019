{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(974, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv('full_taggeddataset.csv')\n",
    "#df = shuffle(df, random_state=42)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>period</th>\n",
       "      <th>region</th>\n",
       "      <th>year</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>So koͤmmet euch der LoͤwRitter schwermuͤtig vo...</td>\n",
       "      <td>ADV VVFIN PPER ART NE ADJD PTKVZ SENT ITJ PPER...</td>\n",
       "      <td>so kommen ihr d Löwritter schwermütig vor ? ja...</td>\n",
       "      <td>Leonilda.txt</td>\n",
       "      <td>DRAM</td>\n",
       "      <td>P1</td>\n",
       "      <td>NoD</td>\n",
       "      <td>1673</td>\n",
       "      <td>manchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ARmes herz / laß ab zu hoffen / weil das gluͤc...</td>\n",
       "      <td>ADJA NN $, VVIMP PTKVZ PTKZU VVINF $, KOUS PDS...</td>\n",
       "      <td>arm Herz / lassen ab zu hoffen / weil d glück ...</td>\n",
       "      <td>Euridice.txt</td>\n",
       "      <td>DRAM</td>\n",
       "      <td>P1</td>\n",
       "      <td>NoD</td>\n",
       "      <td>1699</td>\n",
       "      <td>manchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ACh / ich bin schon so müde / das ich kaum meh...</td>\n",
       "      <td>ITJ $, PPER VAFIN ADV ADV ADJD $, PRELS PPER A...</td>\n",
       "      <td>ach / ich sein schon so müde / d ich kaum mehr...</td>\n",
       "      <td>Freyheit.txt</td>\n",
       "      <td>DRAM</td>\n",
       "      <td>P1</td>\n",
       "      <td>NoD</td>\n",
       "      <td>1700</td>\n",
       "      <td>manchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>So ists ! er ließ mich hoch vnd uͤberhoch bela...</td>\n",
       "      <td>ADV VAFIN SENT PPER VVFIN PPER ADJD KON NN VVI...</td>\n",
       "      <td>so sein ! er lassen ich hoch und überhoch bela...</td>\n",
       "      <td>Cardenio.txt</td>\n",
       "      <td>DRAM</td>\n",
       "      <td>P1</td>\n",
       "      <td>OMD</td>\n",
       "      <td>1657</td>\n",
       "      <td>manchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>VErtraute Charmium / dis ist di Lebens-Hoͤle ;...</td>\n",
       "      <td>NN NN $, PDS VAFIN FM NN SENT PDS VAFIN ART NN...</td>\n",
       "      <td>vertraute Charmium / dies sein -- Lebens-Höle ...</td>\n",
       "      <td>Cleopatra.txt</td>\n",
       "      <td>DRAM</td>\n",
       "      <td>P1</td>\n",
       "      <td>OMD</td>\n",
       "      <td>1661</td>\n",
       "      <td>manchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>969</td>\n",
       "      <td>633</td>\n",
       "      <td>Kameraden ! Daheim in den Silvester = Gottesdi...</td>\n",
       "      <td>NN $. ADV APPR ART NN $( NN VVFIN PPER ADV NN ...</td>\n",
       "      <td>Kamerad ! daheim in die Silvester = Gottesdien...</td>\n",
       "      <td>Zwölf</td>\n",
       "      <td>SERM</td>\n",
       "      <td>P6</td>\n",
       "      <td>WMD</td>\n",
       "      <td>1917</td>\n",
       "      <td>innsbruck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>634</td>\n",
       "      <td>Ein jeder Uebergang im Leben hat seine besonde...</td>\n",
       "      <td>ART PIAT NN APPRART NN VAFIN PPOSAT ADJA $, AD...</td>\n",
       "      <td>eine jede Uebergang in+die Leben haben sein be...</td>\n",
       "      <td>Hochzeits-Predigt</td>\n",
       "      <td>SERM</td>\n",
       "      <td>P6</td>\n",
       "      <td>WOD</td>\n",
       "      <td>1906</td>\n",
       "      <td>innsbruck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>971</td>\n",
       "      <td>635</td>\n",
       "      <td>Andächtige Christen , Geliebte im Herrn ! Als ...</td>\n",
       "      <td>ADJA NN $, NN APPRART NN $. KOUS ART ADJA NE P...</td>\n",
       "      <td>andächtig Christ , Geliebte in+die Herr ! als ...</td>\n",
       "      <td>Der</td>\n",
       "      <td>SERM</td>\n",
       "      <td>P6</td>\n",
       "      <td>WOD</td>\n",
       "      <td>1914</td>\n",
       "      <td>innsbruck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>972</td>\n",
       "      <td>636</td>\n",
       "      <td>Darum wollen wir mit getroster Zuversicht ihn ...</td>\n",
       "      <td>PAV VMFIN PPER APPR ADJA NN PPER VVINF $, KOUS...</td>\n",
       "      <td>darum wollen wir mit getroster Zuversicht er b...</td>\n",
       "      <td>Zur</td>\n",
       "      <td>SERM</td>\n",
       "      <td>P6</td>\n",
       "      <td>WOD</td>\n",
       "      <td>1916</td>\n",
       "      <td>innsbruck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>973</td>\n",
       "      <td>637</td>\n",
       "      <td>Die Eingliederung unserer evang. Jugendvereine...</td>\n",
       "      <td>ART NN PPOSAT ADJA NN APPR ART NN VAFIN PPOSAT...</td>\n",
       "      <td>die Eingliederung unser evang. Jugendverein in...</td>\n",
       "      <td>Unsere</td>\n",
       "      <td>SERM</td>\n",
       "      <td>P6</td>\n",
       "      <td>WOD</td>\n",
       "      <td>1934</td>\n",
       "      <td>innsbruck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             tokens  \\\n",
       "0             0  So koͤmmet euch der LoͤwRitter schwermuͤtig vo...   \n",
       "1             1  ARmes herz / laß ab zu hoffen / weil das gluͤc...   \n",
       "2             2  ACh / ich bin schon so müde / das ich kaum meh...   \n",
       "3             3  So ists ! er ließ mich hoch vnd uͤberhoch bela...   \n",
       "4             4  VErtraute Charmium / dis ist di Lebens-Hoͤle ;...   \n",
       "..          ...                                                ...   \n",
       "969         633  Kameraden ! Daheim in den Silvester = Gottesdi...   \n",
       "970         634  Ein jeder Uebergang im Leben hat seine besonde...   \n",
       "971         635  Andächtige Christen , Geliebte im Herrn ! Als ...   \n",
       "972         636  Darum wollen wir mit getroster Zuversicht ihn ...   \n",
       "973         637  Die Eingliederung unserer evang. Jugendvereine...   \n",
       "\n",
       "                                              pos_tags  \\\n",
       "0    ADV VVFIN PPER ART NE ADJD PTKVZ SENT ITJ PPER...   \n",
       "1    ADJA NN $, VVIMP PTKVZ PTKZU VVINF $, KOUS PDS...   \n",
       "2    ITJ $, PPER VAFIN ADV ADV ADJD $, PRELS PPER A...   \n",
       "3    ADV VAFIN SENT PPER VVFIN PPER ADJD KON NN VVI...   \n",
       "4    NN NN $, PDS VAFIN FM NN SENT PDS VAFIN ART NN...   \n",
       "..                                                 ...   \n",
       "969  NN $. ADV APPR ART NN $( NN VVFIN PPER ADV NN ...   \n",
       "970  ART PIAT NN APPRART NN VAFIN PPOSAT ADJA $, AD...   \n",
       "971  ADJA NN $, NN APPRART NN $. KOUS ART ADJA NE P...   \n",
       "972  PAV VMFIN PPER APPR ADJA NN PPER VVINF $, KOUS...   \n",
       "973  ART NN PPOSAT ADJA NN APPR ART NN VAFIN PPOSAT...   \n",
       "\n",
       "                                                lemmas              title  \\\n",
       "0    so kommen ihr d Löwritter schwermütig vor ? ja...       Leonilda.txt   \n",
       "1    arm Herz / lassen ab zu hoffen / weil d glück ...       Euridice.txt   \n",
       "2    ach / ich sein schon so müde / d ich kaum mehr...       Freyheit.txt   \n",
       "3    so sein ! er lassen ich hoch und überhoch bela...       Cardenio.txt   \n",
       "4    vertraute Charmium / dies sein -- Lebens-Höle ...      Cleopatra.txt   \n",
       "..                                                 ...                ...   \n",
       "969  Kamerad ! daheim in die Silvester = Gottesdien...              Zwölf   \n",
       "970  eine jede Uebergang in+die Leben haben sein be...  Hochzeits-Predigt   \n",
       "971  andächtig Christ , Geliebte in+die Herr ! als ...                Der   \n",
       "972  darum wollen wir mit getroster Zuversicht er b...                Zur   \n",
       "973  die Eingliederung unser evang. Jugendverein in...             Unsere   \n",
       "\n",
       "    genre period region  year      corpus  \n",
       "0    DRAM     P1    NoD  1673  manchester  \n",
       "1    DRAM     P1    NoD  1699  manchester  \n",
       "2    DRAM     P1    NoD  1700  manchester  \n",
       "3    DRAM     P1    OMD  1657  manchester  \n",
       "4    DRAM     P1    OMD  1661  manchester  \n",
       "..    ...    ...    ...   ...         ...  \n",
       "969  SERM     P6    WMD  1917   innsbruck  \n",
       "970  SERM     P6    WOD  1906   innsbruck  \n",
       "971  SERM     P6    WOD  1914   innsbruck  \n",
       "972  SERM     P6    WOD  1916   innsbruck  \n",
       "973  SERM     P6    WOD  1934   innsbruck  \n",
       "\n",
       "[974 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Achtung!!! Hier können die NEWS aus dem Datensatz herausgenommen werden - Einfach mit \\# kommentieren oder entkommentieren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                             tokens  \\\n",
      "0             0  So koͤmmet euch der LoͤwRitter schwermuͤtig vo...   \n",
      "1             1  ARmes herz / laß ab zu hoffen / weil das gluͤc...   \n",
      "2             2  ACh / ich bin schon so müde / das ich kaum meh...   \n",
      "3             3  So ists ! er ließ mich hoch vnd uͤberhoch bela...   \n",
      "4             4  VErtraute Charmium / dis ist di Lebens-Hoͤle ;...   \n",
      "..          ...                                                ...   \n",
      "969         633  Kameraden ! Daheim in den Silvester = Gottesdi...   \n",
      "970         634  Ein jeder Uebergang im Leben hat seine besonde...   \n",
      "971         635  Andächtige Christen , Geliebte im Herrn ! Als ...   \n",
      "972         636  Darum wollen wir mit getroster Zuversicht ihn ...   \n",
      "973         637  Die Eingliederung unserer evang. Jugendvereine...   \n",
      "\n",
      "                                              pos_tags  \\\n",
      "0    ADV VVFIN PPER ART NE ADJD PTKVZ SENT ITJ PPER...   \n",
      "1    ADJA NN $, VVIMP PTKVZ PTKZU VVINF $, KOUS PDS...   \n",
      "2    ITJ $, PPER VAFIN ADV ADV ADJD $, PRELS PPER A...   \n",
      "3    ADV VAFIN SENT PPER VVFIN PPER ADJD KON NN VVI...   \n",
      "4    NN NN $, PDS VAFIN FM NN SENT PDS VAFIN ART NN...   \n",
      "..                                                 ...   \n",
      "969  NN $. ADV APPR ART NN $( NN VVFIN PPER ADV NN ...   \n",
      "970  ART PIAT NN APPRART NN VAFIN PPOSAT ADJA $, AD...   \n",
      "971  ADJA NN $, NN APPRART NN $. KOUS ART ADJA NE P...   \n",
      "972  PAV VMFIN PPER APPR ADJA NN PPER VVINF $, KOUS...   \n",
      "973  ART NN PPOSAT ADJA NN APPR ART NN VAFIN PPOSAT...   \n",
      "\n",
      "                                                lemmas              title  \\\n",
      "0    so kommen ihr d Löwritter schwermütig vor ? ja...       Leonilda.txt   \n",
      "1    arm Herz / lassen ab zu hoffen / weil d glück ...       Euridice.txt   \n",
      "2    ach / ich sein schon so müde / d ich kaum mehr...       Freyheit.txt   \n",
      "3    so sein ! er lassen ich hoch und überhoch bela...       Cardenio.txt   \n",
      "4    vertraute Charmium / dies sein -- Lebens-Höle ...      Cleopatra.txt   \n",
      "..                                                 ...                ...   \n",
      "969  Kamerad ! daheim in die Silvester = Gottesdien...              Zwölf   \n",
      "970  eine jede Uebergang in+die Leben haben sein be...  Hochzeits-Predigt   \n",
      "971  andächtig Christ , Geliebte in+die Herr ! als ...                Der   \n",
      "972  darum wollen wir mit getroster Zuversicht er b...                Zur   \n",
      "973  die Eingliederung unser evang. Jugendverein in...             Unsere   \n",
      "\n",
      "    genre period region  year      corpus  \n",
      "0    DRAM     P1    NoD  1673  manchester  \n",
      "1    DRAM     P1    NoD  1699  manchester  \n",
      "2    DRAM     P1    NoD  1700  manchester  \n",
      "3    DRAM     P1    OMD  1657  manchester  \n",
      "4    DRAM     P1    OMD  1661  manchester  \n",
      "..    ...    ...    ...   ...         ...  \n",
      "969  SERM     P6    WMD  1917   innsbruck  \n",
      "970  SERM     P6    WOD  1906   innsbruck  \n",
      "971  SERM     P6    WOD  1914   innsbruck  \n",
      "972  SERM     P6    WOD  1916   innsbruck  \n",
      "973  SERM     P6    WOD  1934   innsbruck  \n",
      "\n",
      "[663 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df[df.genre != 'NEWS']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teilung des Dataframes in die einzelnen Teilcorpora und Perioden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Teilung in Manchester und Innsbruck Dataframe, sowie in die einzelnen Perioden+\n",
    "#Der einfachheit halber wird hier mit dem Dataframe.loc Attribut gearbeitet, weil es vergleichbar mit einem SQL-Statement ist ist\n",
    "#Hierfür jeweils eine eigene Zelle, damit man via Shape nochmal die Größe prüfen kann\n",
    "#Für die Tests können die einzelnen Dataframes wie gewünscht concateniert werden\n",
    "\n",
    "df_man = df.loc[df['corpus'] == 'manchester']\n",
    "df_inn = df.loc[df['corpus'] == 'innsbruck']\n",
    "#P1\n",
    "df_P1 = df.loc[df['period'] == 'P1']\n",
    "#P2\n",
    "df_P2 = df.loc[df['period'] == 'P2']\n",
    "#P3\n",
    "df_P3 = df.loc[df['period'] == 'P3']\n",
    "#P4\n",
    "df_P4 = df.loc[df['period'] == 'P4']\n",
    "#P5\n",
    "df_P5 = df.loc[df['period'] == 'P5']\n",
    "#P6\n",
    "df_P6 = df.loc[df['period'] == 'P6']\n",
    "df_man.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konkatenieren der einzelnen Teile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat34 = pd.concat((df_P3, df_P4))\n",
    "df_concat12 = pd.concat((df_P1, df_P2))\n",
    "df_concat12.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features P1 ist der Trainingskorpus, er heißt im folgenden _train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "tf = TfidfVectorizer(stop_words=get_stop_words('de'), max_features=20000)\n",
    "\n",
    "#Wie beim Lennart steht das X für die Texte und Y für die Label\n",
    "\n",
    "X_train = tf.fit_transform(df_P1.lemmas)\n",
    "X_P2 = tf.transform(df_P2.lemmas)\n",
    "X_P3 = tf.transform(df_P3.lemmas)\n",
    "X_P4 = tf.transform(df_P4.lemmas)\n",
    "X_P5 = tf.transform(df_P5.lemmas)\n",
    "X_P6 = tf.transform(df_P6.lemmas)\n",
    "\n",
    "y_train = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P1 auf die restlichen einzelnen Perioden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.83      1.00      0.91        15\n",
      "        HUMA       0.56      0.33      0.42        15\n",
      "        LEGA       1.00      0.87      0.93        15\n",
      "        NARR       0.67      0.53      0.59        15\n",
      "        SCIE       0.81      0.87      0.84        15\n",
      "        SERM       0.68      1.00      0.81        15\n",
      "\n",
      "    accuracy                           0.77        90\n",
      "   macro avg       0.76      0.77      0.75        90\n",
      "weighted avg       0.76      0.77      0.75        90\n",
      "\n",
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.54      1.00      0.70        15\n",
      "        HUMA       0.50      0.47      0.48        15\n",
      "        LEGA       1.00      0.73      0.85        15\n",
      "        NARR       0.75      0.20      0.32        15\n",
      "        SCIE       0.71      0.67      0.69        15\n",
      "        SERM       0.74      0.93      0.82        15\n",
      "\n",
      "    accuracy                           0.67        90\n",
      "   macro avg       0.71      0.67      0.64        90\n",
      "weighted avg       0.71      0.67      0.64        90\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.53      0.95      0.68        22\n",
      "        HUMA       0.54      0.54      0.54        24\n",
      "        LEGA       0.92      0.88      0.90        25\n",
      "        NARR       0.40      0.08      0.13        26\n",
      "        SCIE       0.93      0.70      0.80        20\n",
      "        SERM       0.61      0.86      0.72        22\n",
      "\n",
      "    accuracy                           0.65       139\n",
      "   macro avg       0.65      0.67      0.63       139\n",
      "weighted avg       0.65      0.65      0.61       139\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.56      0.83      0.67        18\n",
      "        HUMA       0.65      0.59      0.62        22\n",
      "        LEGA       1.00      0.95      0.97        20\n",
      "        NARR       0.45      0.23      0.30        22\n",
      "        SCIE       0.75      0.60      0.67        20\n",
      "        SERM       0.68      0.95      0.79        22\n",
      "\n",
      "    accuracy                           0.69       124\n",
      "   macro avg       0.68      0.69      0.67       124\n",
      "weighted avg       0.68      0.69      0.67       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.53      0.84      0.65        19\n",
      "        HUMA       0.62      0.62      0.62        21\n",
      "        LEGA       0.83      0.91      0.87        22\n",
      "        NARR       0.71      0.26      0.38        19\n",
      "        SCIE       0.84      0.59      0.70        27\n",
      "        SERM       0.68      0.90      0.78        21\n",
      "\n",
      "    accuracy                           0.69       129\n",
      "   macro avg       0.70      0.69      0.67       129\n",
      "weighted avg       0.71      0.69      0.67       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "naive_bayes = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred_P2 = naive_bayes.predict(X_P2)\n",
    "y_pred_P3 = naive_bayes.predict(X_P3)\n",
    "y_pred_P4 = naive_bayes.predict(X_P4)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NARR' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'SERM' 'DRAM' 'DRAM' 'SERM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'HUMA'\n",
      " 'SERM' 'SCIE' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'SCIE' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'LEGA' 'HUMA' 'HUMA' 'SERM' 'HUMA' 'NARR' 'HUMA' 'LEGA' 'HUMA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'SCIE' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'SERM' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'NARR' 'DRAM' 'DRAM' 'NARR' 'DRAM' 'DRAM' 'NARR' 'DRAM'\n",
      " 'DRAM' 'SERM' 'DRAM' 'NARR' 'DRAM' 'DRAM' 'DRAM' 'NARR' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'SCIE' 'SERM' 'SCIE' 'HUMA' 'SCIE' 'SCIE' 'SCIE' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'HUMA' 'SCIE' 'HUMA' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'HUMA'\n",
      " 'SCIE' 'SERM' 'SERM' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'HUMA' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'DRAM' 'SERM'\n",
      " 'SERM' 'SERM' 'HUMA' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'] \n",
      "\n",
      " ['DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_P6,'\\n\\n', y_P6) #Vergleich der vorhergesagten mit den tatsächlichen Label durch NB bei P6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P1 und P2 concateniert auf die restlichen Perioden und den neuen Korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.50      1.00      0.67        15\n",
      "        HUMA       0.41      0.47      0.44        15\n",
      "        LEGA       1.00      0.60      0.75        15\n",
      "        NARR       0.80      0.27      0.40        15\n",
      "        SCIE       0.69      0.60      0.64        15\n",
      "        SERM       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.64        90\n",
      "   macro avg       0.71      0.64      0.63        90\n",
      "weighted avg       0.71      0.64      0.63        90\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.49      1.00      0.66        22\n",
      "        HUMA       0.59      0.67      0.63        24\n",
      "        LEGA       1.00      0.68      0.81        25\n",
      "        NARR       1.00      0.04      0.07        26\n",
      "        SCIE       0.82      0.70      0.76        20\n",
      "        SERM       0.69      1.00      0.81        22\n",
      "\n",
      "    accuracy                           0.66       139\n",
      "   macro avg       0.77      0.68      0.62       139\n",
      "weighted avg       0.77      0.66      0.61       139\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.48      0.83      0.61        18\n",
      "        HUMA       0.57      0.55      0.56        22\n",
      "        LEGA       1.00      0.65      0.79        20\n",
      "        NARR       0.56      0.23      0.32        22\n",
      "        SCIE       0.68      0.75      0.71        20\n",
      "        SERM       0.75      0.95      0.84        22\n",
      "\n",
      "    accuracy                           0.65       124\n",
      "   macro avg       0.67      0.66      0.64       124\n",
      "weighted avg       0.67      0.65      0.64       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.53      0.95      0.68        19\n",
      "        HUMA       0.68      0.71      0.70        21\n",
      "        LEGA       1.00      0.45      0.62        22\n",
      "        NARR       0.86      0.32      0.46        19\n",
      "        SCIE       0.64      0.78      0.70        27\n",
      "        SERM       0.83      0.90      0.86        21\n",
      "\n",
      "    accuracy                           0.69       129\n",
      "   macro avg       0.76      0.69      0.67       129\n",
      "weighted avg       0.75      0.69      0.68       129\n",
      "\n",
      "Inn               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.50      0.93      0.65        59\n",
      "        HUMA       0.61      0.64      0.62        67\n",
      "        LEGA       1.00      0.60      0.75        67\n",
      "        NARR       0.71      0.18      0.29        67\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.69      0.75      0.72        67\n",
      "        SERM       0.75      0.95      0.84        65\n",
      "\n",
      "    accuracy                           0.67       393\n",
      "   macro avg       0.61      0.58      0.55       393\n",
      "weighted avg       0.71      0.67      0.64       393\n",
      "\n",
      "['DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'HUMA' 'HUMA' 'HUMA' 'SERM' 'HUMA' 'SERM' 'SCIE' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'DRAM' 'HUMA' 'SERM' 'SERM' 'HUMA' 'HUMA' 'DRAM' 'SERM'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'SCIE' 'LEGA' 'LEGA' 'LEGA' 'SCIE' 'HUMA' 'LEGA' 'LEGA' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'HUMA' 'LEGA' 'LEGA' 'HUMA' 'LEGA' 'HUMA' 'LEGA'\n",
      " 'LEGA' 'DRAM' 'SERM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'NARR' 'SERM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'SERM' 'SERM' 'HUMA' 'SCIE' 'HUMA'\n",
      " 'HUMA' 'SCIE' 'HUMA' 'HUMA' 'SCIE' 'SCIE' 'SERM' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'HUMA' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'DRAM' 'NARR' 'NARR' 'DRAM' 'DRAM' 'NARR' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'NARR' 'SERM'\n",
      " 'HUMA' 'DRAM' 'HUMA' 'HUMA' 'SERM' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'SCIE'\n",
      " 'SERM' 'HUMA' 'SCIE' 'SCIE' 'SCIE' 'HUMA' 'HUMA' 'SCIE' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'LEGA' 'SCIE' 'LEGA' 'HUMA' 'LEGA' 'HUMA' 'LEGA' 'SCIE' 'LEGA'\n",
      " 'HUMA' 'LEGA' 'LEGA' 'LEGA' 'HUMA' 'LEGA' 'LEGA' 'HUMA' 'LEGA' 'LEGA'\n",
      " 'NARR' 'NARR' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'NARR' 'SERM' 'DRAM'\n",
      " 'HUMA' 'DRAM' 'SERM' 'SERM' 'NARR' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'NARR' 'DRAM' 'SCIE' 'SCIE' 'HUMA' 'HUMA' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'HUMA' 'SCIE' 'DRAM' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SERM' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'NARR'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'SERM' 'SCIE' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'SCIE' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'DRAM' 'SERM' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'SCIE' 'HUMA' 'LEGA' 'SCIE' 'LEGA' 'LEGA' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'LEGA' 'HUMA' 'LEGA' 'LEGA' 'SCIE' 'SCIE' 'HUMA' 'LEGA' 'LEGA'\n",
      " 'SCIE' 'SCIE' 'HUMA' 'LEGA' 'SCIE' 'LEGA' 'NARR' 'DRAM' 'DRAM' 'NARR'\n",
      " 'DRAM' 'DRAM' 'NARR' 'DRAM' 'DRAM' 'NARR' 'DRAM' 'NARR' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'NARR' 'SCIE' 'SERM' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'DRAM' 'SCIE' 'HUMA' 'SCIE' 'HUMA' 'HUMA' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SERM' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'DRAM' 'SERM' 'SERM' 'SERM' 'HUMA' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM'] \n",
      "\n",
      " ['DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NEWS-P4' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train12 = tf.fit_transform(df_concat12.lemmas)\n",
    "X_P3 = tf.transform(df_P3.lemmas)\n",
    "X_P4 = tf.transform(df_P4.lemmas)\n",
    "X_P5 = tf.transform(df_P5.lemmas)\n",
    "X_P6 = tf.transform(df_P6.lemmas)\n",
    "X_inn = tf.transform(df_inn.lemmas)\n",
    "\n",
    "y_train12 = df_concat12.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "y_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train12, y_train12)\n",
    "\n",
    "y_pred_P3 = naive_bayes.predict(X_P3)\n",
    "y_pred_P4 = naive_bayes.predict(X_P4)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "y_pred_inn = naive_bayes.predict(X_inn)\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))\n",
    "print('Inn', classification_report(y_inn, y_pred_inn))\n",
    "\n",
    "#Vergleich der predicted und tatsächlichen Label des Innsbruck Korpus\n",
    "print(y_pred_inn,'\\n\\n', y_inn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes P3 und P4 concateniert auf die restlichen Perioden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.07      0.12        15\n",
      "        HUMA       0.67      0.13      0.22        15\n",
      "        LEGA       0.78      0.93      0.85        15\n",
      "        NARR       0.48      0.87      0.62        15\n",
      "        SCIE       1.00      0.40      0.57        15\n",
      "        SERM       0.43      1.00      0.60        15\n",
      "\n",
      "    accuracy                           0.57        90\n",
      "   macro avg       0.73      0.57      0.50        90\n",
      "weighted avg       0.73      0.57      0.50        90\n",
      "\n",
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        15\n",
      "        HUMA       0.67      0.13      0.22        15\n",
      "        LEGA       0.93      0.87      0.90        15\n",
      "        NARR       0.38      0.87      0.53        15\n",
      "        SCIE       0.83      0.67      0.74        15\n",
      "        SERM       0.56      1.00      0.71        15\n",
      "\n",
      "    accuracy                           0.59        90\n",
      "   macro avg       0.56      0.59      0.52        90\n",
      "weighted avg       0.56      0.59      0.52        90\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.11      0.20        18\n",
      "        HUMA       0.94      0.73      0.82        22\n",
      "        LEGA       0.91      1.00      0.95        20\n",
      "        NARR       0.50      0.95      0.66        22\n",
      "        SCIE       1.00      0.90      0.95        20\n",
      "        SERM       0.96      1.00      0.98        22\n",
      "\n",
      "    accuracy                           0.80       124\n",
      "   macro avg       0.88      0.78      0.76       124\n",
      "weighted avg       0.88      0.80      0.77       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.05      0.10        19\n",
      "        HUMA       0.79      0.71      0.75        21\n",
      "        LEGA       0.73      1.00      0.85        22\n",
      "        NARR       0.45      1.00      0.62        19\n",
      "        SCIE       1.00      0.63      0.77        27\n",
      "        SERM       0.95      0.90      0.93        21\n",
      "\n",
      "    accuracy                           0.72       129\n",
      "   macro avg       0.82      0.72      0.67       129\n",
      "weighted avg       0.83      0.72      0.69       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train34 = tf.fit_transform(df_concat34.lemmas)\n",
    "X_P1 = tf.transform(df_P1.lemmas)\n",
    "X_P2 = tf.transform(df_P2.lemmas)\n",
    "X_P5 = tf.transform(df_P5.lemmas)\n",
    "X_P6 = tf.transform(df_P6.lemmas)\n",
    "\n",
    "y_train34 = df_concat34.genre.to_numpy()\n",
    "y_P1 = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train34, y_train34)\n",
    "\n",
    "y_pred_P1 = naive_bayes.predict(X_P1)\n",
    "y_pred_P2 = naive_bayes.predict(X_P2)\n",
    "y_pred_P5 = naive_bayes.predict(X_P5)\n",
    "y_pred_P6 = naive_bayes.predict(X_P6)\n",
    "print('P1', classification_report(y_P1, y_pred_P1))\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes alter auf neuer Korpus - Manchester Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.57      0.98      0.72        59\n",
      "        HUMA       0.77      0.70      0.73        67\n",
      "        LEGA       0.98      0.61      0.75        67\n",
      "        NARR       0.82      0.27      0.40        67\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.64      0.87      0.74        67\n",
      "        SERM       0.84      0.98      0.91        65\n",
      "\n",
      "    accuracy                           0.73       393\n",
      "   macro avg       0.66      0.63      0.61       393\n",
      "weighted avg       0.77      0.73      0.71       393\n",
      "\n",
      "['DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'HUMA' 'HUMA' 'HUMA' 'SERM' 'HUMA' 'SERM' 'SCIE' 'HUMA'\n",
      " 'SCIE' 'HUMA' 'DRAM' 'HUMA' 'HUMA' 'SERM' 'HUMA' 'HUMA' 'HUMA' 'SERM'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'SCIE' 'LEGA' 'LEGA' 'LEGA' 'SCIE' 'SCIE' 'LEGA' 'LEGA' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'HUMA' 'LEGA' 'LEGA' 'HUMA' 'LEGA' 'SCIE' 'LEGA'\n",
      " 'LEGA' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'SERM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'SERM' 'SERM' 'LEGA' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'HUMA' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'DRAM' 'NARR' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'NARR'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'SCIE'\n",
      " 'HUMA' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'LEGA' 'SCIE' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'SCIE' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'HUMA' 'LEGA' 'LEGA'\n",
      " 'NARR' 'NARR' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'NARR' 'SERM' 'DRAM'\n",
      " 'HUMA' 'NARR' 'SERM' 'SERM' 'NARR' 'DRAM' 'NARR' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'NARR' 'DRAM' 'SCIE' 'SCIE' 'SCIE' 'HUMA' 'SCIE' 'SCIE' 'SCIE' 'HUMA'\n",
      " 'SCIE' 'SCIE' 'HUMA' 'SCIE' 'HUMA' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'SERM' 'SCIE' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'SCIE' 'HUMA' 'HUMA' 'HUMA' 'SCIE' 'SCIE' 'HUMA' 'HUMA' 'SERM' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'SCIE' 'HUMA' 'LEGA' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'LEGA' 'LEGA' 'LEGA' 'SCIE' 'SCIE' 'SCIE' 'HUMA' 'LEGA' 'LEGA'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'LEGA' 'NARR' 'NARR' 'DRAM' 'NARR'\n",
      " 'NARR' 'DRAM' 'NARR' 'DRAM' 'DRAM' 'NARR' 'NARR' 'NARR' 'DRAM' 'NARR'\n",
      " 'DRAM' 'DRAM' 'NARR' 'DRAM' 'NARR' 'SCIE' 'HUMA' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'DRAM' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'NARR' 'NARR' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'HUMA' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM'] \n",
      "\n",
      " ['DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NEWS-P4' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM']\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "SERM HUMA\n",
      "HUMA HUMA\n",
      "SERM HUMA\n",
      "SCIE HUMA\n",
      "HUMA HUMA\n",
      "SCIE HUMA\n",
      "HUMA HUMA\n",
      "DRAM HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "SERM HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "SERM HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "SCIE LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "HUMA LEGA\n",
      "HUMA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "HUMA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "HUMA LEGA\n",
      "LEGA LEGA\n",
      "SCIE LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "SERM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "SERM NARR\n",
      "SERM NARR\n",
      "LEGA NEWS-P4\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "HUMA SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "DRAM DRAM\n",
      "NARR DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "HUMA HUMA\n",
      "NARR HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "SCIE HUMA\n",
      "HUMA HUMA\n",
      "SCIE HUMA\n",
      "SCIE HUMA\n",
      "SCIE HUMA\n",
      "SCIE HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "SCIE LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "SCIE LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "HUMA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "NARR NARR\n",
      "NARR NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "NARR NARR\n",
      "SERM NARR\n",
      "DRAM NARR\n",
      "HUMA NARR\n",
      "NARR NARR\n",
      "SERM NARR\n",
      "SERM NARR\n",
      "NARR NARR\n",
      "DRAM NARR\n",
      "NARR NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "NARR NARR\n",
      "DRAM NARR\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "HUMA SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "HUMA SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "HUMA SCIE\n",
      "SCIE SCIE\n",
      "HUMA SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "DRAM DRAM\n",
      "HUMA HUMA\n",
      "SERM HUMA\n",
      "SCIE HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "SCIE HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "SCIE HUMA\n",
      "SCIE HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "SERM HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "HUMA HUMA\n",
      "SCIE HUMA\n",
      "HUMA HUMA\n",
      "LEGA LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "HUMA LEGA\n",
      "LEGA LEGA\n",
      "LEGA LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "SCIE LEGA\n",
      "LEGA LEGA\n",
      "NARR NARR\n",
      "NARR NARR\n",
      "DRAM NARR\n",
      "NARR NARR\n",
      "NARR NARR\n",
      "DRAM NARR\n",
      "NARR NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "NARR NARR\n",
      "NARR NARR\n",
      "NARR NARR\n",
      "DRAM NARR\n",
      "NARR NARR\n",
      "DRAM NARR\n",
      "DRAM NARR\n",
      "NARR NARR\n",
      "DRAM NARR\n",
      "NARR NARR\n",
      "SCIE SCIE\n",
      "HUMA SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "DRAM SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "NARR SCIE\n",
      "NARR SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SCIE SCIE\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "HUMA SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n",
      "SERM SERM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_man = tf.fit_transform(df_man.lemmas)\n",
    "X_test_inn = tf.transform(df_inn.lemmas)\n",
    "\n",
    "y_train_man = df_man.genre.to_numpy()\n",
    "y_test_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train_man, y_train_man)\n",
    "\n",
    "y_pred_inn = naive_bayes.predict(X_test_inn)\n",
    "print(classification_report(y_test_inn, y_pred_inn))\n",
    "\n",
    "#Vergleich des Predicted und tatsächlichen Labels für den Innsbruck Korpus\n",
    "y=0\n",
    "for x in y_pred_inn:\n",
    "    print(x,y_test_inn[y])\n",
    "    y=y+1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes neuer auf alter Korpus - Innsbruck Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.00      0.00      0.00        45\n",
      "        HUMA       0.78      0.16      0.26        45\n",
      "        LEGA       0.93      0.29      0.44        45\n",
      "        NARR       0.37      0.76      0.50        45\n",
      "        SCIE       1.00      0.38      0.55        45\n",
      "        SERM       0.32      1.00      0.49        45\n",
      "\n",
      "    accuracy                           0.43       270\n",
      "   macro avg       0.57      0.43      0.37       270\n",
      "weighted avg       0.57      0.43      0.37       270\n",
      "\n",
      "['SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'NARR' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'NARR' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'NARR' 'NARR' 'SERM' 'NARR' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'NARR' 'NARR' 'NARR' 'NARR' 'SERM' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'NARR' 'SERM' 'SERM' 'NARR'\n",
      " 'SERM' 'SERM' 'NARR' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'NARR' 'NARR' 'HUMA' 'NARR' 'SERM' 'SERM' 'NARR' 'NARR' 'SERM' 'NARR'\n",
      " 'NARR' 'HUMA' 'SERM' 'NARR' 'NARR' 'SERM' 'HUMA' 'NARR' 'HUMA' 'HUMA'\n",
      " 'NARR' 'NARR' 'HUMA' 'LEGA' 'SERM' 'NARR' 'NARR' 'NARR' 'SERM' 'HUMA'\n",
      " 'SERM' 'SERM' 'LEGA' 'LEGA' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'LEGA' 'SERM' 'SERM' 'SERM' 'SERM' 'NARR' 'SERM' 'SERM'\n",
      " 'NARR' 'LEGA' 'NARR' 'SERM' 'NARR' 'SERM' 'SERM' 'SERM' 'LEGA' 'NARR'\n",
      " 'NARR' 'SERM' 'LEGA' 'LEGA' 'NARR' 'SERM' 'LEGA' 'HUMA' 'SERM' 'SERM'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'NARR' 'NARR' 'SERM' 'NARR' 'SERM'\n",
      " 'SERM' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'SERM' 'NARR' 'SERM'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'SERM' 'NARR' 'NARR' 'SERM' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'SERM' 'NARR' 'NARR' 'NARR' 'SERM' 'NARR' 'NARR' 'SERM' 'SERM'\n",
      " 'SERM' 'NARR' 'NARR' 'SERM' 'NARR' 'NARR' 'SCIE' 'SERM' 'NARR' 'NARR'\n",
      " 'NARR' 'SERM' 'NARR' 'SERM' 'SCIE' 'SCIE' 'SERM' 'SCIE' 'NARR' 'SCIE'\n",
      " 'NARR' 'NARR' 'NARR' 'SCIE' 'NARR' 'NARR' 'SERM' 'NARR' 'NARR' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'NARR' 'SERM' 'SCIE' 'SERM'\n",
      " 'HUMA' 'NARR' 'SCIE' 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'] \n",
      "\n",
      " ['DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM'\n",
      " 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'DRAM' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA' 'HUMA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA'\n",
      " 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'LEGA' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR' 'NARR'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE'\n",
      " 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SCIE' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM'\n",
      " 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM' 'SERM']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_inn = tf.fit_transform(df_inn.lemmas)\n",
    "X_test_man = tf.transform(df_man.lemmas)\n",
    "\n",
    "y_train_inn = df_inn.genre.to_numpy()\n",
    "y_test_man = df_man.genre.to_numpy()\n",
    "\n",
    "#Naive Bayes:\n",
    "naive_bayes = MultinomialNB().fit(X_train_inn, y_train_inn)\n",
    "\n",
    "y_pred_man = naive_bayes.predict(X_test_man)\n",
    "print(classification_report(y_test_man, y_pred_man))\n",
    "\n",
    "#Vergleich des predicted und tatsächlichen Labels:\n",
    "print(y_pred_man,'\\n\\n', y_test_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression P1 auf den rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.92      0.80      0.86        15\n",
      "        HUMA       0.38      0.20      0.26        15\n",
      "        LEGA       1.00      0.87      0.93        15\n",
      "        NARR       0.48      0.67      0.56        15\n",
      "        SCIE       0.70      0.93      0.80        15\n",
      "        SERM       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.73        90\n",
      "   macro avg       0.73      0.73      0.72        90\n",
      "weighted avg       0.73      0.73      0.72        90\n",
      "\n",
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.67      0.93      0.78        15\n",
      "        HUMA       0.45      0.33      0.38        15\n",
      "        LEGA       1.00      0.87      0.93        15\n",
      "        NARR       0.56      0.67      0.61        15\n",
      "        SCIE       0.69      0.73      0.71        15\n",
      "        SERM       1.00      0.73      0.85        15\n",
      "\n",
      "    accuracy                           0.71        90\n",
      "   macro avg       0.73      0.71      0.71        90\n",
      "weighted avg       0.73      0.71      0.71        90\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.62      0.82      0.71        22\n",
      "        HUMA       0.50      0.33      0.40        24\n",
      "        LEGA       0.64      1.00      0.78        25\n",
      "        NARR       0.65      0.42      0.51        26\n",
      "        SCIE       0.82      0.70      0.76        20\n",
      "        SERM       0.81      0.77      0.79        22\n",
      "\n",
      "    accuracy                           0.67       139\n",
      "   macro avg       0.67      0.67      0.66       139\n",
      "weighted avg       0.67      0.67      0.65       139\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.68      0.72      0.70        18\n",
      "        HUMA       0.65      0.50      0.56        22\n",
      "        LEGA       0.83      1.00      0.91        20\n",
      "        NARR       0.64      0.64      0.64        22\n",
      "        SCIE       0.76      0.80      0.78        20\n",
      "        SERM       0.90      0.86      0.88        22\n",
      "\n",
      "    accuracy                           0.75       124\n",
      "   macro avg       0.74      0.75      0.75       124\n",
      "weighted avg       0.74      0.75      0.74       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.67      0.42      0.52        19\n",
      "        HUMA       0.64      0.33      0.44        21\n",
      "        LEGA       0.55      1.00      0.71        22\n",
      "        NARR       0.59      0.89      0.71        19\n",
      "        SCIE       0.94      0.63      0.76        27\n",
      "        SERM       0.89      0.81      0.85        21\n",
      "\n",
      "    accuracy                           0.68       129\n",
      "   macro avg       0.71      0.68      0.66       129\n",
      "weighted avg       0.73      0.68      0.67       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train = tf.fit_transform(df_P1.lemmas)\n",
    "X_P2 = tf.transform(df_P2.lemmas)\n",
    "X_P3 = tf.transform(df_P3.lemmas)\n",
    "X_P4 = tf.transform(df_P4.lemmas)\n",
    "X_P5 = tf.transform(df_P5.lemmas)\n",
    "X_P6 = tf.transform(df_P6.lemmas)\n",
    "\n",
    "y_train = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred_P2 = log_reg.predict(X_P2)\n",
    "y_pred_P3 = log_reg.predict(X_P3)\n",
    "y_pred_P4 = log_reg.predict(X_P4)\n",
    "y_pred_P5 = log_reg.predict(X_P5)\n",
    "y_pred_P6 = log_reg.predict(X_P6)\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression P1 und P2 konkateniert auf den Rest angewandt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.60      1.00      0.75        15\n",
      "        HUMA       0.58      0.73      0.65        15\n",
      "        LEGA       1.00      1.00      1.00        15\n",
      "        NARR       0.88      0.47      0.61        15\n",
      "        SCIE       0.82      0.60      0.69        15\n",
      "        SERM       1.00      0.80      0.89        15\n",
      "\n",
      "    accuracy                           0.77        90\n",
      "   macro avg       0.81      0.77      0.76        90\n",
      "weighted avg       0.81      0.77      0.76        90\n",
      "\n",
      "P4               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.59      0.91      0.71        22\n",
      "        HUMA       0.65      0.54      0.59        24\n",
      "        LEGA       0.83      0.96      0.89        25\n",
      "        NARR       0.90      0.35      0.50        26\n",
      "        SCIE       0.79      0.95      0.86        20\n",
      "        SERM       0.82      0.82      0.82        22\n",
      "\n",
      "    accuracy                           0.74       139\n",
      "   macro avg       0.76      0.75      0.73       139\n",
      "weighted avg       0.77      0.74      0.72       139\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.59      0.72      0.65        18\n",
      "        HUMA       0.80      0.73      0.76        22\n",
      "        LEGA       0.95      0.95      0.95        20\n",
      "        NARR       0.69      0.50      0.58        22\n",
      "        SCIE       0.78      0.90      0.84        20\n",
      "        SERM       0.91      0.95      0.93        22\n",
      "\n",
      "    accuracy                           0.79       124\n",
      "   macro avg       0.79      0.79      0.79       124\n",
      "weighted avg       0.79      0.79      0.79       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.71      0.63      0.67        19\n",
      "        HUMA       0.87      0.62      0.72        21\n",
      "        LEGA       0.76      0.86      0.81        22\n",
      "        NARR       0.73      0.84      0.78        19\n",
      "        SCIE       0.81      0.93      0.86        27\n",
      "        SERM       0.89      0.81      0.85        21\n",
      "\n",
      "    accuracy                           0.79       129\n",
      "   macro avg       0.79      0.78      0.78       129\n",
      "weighted avg       0.80      0.79      0.79       129\n",
      "\n",
      "Inn               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.62      0.76      0.68        59\n",
      "        HUMA       0.76      0.63      0.69        67\n",
      "        LEGA       0.83      0.93      0.87        67\n",
      "        NARR       0.75      0.54      0.63        67\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.79      0.93      0.86        67\n",
      "        SERM       0.88      0.86      0.87        65\n",
      "\n",
      "    accuracy                           0.77       393\n",
      "   macro avg       0.66      0.66      0.66       393\n",
      "weighted avg       0.77      0.77      0.76       393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train12 = tf.fit_transform(df_concat12.lemmas)\n",
    "X_P3 = tf.transform(df_P3.lemmas)\n",
    "X_P4 = tf.transform(df_P4.lemmas)\n",
    "X_P5 = tf.transform(df_P5.lemmas)\n",
    "X_P6 = tf.transform(df_P6.lemmas)\n",
    "X_inn = tf.transform(df_inn.lemmas)\n",
    "\n",
    "y_train12 = df_concat12.genre.to_numpy()\n",
    "y_P3 = df_P3.genre.to_numpy()\n",
    "y_P4 = df_P4.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "y_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train12, y_train12)\n",
    "\n",
    "y_pred_P3 = log_reg.predict(X_P3)\n",
    "y_pred_P4 = log_reg.predict(X_P4)\n",
    "y_pred_P5 = log_reg.predict(X_P5)\n",
    "y_pred_P6 = log_reg.predict(X_P6)\n",
    "y_pred_inn = log_reg.predict(X_inn)\n",
    "print('P3', classification_report(y_P3, y_pred_P3))\n",
    "print('P4', classification_report(y_P4, y_pred_P4))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))\n",
    "print('Inn', classification_report(y_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression P3 und P4 angewandt auf den Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      1.00      1.00        15\n",
      "        HUMA       0.80      0.27      0.40        15\n",
      "        LEGA       0.74      0.93      0.82        15\n",
      "        NARR       0.72      0.87      0.79        15\n",
      "        SCIE       0.88      0.47      0.61        15\n",
      "        SERM       0.56      0.93      0.70        15\n",
      "\n",
      "    accuracy                           0.74        90\n",
      "   macro avg       0.78      0.74      0.72        90\n",
      "weighted avg       0.78      0.74      0.72        90\n",
      "\n",
      "P2               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.82      0.93      0.87        15\n",
      "        HUMA       0.67      0.13      0.22        15\n",
      "        LEGA       0.74      0.93      0.82        15\n",
      "        NARR       0.57      0.53      0.55        15\n",
      "        SCIE       0.74      0.93      0.82        15\n",
      "        SERM       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.74        90\n",
      "   macro avg       0.73      0.74      0.70        90\n",
      "weighted avg       0.73      0.74      0.70        90\n",
      "\n",
      "P5               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.93      0.72      0.81        18\n",
      "        HUMA       1.00      0.77      0.87        22\n",
      "        LEGA       0.87      1.00      0.93        20\n",
      "        NARR       0.81      0.95      0.88        22\n",
      "        SCIE       0.91      1.00      0.95        20\n",
      "        SERM       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           0.91       124\n",
      "   macro avg       0.92      0.91      0.91       124\n",
      "weighted avg       0.92      0.91      0.91       124\n",
      "\n",
      "P6               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       1.00      0.47      0.64        19\n",
      "        HUMA       0.81      0.62      0.70        21\n",
      "        LEGA       0.61      1.00      0.76        22\n",
      "        NARR       0.58      1.00      0.73        19\n",
      "        SCIE       1.00      0.63      0.77        27\n",
      "        SERM       0.94      0.81      0.87        21\n",
      "\n",
      "    accuracy                           0.75       129\n",
      "   macro avg       0.82      0.76      0.75       129\n",
      "weighted avg       0.83      0.75      0.75       129\n",
      "\n",
      "Inn, (!!Vorsicht!! ist in P4 identisch mit trainingsdaten)               precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.98      0.75      0.85        59\n",
      "        HUMA       0.95      0.79      0.86        67\n",
      "        LEGA       0.78      1.00      0.88        67\n",
      "        NARR       0.78      0.99      0.87        67\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.97      0.85      0.90        67\n",
      "        SERM       0.98      0.94      0.96        65\n",
      "\n",
      "    accuracy                           0.89       393\n",
      "   macro avg       0.78      0.76      0.76       393\n",
      "weighted avg       0.90      0.89      0.88       393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train34 = tf.fit_transform(df_concat34.lemmas)\n",
    "X_P1 = tf.transform(df_P1.lemmas)\n",
    "X_P2 = tf.transform(df_P2.lemmas)\n",
    "X_P5 = tf.transform(df_P5.lemmas)\n",
    "X_P6 = tf.transform(df_P6.lemmas)\n",
    "X_inn = tf.transform(df_inn.lemmas)\n",
    "\n",
    "y_train34 = df_concat34.genre.to_numpy()\n",
    "y_P1 = df_P1.genre.to_numpy()\n",
    "y_P2 = df_P2.genre.to_numpy()\n",
    "y_P5 = df_P5.genre.to_numpy()\n",
    "y_P6 = df_P6.genre.to_numpy()\n",
    "y_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train34, y_train34)\n",
    "\n",
    "y_pred_P1 = log_reg.predict(X_P1)\n",
    "y_pred_P2 = log_reg.predict(X_P2)\n",
    "y_pred_P5 = log_reg.predict(X_P5)\n",
    "y_pred_P6 = log_reg.predict(X_P6)\n",
    "y_pred_inn = log_reg.predict(X_inn)\n",
    "print('P1', classification_report(y_P1, y_pred_P1))\n",
    "print('P2', classification_report(y_P2, y_pred_P2))\n",
    "print('P5', classification_report(y_P5, y_pred_P5))\n",
    "print('P6', classification_report(y_P6, y_pred_P6))\n",
    "print('Inn, (!!Vorsicht!! ist in P4 identisch mit trainingsdaten)', classification_report(y_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression alter auf neuer - Manchester TRainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.82      0.68      0.74        59\n",
      "        HUMA       0.76      0.52      0.62        67\n",
      "        LEGA       0.82      0.40      0.54        67\n",
      "        NARR       0.74      0.84      0.78        67\n",
      "     NEWS-P4       0.00      0.00      0.00         1\n",
      "        SCIE       0.50      0.94      0.66        67\n",
      "        SERM       0.91      0.89      0.90        65\n",
      "\n",
      "    accuracy                           0.71       393\n",
      "   macro avg       0.65      0.61      0.61       393\n",
      "weighted avg       0.75      0.71      0.70       393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janko\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_man = tf.fit_transform(df_man.lemmas)\n",
    "X_test_inn = tf.transform(df_inn.lemmas)\n",
    "\n",
    "y_train_man = df_man.genre.to_numpy()\n",
    "y_test_inn = df_inn.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train_man, y_train_man)\n",
    "\n",
    "y_pred_inn = log_reg.predict(X_test_inn)\n",
    "print(classification_report(y_test_inn, y_pred_inn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression neuer auf alter Korpus - Innsbruck Trainingskorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DRAM       0.23      0.16      0.18        45\n",
      "        HUMA       0.65      0.24      0.35        45\n",
      "        LEGA       0.57      0.09      0.15        45\n",
      "        NARR       0.33      0.87      0.48        45\n",
      "        SCIE       0.81      0.56      0.66        45\n",
      "        SERM       0.64      0.96      0.77        45\n",
      "\n",
      "    accuracy                           0.48       270\n",
      "   macro avg       0.54      0.48      0.43       270\n",
      "weighted avg       0.54      0.48      0.43       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Features:\n",
    "X_train_inn = tf.fit_transform(df_inn.lemmas)\n",
    "X_test_man = tf.transform(df_man.lemmas)\n",
    "\n",
    "y_train_inn = df_inn.genre.to_numpy()\n",
    "y_test_man = df_man.genre.to_numpy()\n",
    "\n",
    "#Logistische Regression:\n",
    "log_reg = LogisticRegression().fit(X_train_inn, y_train_inn)\n",
    "\n",
    "y_pred_man = log_reg.predict(X_test_man)\n",
    "print(classification_report(y_test_man, y_pred_man))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einlesen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv('tagged_dataset.csv', encoding='UTF-8').dropna()\n",
    "df = df[~df['genre'].isin(['NEWS-P4'])]  # remove invalid genre (only one document)\n",
    "df = shuffle(df, random_state=42)\n",
    "#df['n_chars'] = df.tokens.apply(lambda x: len(x.split())) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trennen von Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "# tfidf values for tokens (n_grams)\n",
    "cv_token = TfidfVectorizer(max_features=6000, stop_words=get_stop_words('de'))\n",
    "X_token_train = cv_token.fit_transform(df_train.tokens)\n",
    "X_token_test = cv_token.transform(df_test.tokens)\n",
    "\n",
    "# tfidf values for lemmas (n_grams)\n",
    "cv_lemma = TfidfVectorizer(max_features=6000, stop_words=get_stop_words('de'))\n",
    "X_lemma_train = cv_lemma.fit_transform(df_train.lemmas)\n",
    "X_lemma_test = cv_lemma.transform(df_test.lemmas)\n",
    "\n",
    "# Only count pos tags\n",
    "cv_pos = CountVectorizer()\n",
    "X_pos_train = cv_pos.fit_transform(df_train.pos_tags)\n",
    "X_pos_test = cv_pos.transform(df_test.pos_tags)\n",
    "\n",
    "# Concatenate features horizontally\n",
    "features = np.hstack([\n",
    "    np.array(list(cv_token.vocabulary_.keys())),\n",
    "    np.array(list(cv_lemma.vocabulary_.keys())),\n",
    "    np.array(list(cv_pos.vocabulary_.keys()))\n",
    "])\n",
    "\n",
    "X_train = hstack([\n",
    "    X_token_train,\n",
    "    X_lemma_train,\n",
    "    X_pos_train\n",
    "])\n",
    "X_test = hstack([\n",
    "    X_token_test,\n",
    "    X_lemma_test,\n",
    "    X_pos_test\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_lemma_pos = []\n",
    "#for index, row in df_train.iterrows():\n",
    "#    sample_lemma_pos = []\n",
    "#    for lemma, pos in zip(row.tokens, row.pos_tags):\n",
    "#        sample_lemma_pos.append(\"_\".join((lemma, pos)))\n",
    "#    train_lemma_pos.append(\" \".join(sample_lemma_pos))\n",
    "#\n",
    "#test_lemma_pos = []\n",
    "#for index, row in df_test.iterrows():\n",
    "#    sample_lemma_pos = []\n",
    "#    for lemma, pos in zip(row.tokens, row.pos_tags):\n",
    "#        sample_lemma_pos.append(\"_\".join((lemma, pos)))\n",
    "#    test_lemma_pos.append(\" \".join(sample_lemma_pos))\n",
    "#\n",
    "#merged_cv = TfidfVectorizer()\n",
    "#X_train = merged_cv.fit_transform(train_lemma_pos)\n",
    "#X_test = merged_cv.transform(test_lemma_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.genre\n",
    "y_test = df_test.genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check feature weights of logreg model to get highly correlated features for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "for class_ind, class_coef in enumerate(logreg.coef_):\n",
    "    print('Class:', logreg.classes_[class_ind])\n",
    "    print('Positive features')\n",
    "    positive_features = np.flip(np.argsort(class_coef)[-n:])\n",
    "    for ind in positive_features:\n",
    "        print(features[ind], class_coef[ind])\n",
    "    print()\n",
    "    print('Negative features')\n",
    "    negative_features = np.argsort(class_coef)[:n]\n",
    "    for ind in negative_features:\n",
    "        print(features[ind], class_coef[ind])\n",
    "    print()\n",
    "    print('#'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "linsvm_params = {\n",
    "    'C': [0.1, 0.5, 1, 1.5, 2, 3, 4]\n",
    "}\n",
    "\n",
    "gridsearch_linsvm = GridSearchCV(\n",
    "    LinearSVC(),\n",
    "    cv=5,\n",
    "    param_grid=linsvm_params,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gridsearch_linsvm.fit(X_train, y_train)\n",
    "gridsearch_linsvm.best_params_, gridsearch_linsvm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linsvm = LinearSVC()\n",
    "linsvm.fit(X_train, y_train)\n",
    "y_pred = linsvm.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "rbfsvm = SVC(kernel='poly')\n",
    "rbfsvm.fit(X_train, y_train)\n",
    "y_pred = rbfsvm.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dectree = DecisionTreeClassifier()\n",
    "dectree.fit(X_train, y_train)\n",
    "y_pred = dectree.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randforest = RandomForestClassifier()\n",
    "randforest.fit(X_train, y_train)\n",
    "y_pred = randforest.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgdsvm = SGDClassifier(loss='modified_huber', max_iter=15, random_state=42)\n",
    "\n",
    "sgdsvm.fit(X_train, y_train)\n",
    "y_pred = sgdsvm.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "adaboost = AdaBoostClassifier(\n",
    "    #base_estimator=SGDClassifier(loss='modified_huber', max_iter=5, random_state=42),\n",
    "    #algorithm='SAMME.R',\n",
    "    #n_estimators=100\n",
    ")\n",
    "\n",
    "adaboost.fit(X_train, y_train)\n",
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "grad_boost = XGBClassifier()\n",
    "grad_boost.fit(X_train, y_train)\n",
    "y_pred = grad_boost.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boostrap Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def bootstrap_validation(clf1: BaseEstimator, clf2: BaseEstimator,\n",
    "                         X: csr_matrix, y: csr_matrix,\n",
    "                         n_samples: int,\n",
    "                         sample_size: int,\n",
    "                         scorer: callable = lambda y_true, y_pred: f1_score(y_true, y_pred, average='macro')) -> float:\n",
    "    \n",
    "    \"\"\"\n",
    "    Implementation of bootstrapping test according to Jurafsky.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute initial performance difference on complete test set\n",
    "    y_pred_1 = clf1.predict(X)\n",
    "    clf1_score = scorer(y, y_pred_1)\n",
    "    \n",
    "    y_pred_2 = clf2.predict(X)\n",
    "    clf2_score = scorer(y, y_pred_2)\n",
    "    \n",
    "    initial_difference = clf1_score - clf2_score\n",
    "    \n",
    "    # compute differences on n_samples different testsets\n",
    "    sample_differences = []\n",
    "    for _ in range(n_samples):\n",
    "        \n",
    "        # create boostrap sample\n",
    "        X_sample, y_sample = resample(X, y,\n",
    "                                      replace=True,\n",
    "                                      n_samples=sample_size)\n",
    "        \n",
    "        # calculate performance difference and store it\n",
    "        y_pred_1 = clf1.predict(X_sample)\n",
    "        clf1_score = scorer(y_sample, y_pred_1)\n",
    "    \n",
    "        y_pred_2 = clf2.predict(X_sample)\n",
    "        clf2_score = scorer(y_sample, y_pred_2)\n",
    "        sample_differences.append(clf1_score - clf2_score)\n",
    "    \n",
    "    # calculate p value based on performance differences\n",
    "    s_values = []\n",
    "    s = 0\n",
    "    for sample_difference in sample_differences:\n",
    "        if sample_difference > 2 * initial_difference:\n",
    "            s += 1\n",
    "    p_value = s / n_samples\n",
    "    \n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lennartkeller/anaconda3/envs/nlp/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/lennartkeller/anaconda3/envs/nlp/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score Macro for Classifier 1: 0.8330271157857364\n",
      "F1-Score Macro for Classifier 2: 0.6495289083092743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lennartkeller/anaconda3/envs/nlp/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "clf1 = LogisticRegression().fit(X_train, y_train)\n",
    "clf2 = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"F1-Score Macro for Classifier 1: {f1_score(y_test, clf1.predict(X_test), average='macro')}\")\n",
    "print(f\"F1-Score Macro for Classifier 2: {f1_score(y_test, clf2.predict(X_test), average='macro')}\")\n",
    "\n",
    "bootstrap_validation(clf1, clf2,\n",
    "                     X_test, y_test,\n",
    "                     n_samples=20,\n",
    "                     sample_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lennartkeller/anaconda3/envs/nlp/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/lennartkeller/anaconda3/envs/nlp/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score Macro for Classifier 1: 0.6768693936440188\n",
      "F1-Score Macro for Classifier 2: 0.7240826181615655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lennartkeller/anaconda3/envs/nlp/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "clf2 = LinearSVC().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"F1-Score Macro for Classifier 1: {f1_score(y_test, clf1.predict(X_test), average='macro')}\")\n",
    "print(f\"F1-Score Macro for Classifier 2: {f1_score(y_test, clf2.predict(X_test), average='macro')}\")\n",
    "\n",
    "bootstrap_validation(clf1, clf2,\n",
    "                     X_test, y_test,\n",
    "                     n_samples=200,\n",
    "                     sample_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grad_boost_sklean = GradientBoostingClassifier()\n",
    "grad_boost_sklean.fit(X_train, y_train)\n",
    "y_pred = grad_boost_sklean.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tok = Tokenizer(num_words=20000)\n",
    "tok.fit_on_texts(df_train.text)\n",
    "\n",
    "Xk_train = tok.texts_to_matrix(df_train.text)\n",
    "Xk_test = tok.texts_to_matrix(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "yk_train = le.fit_transform(y_train)\n",
    "yk_test = le.transform(y_test)\n",
    "\n",
    "yk_train = to_categorical(yk_train)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Reshape\n",
    "\n",
    "def build_model(num_words, n_classes, hiddenlayer_size=512, n_hiddenlayer=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hiddenlayer_size, input_shape=(num_words, ), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    for i in range(n_hiddenlayer):\n",
    "        model.add(Dense(hiddenlayer_size, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = build_model(20000,\n",
    "                    len(np.unique(y_train)),\n",
    "                    n_hiddenlayer=3,\n",
    "                    hiddenlayer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(Xk_train, yk_train,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.1,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yk_pred = model.predict_classes(X_test)\n",
    "print(classification_report(yk_test, yk_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "NUM_WORDS = 5000\n",
    "MAX_SEQ_LEN = 3000\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(df_train.text)\n",
    "test_sequences = tokenizer.texts_to_sequences(df_test.text)\n",
    "\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=MAX_SEQ_LEN)\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "from flair.data import Sentence\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def create_embedding_matrix(sequences, tokenizer: Tokenizer):\n",
    "    X = []\n",
    "    embedder = WordEmbeddings('de')\n",
    "    for sequence in train_sequences:\n",
    "        text = []\n",
    "        for entry in sequence:\n",
    "            text.append(tokenizer.index_word.get(entry, 'UNKOWN'))\n",
    "        text_mat = []\n",
    "        print(text[:4])\n",
    "        flair_data = Sentence(\" \".join(text))\n",
    "        embedder.embed(flair_data)\n",
    "        for token in flair_data:\n",
    "            text_mat.append(token.embedding.cpu().detach().numpy())\n",
    "        X.append(text_mat)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "\n",
    "def build_multiinput_model(embedding_dim, pos_input_shape, char_input_shape, num_classes):\n",
    "    \n",
    "    \"\"\"\n",
    "    Conceptional draft\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Input \n",
    "    embedding_input = Input(shape=(embedding_dim,))\n",
    "    emebedding_layer = Embedding(input_dim=embedding_dim, output_dim=100)(embedding_input)\n",
    "    embedding_conv_dropout = SpatialDropout1D(0.5)\n",
    "    embedding_conv = Conv1D(filters=128, kernel_size=(5,))(emebedding_layer)\n",
    "    \n",
    "    # 2. Input pos \n",
    "    pos_input = Input(shape=pos_input_shape)\n",
    "    pos_dense = Dense(512)(pos_input)\n",
    "    pos_dropout = Dropout(0.5)(pos_dense)\n",
    "    \n",
    "    # 3.Input char\n",
    "    char_input = Input(shape=char_input_shape)\n",
    "    char_embedding = Embedding(input_dim=embedding_dim, output_dim=100)(char_input) # meh\n",
    "    char_conv_dropout = SpatialDropout1D(0.5)\n",
    "    char_conv = Conv1D(filters=128, kernel_size=(5,))(char_embedding)\n",
    "\n",
    "    # 3. Concat input the three input layers\n",
    "    concat_layer = Concatenate()([embedding_conv, char_conv])\n",
    "    bi_lstm = Bidirectional(LSTM(16, return_sequences=True))(concat_layer)\n",
    "    flatten_layer = Flatten()(bi_lstm)\n",
    "    hidden_dense = Dense(512, activation='relu')(flatten_layer)\n",
    "    outpout_layer = Dense(num_classes, activation='softmax')\n",
    "    model = Model(inputs=[embedding_input, pos_input, char_input], outpouts=[outpout_layer])\n",
    "    mode.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_multiinput_model(300, (5000,), (100,), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

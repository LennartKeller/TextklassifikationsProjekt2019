{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:nlp]",
      "language": "python",
      "name": "conda-env-nlp-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "HyperparamOptimization.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LennartKeller/TextklassifikationsProjekt2019/blob/master/HyperparamOptimization_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLxGUx5_Otq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Union, List\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.exceptions import NotFittedError\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class PeriodEstimatorWrapper(BaseEstimator):\n",
        "\n",
        "    def __init__(self, clf: BaseEstimator, **params):\n",
        "        self.clf = clf(**params)\n",
        "        if params.get('verbose'):\n",
        "            self.verbose = params['verbose']\n",
        "\n",
        "    def fit(self, X_train: Union[csr_matrix, np.ndarray], y_train: np.array):\n",
        "        \"\"\"\n",
        "        Fits the estimator.\n",
        "\n",
        "        :param X_train: normal feature matrix e.g. shape (n_samples, n_features)\n",
        "        :param y_train: label vector shape (n_samples,)\n",
        "        :return: fitted instance of itself\n",
        "        \"\"\"\n",
        "\n",
        "        self.clf.fit(X_train, y_train)\n",
        "        self.fitted_ = True\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X_test: List[Union[csr_matrix, np.ndarray]]):\n",
        "        \"\"\"\n",
        "        Predicts classes for n periods\n",
        "        :param X_test: list of feature matrices (n_samples, n_features) to predict (one for each period)\n",
        "        :return: list of predicted label vectors\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.fitted_:\n",
        "            raise NotFittedError\n",
        "\n",
        "        result = []\n",
        "        if self.verbose:\n",
        "            iterator = tqdm(X_test, desc='Predicting classes for periods')\n",
        "        else:\n",
        "            iterator = X_test\n",
        "\n",
        "        for X in iterator:\n",
        "            result.append(self.clf.predict(X))\n",
        "\n",
        "        return result\n",
        "\n",
        "    def predict_proba(self, X_test: List[Union[csr_matrix, np.ndarray]]):\n",
        "        \"\"\"\n",
        "        Predicts probabilities for n periods\n",
        "        :param X_test: list of feature matrices (n_samples, n_features) to predict (one for each period)\n",
        "        :return: list of predicted label vectors\n",
        "        \"\"\"\n",
        "        if not hasattr(self.clf, 'predict_proba'):\n",
        "            raise Exception(f\"Method predict_proba is not implemented in {self.clf.__class__.__name__}\")\n",
        "\n",
        "        if not self.fitted_:\n",
        "            raise NotFittedError\n",
        "\n",
        "        result = []\n",
        "        if self.verbose:\n",
        "            iterator = tqdm(X_test, desc='Predicting classes for periods')\n",
        "        else:\n",
        "            iterator = X_test\n",
        "\n",
        "        for X in iterator:\n",
        "            result.append(self.clf.predict_proba(X))\n",
        "\n",
        "        return result\n",
        "\n",
        "    def decision_function(self, X_test: List[Union[csr_matrix, np.ndarray]]):\n",
        "        \"\"\"\n",
        "        Predicts decision scores for n periods\n",
        "        :param X_test: list of feature matrices (n_samples, n_features) to predict (one for each period)\n",
        "        :return: list of predicted label vectors\n",
        "        \"\"\"\n",
        "        if not hasattr(self.clf, 'decision_function'):\n",
        "            raise Exception(f\"Method decision_function is not implemented in {self.clf.__class__.__name__}\")\n",
        "\n",
        "        if not self.fitted_:\n",
        "            raise NotFittedError\n",
        "\n",
        "        result = []\n",
        "        if self.verbose:\n",
        "            iterator = tqdm(X_test, desc='Predicting classes for periods')\n",
        "        else:\n",
        "            iterator = X_test\n",
        "\n",
        "        for X in iterator:\n",
        "            result.append(self.clf.predict_proba(X))\n",
        "\n",
        "        return result\n",
        "\n",
        "    def score(self,\n",
        "              X_test: List[Union[csr_matrix, np.ndarray]],\n",
        "              y_true: List[np.array],\n",
        "              scoring_func: callable = lambda y_true, y_pred: f1_score(y_true, y_pred, average='macro'),\n",
        "              pooling_func: callable = np.mean):\n",
        "\n",
        "        if not self.fitted_:\n",
        "            raise NotFittedError\n",
        "\n",
        "        scores = []\n",
        "        for X, y in zip(X_test, y_true):\n",
        "            y_pred = self.clf.predict(X)\n",
        "            score = scoring_func(y, y_pred)\n",
        "            scores.append(score)\n",
        "\n",
        "        return pooling_func(scores)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev1QTSkwOtq_",
        "colab_type": "text"
      },
      "source": [
        "### Problem: Wie tunen wir die Hyperparameter?\n",
        "\n",
        "Problem: Unsere Idee sieht vor ein Modell auf alle Genres innerhalb einer \"Periode\" zu trainieren und auf alle anderen anzuwenden, um abzuschätzen wie sehr sich die Genres über die Zeit verändern. Hierbei stellt sich die Frage, wie man die Hyperparameter der Modelle valide und gleichzeitig effektiv optimieren kann.\n",
        "\n",
        "* Möglichkeit 1:\n",
        "    * Gridsearch auf Ausgangsperiode\n",
        "    * Vorteile:\n",
        "        * Wahrscheinlich am ehesten valide\n",
        "    * Nachteile:\n",
        "        * Unsere Datengrundlage ist zu klein, um dass für einzelne Epochen sinnvoll durchzuführen\n",
        "* Möglichkeit 2:\n",
        "    * Gridsearch auf allen Daten\n",
        "    * Vorteile:\n",
        "        * Große Datenmenge\n",
        "        * Modell würde auf alle Eigenheiten der Perioden getuned werden (wobei das eher ein Nachteil ist)\n",
        "    * Nachteil:\n",
        "        * Spätere Testdaten würden fürs Optimieren verwendet werden\n",
        "* Möglichkeit 3:\n",
        "    * ParamDict verwenden, um die den eigentlich Lauf (das Trainieren auf einer Epoche und Testen auf allen Anderen) mit allen möglichen Hyperparamtern zu testen. Eigene Evaulation (bsp. Mittelwert der F1-Scores für die verschiedenen Epochen)\n",
        "    * Vorteile:\n",
        "        * Klare Trennung von Test und Trainingsdaten\n",
        "        * Mehr Daten für die Optimierung als bei Möglichkeit 1\n",
        "    * Nachteile:\n",
        "        * keine cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJll098LOtrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNTAduy9Pht-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "d11eacef-d32c-47a6-c477-d99b2cee9151"
      },
      "source": [
        "!pip install stop_words"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop_words\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-cp36-none-any.whl size=32916 sha256=40a1030c0ca3eada619d064b0f4bed62c013a5c17daec602aa0d4dec59a5b4d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgoygjA4OxG1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "18b8b0b0-f832-4755-e493-aaeee073b9fb"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etQ-W29_O5vE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0d5ea30-31e9-41a7-9224-7fa1e43dcef3"
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "full_dataset.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux6i71RfOtrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/full_dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSremhOROtrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove news genre\n",
        "df = df[df.genre != 'NEWS']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWr0rCcDOtrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_p1 = df.loc[df['period'] == 'P1']\n",
        "df_rest = df.loc[df['period'] != 'P1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-NiWcaHOtrO",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGNoSRjiOtrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from stop_words import get_stop_words\n",
        "\n",
        "tfidf = TfidfVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYXH26JxOtrU",
        "colab_type": "text"
      },
      "source": [
        "# Bauen der Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtseh1vjOtrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import make_pipeline, make_union, Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX5iGM3YOtrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGGzLvaPOtrZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "103d9e32-8d88-42e5-cebc-ef325bbb84d1"
      },
      "source": [
        "pipe_svm = Pipeline([('tfidf', tfidf), ('linearsvc', LinearSVC(loss='hinge'))])\n",
        "pipe_svm"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('linearsvc',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='hinge', max_iter=1000, multi_class='ovr',\n",
              "                           penalty='l2', random_state=None, tol=0.0001,\n",
              "                           verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGR-D6h9Otrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe_svm_params = {\n",
        "    'tfidf__max_features': [1000, 5000, 10000, 15000, 20000],\n",
        "    #'tfidf__stop_words': [None, get_stop_words('de')],\n",
        "    'tfidf__analyzer': ['word', 'char', 'char_wb'],\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 3), (1, 5)],\n",
        "    'linearsvc__C': list(range(1,11)),\n",
        "    'linearsvc__penalty': ['l2', 'l1']\n",
        "    \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIyiuscaOtrg",
        "colab_type": "text"
      },
      "source": [
        "# 1. Möglichkeit: Gridsearch auf Trainingsperiode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92CFvLD8Otri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "gridsearch = GridSearchCV(\n",
        "    pipe_svm,\n",
        "    pipe_svm_params,\n",
        "    scoring='f1_macro',\n",
        "    verbose=1,\n",
        "    n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLEMSQvoOtrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "d8b39a07-8d13-4edc-a39f-508ebd00f50a"
      },
      "source": [
        "gridsearch.fit(df_p1.text, df_p1.genre.to_numpy())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  6.6min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed: 12.8min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 23.4min\n",
            "[Parallel(n_jobs=-1)]: Done 1246 tasks      | elapsed: 36.4min\n",
            "[Parallel(n_jobs=-1)]: Done 1796 tasks      | elapsed: 51.8min\n",
            "[Parallel(n_jobs=-1)]: Done 2446 tasks      | elapsed: 71.9min\n",
            "[Parallel(n_jobs=-1)]: Done 3196 tasks      | elapsed: 92.3min\n",
            "[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed: 117.0min\n",
            "[Parallel(n_jobs=-1)]: Done 4500 out of 4500 | elapsed: 130.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('tfidf',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_...\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'linearsvc__C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
              "                         'linearsvc__penalty': ['l2', 'l1'],\n",
              "                         'tfidf__analyzer': ['word', 'char', 'char_wb'],\n",
              "                         'tfidf__max_features': [1000, 5000, 10000, 15000,\n",
              "                                                 20000],\n",
              "                         'tfidf__ngram_range': [(1, 1), (1, 3), (1, 5)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_macro', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYqSbESYOtrm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "200c2d1a-d12a-4519-e7a4-2d3ef291edbe"
      },
      "source": [
        "gridsearch.best_params_, gridsearch.best_score_"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'linearsvc__C': 3,\n",
              "  'linearsvc__penalty': 'l2',\n",
              "  'tfidf__analyzer': 'word',\n",
              "  'tfidf__max_features': 15000,\n",
              "  'tfidf__ngram_range': (1, 1)},\n",
              " 0.7830952380952381)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u93G34xIOtro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "outputId": "5da5b002-5860-47d1-8629-9aaad4419dd7"
      },
      "source": [
        "svm_results = pd.DataFrame.from_dict(gridsearch.cv_results_)\n",
        "svm_results"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_linearsvc__C</th>\n",
              "      <th>param_linearsvc__penalty</th>\n",
              "      <th>param_tfidf__analyzer</th>\n",
              "      <th>param_tfidf__max_features</th>\n",
              "      <th>param_tfidf__ngram_range</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.322687</td>\n",
              "      <td>0.003073</td>\n",
              "      <td>0.052285</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>1</td>\n",
              "      <td>l2</td>\n",
              "      <td>word</td>\n",
              "      <td>1000</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>{'linearsvc__C': 1, 'linearsvc__penalty': 'l2'...</td>\n",
              "      <td>0.708730</td>\n",
              "      <td>0.659524</td>\n",
              "      <td>0.703968</td>\n",
              "      <td>0.626984</td>\n",
              "      <td>0.706349</td>\n",
              "      <td>0.681111</td>\n",
              "      <td>0.032613</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.463731</td>\n",
              "      <td>0.034002</td>\n",
              "      <td>0.145152</td>\n",
              "      <td>0.010937</td>\n",
              "      <td>1</td>\n",
              "      <td>l2</td>\n",
              "      <td>word</td>\n",
              "      <td>1000</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>{'linearsvc__C': 1, 'linearsvc__penalty': 'l2'...</td>\n",
              "      <td>0.646825</td>\n",
              "      <td>0.659524</td>\n",
              "      <td>0.515873</td>\n",
              "      <td>0.637302</td>\n",
              "      <td>0.659524</td>\n",
              "      <td>0.623810</td>\n",
              "      <td>0.054613</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.083001</td>\n",
              "      <td>0.029989</td>\n",
              "      <td>0.256598</td>\n",
              "      <td>0.006509</td>\n",
              "      <td>1</td>\n",
              "      <td>l2</td>\n",
              "      <td>word</td>\n",
              "      <td>1000</td>\n",
              "      <td>(1, 5)</td>\n",
              "      <td>{'linearsvc__C': 1, 'linearsvc__penalty': 'l2'...</td>\n",
              "      <td>0.646825</td>\n",
              "      <td>0.659524</td>\n",
              "      <td>0.515873</td>\n",
              "      <td>0.637302</td>\n",
              "      <td>0.659524</td>\n",
              "      <td>0.623810</td>\n",
              "      <td>0.054613</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.301410</td>\n",
              "      <td>0.012273</td>\n",
              "      <td>0.045825</td>\n",
              "      <td>0.001982</td>\n",
              "      <td>1</td>\n",
              "      <td>l2</td>\n",
              "      <td>word</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>{'linearsvc__C': 1, 'linearsvc__penalty': 'l2'...</td>\n",
              "      <td>0.706746</td>\n",
              "      <td>0.716667</td>\n",
              "      <td>0.609524</td>\n",
              "      <td>0.626984</td>\n",
              "      <td>0.811905</td>\n",
              "      <td>0.694365</td>\n",
              "      <td>0.072394</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.401519</td>\n",
              "      <td>0.025374</td>\n",
              "      <td>0.145544</td>\n",
              "      <td>0.006093</td>\n",
              "      <td>1</td>\n",
              "      <td>l2</td>\n",
              "      <td>word</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>{'linearsvc__C': 1, 'linearsvc__penalty': 'l2'...</td>\n",
              "      <td>0.706746</td>\n",
              "      <td>0.817857</td>\n",
              "      <td>0.527778</td>\n",
              "      <td>0.637302</td>\n",
              "      <td>0.811905</td>\n",
              "      <td>0.700317</td>\n",
              "      <td>0.109590</td>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>2.596360</td>\n",
              "      <td>0.023152</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>l1</td>\n",
              "      <td>char_wb</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>{'linearsvc__C': 10, 'linearsvc__penalty': 'l1...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>4.748061</td>\n",
              "      <td>0.059630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>l1</td>\n",
              "      <td>char_wb</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 5)</td>\n",
              "      <td>{'linearsvc__C': 10, 'linearsvc__penalty': 'l1...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>0.862964</td>\n",
              "      <td>0.042816</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>l1</td>\n",
              "      <td>char_wb</td>\n",
              "      <td>20000</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>{'linearsvc__C': 10, 'linearsvc__penalty': 'l1...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>2.596670</td>\n",
              "      <td>0.018641</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>l1</td>\n",
              "      <td>char_wb</td>\n",
              "      <td>20000</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>{'linearsvc__C': 10, 'linearsvc__penalty': 'l1...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>4.540968</td>\n",
              "      <td>0.366708</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>l1</td>\n",
              "      <td>char_wb</td>\n",
              "      <td>20000</td>\n",
              "      <td>(1, 5)</td>\n",
              "      <td>{'linearsvc__C': 10, 'linearsvc__penalty': 'l1...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>900 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0         0.322687      0.003073  ...        0.032613              187\n",
              "1         2.463731      0.034002  ...        0.054613              299\n",
              "2         5.083001      0.029989  ...        0.054613              299\n",
              "3         0.301410      0.012273  ...        0.072394              173\n",
              "4         2.401519      0.025374  ...        0.109590              169\n",
              "..             ...           ...  ...             ...              ...\n",
              "895       2.596360      0.023152  ...             NaN              458\n",
              "896       4.748061      0.059630  ...             NaN              457\n",
              "897       0.862964      0.042816  ...             NaN              456\n",
              "898       2.596670      0.018641  ...             NaN              777\n",
              "899       4.540968      0.366708  ...             NaN              900\n",
              "\n",
              "[900 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onIIWneIxw8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm_results.to_csv('/content/gdrive/My Drive/smv_tuning1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMwjZfbtVxuW",
        "colab_type": "text"
      },
      "source": [
        "# 2. Möglichkeit: Gridsearch auf allen Daten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ3p_4fgV2tS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gridsearch_full_svm = gridsearch = GridSearchCV(\n",
        "    pipe_svm,\n",
        "    pipe_svm_params,\n",
        "    scoring='f1_macro',\n",
        "    verbose=1,\n",
        "    n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWUp9jB8WCnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gridsearch_full_svm.fit(df.text, df.genre.to_numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxeDoRoOWF0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gridsearch_full_svm.best_params_, gridsearch_full_svm.best_score_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taOfHeDFWI1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm_full_results = pd.DataFrame.from_dict(gridsearch_full_svm.cv_results_)\n",
        "svm_full_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rfqmSINWOGF",
        "colab_type": "text"
      },
      "source": [
        "# 3. Möglichkeit: Alle Parametern mit normalen Durchläufen testen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNiDNc3rWazu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import ParameterGrid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUVhTYOYWkgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe_svm_paramdict = ParameterGrid(pipe_svm_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ghyG_yZ2Zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for current_params in pipe_svm_paramdict:\n",
        "  pipe_svm.set_params(**current_params)\n",
        "  # todo use periodwrapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT8s8IXtyHF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}